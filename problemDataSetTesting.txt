problem The code looks comprehensive to a good extent with the usage of comments and clear naming. 1. Adding the not interested feature is aÂ plusÂ point. 2. The naming is done well with attention to the singular andÂ plural nouns for models and controllers. 3. NoÂ problem with respect to the coding clarity.
problem The team has a very well documented history of commits.Â The commit history seems to be well spaced over the entire period of the project development cycle. The team has commits in each of the submission periods and have kept on adding functionalities and updating documentation. The team could have updated their readme a little bit more and added information regarding all the functionalities being assigned to individual roles and how the user experience is set up. Also the team could have adde information on how to run tests in Readme.md file
problem No form validations
problem real estate company-realtor relationship should be 1-to-n -Â missing
problem company realtor relation should be 1-n but isn't. also realtor , house_hunter should belong to user.
problem Models/Schemas do not have the relationships defined. Looks like manual table updation on actions which makes it difficult to maintain long term.
problem Admin - As an admin, when creating a user, there is an option to create an admin - Can't add a house, gives me an error ( im not adding a picture when i save) - can't make inquiries - can't add houses to interest lists - new hunter/realtors i made did get added to the table of all user Realtor - when i switch companies, the previous houses listed from that company, don't appear again. Hunter - search doesn't work - can't make inquiries or add houses for interest list -
problem When admin deletes a company associated with a realtor, it gets reflected in the realtors profile. His company name shows nothing and the houses listed were also deleted. Admin is not able to view house hunters profile (error in deployment), but can view the same using Users section. When a user is deleted by admin, his inquiries are removed and he is no more a potential buyer too. When realtor changes/ creates new company, his previous company houses are deleted. This is reflected in the admin table too. Realtor is not able to view houses listed by others.Â Edge cases A company can be created without filling in the fields required. (Yes an empty row is displayed to the hunter when a company is created without any detail). But it displays the Company number (row number) while seeing the houses. So a house is shown for a company that doesnt exist in the View companies page. Session control : When us
problem 1. when a real estate company is deleted, then the house associated are also deleted 2. when i switch companies, the previous houses listed from that company, don't appear again. 3. cant make inquiries
problem error w/o company for realtor on viewing buyers empty companies- validation missing for empty info on companies admin view - realtor show not working admin view - hunter show not working Search by area missing- no fields to search by area
problem 1) The houses controller handles multiple users. It would make more sense to call methods to handle the case of each type of user. 3) The houses controller also has several long methods. These should be broken up into method calls.
problem The code quality is well written. Many of the functions are doing only one thing at a time. The only limitation I could observe is lack of comments in controller as well model.
problem There are quite a lot of commits meaning that the team could have grouped some of the changes together into one commit instead of commiting every small modification to make them more meaningful
problem DB design is kind of ok, but there are redundant tables for roles/realtors/hunters/admins and users. I believe all this can be combined into one using proper fields and access control. This would have helped you guys keep the code easier as well. Everything else has been handled properly.
problem I can't create a house with no basement as a realtor. It also deleted my image after I uploaded it in this case, before it redirected me to the new page with error information. Also, potential buyers are listed twice (I'm assuming because they liked the house and submitted an inquiry to the realtor associated with it.).
problem The app has the functionalities but the user display is available to all users even though that functionality has to be exclusive to the admin of the app. The realtor also has no means to add a new company and there is no way to edit the user's profile
problem 1Â > No Option to switch roles between hunter/Realtor 2 > No default admin/realtor/hunter account. Maybe you forgot to run db:seed on the server 3 > No validation for Email while creating a company. Any string can be typed in. 4 > Inquiries can only have 1 reply which is a field in DB which gets updated
problem As a realtor, i tried to list a house with no basement, but it won't let me save it saying that an error is prohibiting me. It says basement is blank, when i clearly am selecting the no option. when i changed it to yes, it saved fine Â As an admin I can't see potential buyer list for houses
problem The realtor cannot choose company so the edge case that handle change in company is not handled
problem 1 > Admin login is not working for me 2 > Since I cannot use Admin Account, i cannot test edge cases related to creating/deleting users or creating/deleting Companies 3 > Search is working but is case sensitive.
problem 1) i deleted a company that a realtor was assigned to and it was deleted successfully but the house listed by that company is still in the house list 2) When i switched company for a realtor, i could still deleted the house i listed when i was a previous company 3) when a househunter who made inquiries was deleted, it got rid of their inquires from the system
problem Yes Most of the issues identified are fixed 1) Admin not able to delete user accounts
problem Code looks very clean. I did find some commented lines of code though.
problem The Functionality is working just fine. I noticed one small problem though. As a house hunter, when I added a house to my interest list and then click on more, it says that the page that I was looking for does not exist.
problem I wasn't able to login as admin using the credentials given in the README file. Still, Edge cases are handled well.
problem 1. Switch role functionality could have been simplified. While logging there are two fields regarding roles. If a user forgets to mark yes for realtor, then switch role will be redundant. There is dependency betweenÂ switch role and these fields. Both do the same functionality which results in code duplication. 2. A realtor should not be able to add inquiry, he should be able to reply to inquiry.
problem 1. All realtors belonging to a company should not be allowed to delete the company. Instead only the realtor who created the company must be allowed to delete. Else it can be catastrophic.
problem Cannot upload the image to the house. And a realtor can create an inquiry which they should not. Also, the realtor should able to see the potential buyer for the house under their company, not only the house they create. The more button in the interest list does not work.
problem If delete a company, the realtor needs to find another company, and the house under this company disappeared. But the README.mdÂ does not cover the edge cases.
problem It tests the login function in the user controller, but not test any models.
problem I am not sure how to create a house hunter and realtor using the same email. I see a link to switch roles, but can only see realtor option there as it didn't allow me to create an account for house hunter with same details.
problem Realtor is unable to create his own company. I tried creating one, it dodn't give me an error but didn't even show the company in this list.
problem 1. Switch role option is working for Admin too which is not supposed to be the case.
problem The team continued making commits on a consistent basis throughout the project development after round 1. Commits are named properly,Â they describeÂ changes that were done in theÂ scope of that commit. One issue is thatÂ all contributors are not reflected in statistics.Â I would suggest matching git credentialsÂ stored onÂ local machineÂ toÂ those stored on the server.
problem Foreign key integration does not seem to have been done completely in DB.
problem The relationships are maintained in the schema but the relationship among company realtor seems to be missing as it shows relationship between users and company so the role isnt clear
problem Need to specify role when logging in. It should identify with email. The house search feature does not seem to have been implemented. House hunter and realtor can view all inquiries of all users. Signup page not complete. Image not associated with house. Can view potential buyers of other companies too.
problem Most of the functionalities works in the application, however, >While trying to add a company as a realtor after signing up the user gets the error "Already Created a Company". > While clicking on show on the potentials buyer list, the application breaks. > A house hunter is able to see all the companies which is not as per application requirement.
problem All issues related to admin functionality have been fixed.Â Selecting a company as a realtor and editing it seem to be broken; as such, a house can't be posted.
problem Most basic functionalities are working well. Some functionalities that I found missing: Image upload for house has not been implemented. Admin should not be able to submit inquiries to the houses or add to interest list. I could not find the link to view the inquiry replies for house hunters No link provided for house hunter to see his/her interested house list Potential buyers list page 'show' button doesn't work Realtor cannot create house. Even though company has been updated in the profile, keep receiving message to "select an existing company by editing profile".
problem Throws error when deleting house hunter who has an inquiry.
problem The Readme is very helpful in guiding through the application. Most of the cases haveÂ not been handled by the application. > There is no functionality to upload picture to the houses. Â > A new house hunter is able to see all the inquires made by all the house hunters which is not as per the application design.
problem When house is deleted, the inquires and replies are deleted as well, this has been handled. Error page occurs when I try to sign up for the same role with the same email. Error in deleting a user if the user has submitted an inquiry/reply House hunter can add a house to interest list multiple times, should not be allowed, by maybe hiding the button if the house is already in the current user's interest list. README.md does not cover how the system handles edge cases.
problem (2) Realtor cannot add a house so could not be tested. (3) Admin is unable to delete a house hunter who has submitted inquiries butÂ no proper explanation or error message is displayed. System handles house deletion properly. All relevant inquiries are deleted.
problem 1. AfterÂ signing up as a realtor, I edited the profile and selected a company. However, I can't post a house, the system kept asking me to update my profile and select one of the companies. (alert: "Create a new company or select an existing company by editing profile to post a house.")Â 2. when the admin deleted the company, the house that belongs to the company were not destroy.Â 3.Â https://guarded-chamber-77369.herokuapp.com/potentialbuyers/34 this url crashes
problem The team has not written any test cases for the entities. There are only the default test cases.
problem could not find model or controller testing.
problem The model test just tested the email attribute of the real estate company and the controller test mainly tested for successful responses and redirects, and not page content and method calls.
problem This team claimed to have fully tested the RealEstateCompanyÂ Model and Controller, but there were noÂ tests in the RealEstateModelÂ tests. I didn't check every file after since I don't like being lied to :)
problem last moment commits.
problem Some methods were long and there was a lot of commented-out code. There was at least one instance of bad indentation. Otherwise, the methods were overall fairly short and the naming was sensible.
problem The code quality in this application looks good. I didn't see any extremely large methods, views were clean and simple, and controllers had one-to-one mappings with application-level functions.Â I do think I would encourage this team to consider using scopes in their models next time as I did not see many here.
problem They started adding more commits after the first round of reviews.
problem The team kept committingÂ their changes even in round 2.
problem The models had the correct relationships. The database seemed to have missed some of these. There was not table for potential buyers (n-to-n house-hunter relationship).
problem Overall this was a usable system. However, This app did not do a good job of keeping track of my session. Once I edited that admin account, I could not navigate via links to the home page and was also asked to sign-in again if I clicked "admin sign-in". Even if I signed up as a different user, my admin account was still signed into. I also was not logged-in upon signing-up as a Realtor or House-Hunter. Â Some other comments are: An Admin should be able to set the password for realtor or house-hunter. That is a security vulnerability.Â When I tried to use the "Reset password link", I get an error. When creating a house as an Admin, I shouldn't have to know the ID of the company, I should be provided a drop-down of existing companies - the same way for how a realtor chooses a company to join. Asking a realtor to choose or create a company before signing up is another security vulnerabilityÂ - you leak the existing companies and allow
problem As a house hunter I could edit houses. Also, anyone can create a company, and a realtor cannot create a company before signing up. A realtor could not submit a reply to an inquiry. A realtor could not drop his or her company and could list a house without choosing a company. Last, table IDs are all over the site which is confusing and not helpful to the user. These IDs should not appear to the user or have to be used to create new entities.
problem The search button in not there. No way to add new house. Realtor is given some destroy privileges which are not meant for him.
problem 3) The admin encountered an exception when trying to view potential buyers of a house after its only potential buyer was deleted. Â The README.md did not describe how the system handles edge cases.
problem Here a few things I found: I could list a house that was built in the future. I was also required to give a full date instead of just a year. I was able to edit a house as a House Hunter
problem The Readme file does not specify any information about how edge cases are handled but the edge cases were properly handled. when the real estate company was deleted all the houses and realtors under it were also deleted. However the role switch option between realtor and househunterÂ is not available, further this operation cannot be performed manually also as the code restictsÂ a mail id from being used for two accounts.
problem Upon testing the system for edge cases, the following results were obtained : 1. The real estate company is destroyed and the realtors houses and houses inquiries for the same are removed. 2. The realtor can switch to another company. They will be prohibited to remove the houses listed in the previous company though. 3. The house hunter accounts are deleted without their inquiries . 4. The System does not check for regex fr phone number input during signup.
problem Code in the model methods looks very clean. Attribute symbols are appropriately validated and proper constraints are applied to measure uniqueness. The controller code has great parenthesis and bracket use for function calls and assignments. More consistent spacing of functions and function content would aid in the readability of the code. Also, there are a few instances where conditional blocks are empty. If there is no purpose for the block, it should be removed (example found in the static page controller). Overall, the code seems to implement good Ruby style standards.
problem The code is readable and easy to understand, but at the same time it is not effectively modularized.There are sevealÂ methods which perform the functions of other methods too, which could have better been modularised Apart from that,
problem Most of the code is auto-generated from rails generator so they do the generic thing. Although they have connected most of the app, the basic functionalities are still lacking and no new code has been written. The only part I see is the sessions controller that has been written manually, and follows correct coding convention.
problem The repository name isn't what it is supposed to be. Naming seems inappropriate. plus, there is no read me file explaining the flow of webapp.
problem some direction code is ambiguous
problem There are no issues with code quality or naming.Â Code is clean and readable and follows Ruby on Rails practices.Â Most methods are short and doÂ oneÂ specific task. One possible improvement would be moving outÂ authorization functionality from controller methods to separate functions.
problem The commits were not scattered throughout the development cycle, rather they were concentrated on a particular couple of days, which indicate that the project was a last minute rush, rather than a pre-planned and well executed one.
problem Very Few commits in the project, with most commits coming just from one user towards the deadline period. A lot of Commits done after the deadline period
problem The team did not commit their changes throughout the project period. The changes were committed in round 2.
problem No, majority checkins are near deadlines and not well spread out. Usage of multiple branch is good.
problem The team has pushed almost all the commits on 2-3 days of the entire cycle, not regular. Also, the commits are made by one person, which seems strange to me.
problem Most commits were done by one person whichÂ cannot be considered a good practice. NamingÂ of commits is done well, names are descriptive ofÂ the introduced changes. I would suggestÂ doing commits more often by dividing work into smaller chunks.
problem It seems that some of the associations were attempted. (1) Real Estate Company contains many users and houses and (2) House belongs to a Real Estate Company and a user. These relationships are currently commented out so the dependencies are not enforced. There are additional connections missing such as the Users model, where a Realtor should belong to only a single company and many houses. The implementation seems incomplete, but the idea found within the company and house models is moving in the right direction.
problem The relationship mapping was appropriate and worked as intended. The database unfortunately didn't implement all the necessary features required for the submission. (For example: list of potential buyers)
problem All the 1-n, n-n Relationships have been commented out. There are no mapping table in Schema as well.
problem To the most extent of it. Since, the profile of admin is problematic and not allowing us to login at all. That area is unavailable for testing.
problem As of now, all relationships have been commented out, I am not sure why this has been done.
problem Following are some of the relationships missing: Â house hunter has_many inquiries realtor has_one company
problem can not log in as admin
problem Your home page is very clear as toÂ the application purpose. Unfortunately, I am unable to sign up as a new user or loginÂ with any of the pre-configured user accounts included in the Readme. I can, however, attempt to sign up and/or login but this information is never saved to the database for future access or the appropriate transitioning is not implemented. I like that there are two options listed on the homepage to either sign up as a new user or to login in as a current user. This is convenient for navigation. Consider spacing these links for easier identification. I would also point out that the options in the drop down box included for selecting user type during sign up is a great idea. The third option, is a ambiguous as to its purpose. What does it mean to sign up as a realtor who is also shopping for a house? Perhaps you can just limit the options to Realtor or House Hunter. The functionality of searching homes should be included in the Realtor services. Keep up the work. Once the
problem There are a lot of functional bugs. Also, lots of required functionalities like listing a house as interested, list of potential buyers etc are missing. Also, there are a lot of navigational bugs. For example, when a user is both, a realtor and a househunter, he gets an option to create a new company when viewing list of enquiries, which should not have been the cae.
problem 1 > Admin Login is not working for me 2 > Cannot Login through default Realtor/Hunter Accounts 3 > No Search Functionality for houses 4 > No Image upload for houses 5 > Views are a bit messed up, It shows Inquire About a House in create company page. 6 > Navigation is not proper, Creating a new house redirects you to the home page 7 > inquiries Feature although implemented does not work 8 > No reply Feature
problem The author improved the application but still did not fix all the problems. For an instance, the inquiry option is created but it does not work properly. After creating an inquiry the user gets logged out immediately. Also, the created inquiry is not visible under "my inquiries" options. The interest in a particular house option is still not given.
problem Admin functionality is failing. Not able to log in as it should.
problem Multiple roles seems to be missing. Eg. for the details for house hunter given in readme,i get logged into realtor profile same is whenÂ I create a new user and log-inÂ create a company, get message that user has been created "Welcome to the Real Estate Manager,hunterÂ User was successfully created."
problem when sumbit an iquiry, the page automatically redirect to the homepage and can not find the user page.
problem I am unable to log in as adminÂ with credentials that areÂ provided in README.Â Search houses functionality for house hunter is missing. Inquiries are not added to the system and page that is supposed to display all the inquiriesÂ is not working.
problem (1): Unable to login as admin! (2): Realtor can delete houses, but houses don't seem to map to a real estate company, rather they are mapped to the realtor only (3): Unable to login as admin
problem I am unable to test any edge cases as logging into the system as any type of a user is not implemented.
problem 1 ) Since Admin Login is not working, this cannot be tested 2 ) Realtor Can still edit the house after changing his Company 3 ) Inquiries Feature although implemented is not workingÂ Â Since the basic Functionalities are still lacking I believe the edge cases have not been handled anywhere.
problem I could not login as an admin using the user password combination mentioned in readme.
problem 1. Fails this edge case due to unavailable admin functions 2. This function fails to.Â 3. Not available. 4. Realtor inquiries are also non functional.
problem Since, there is no readme file, admin access is not clear or how to navigate to those features. So most of the cases could not be checked due to ambiguity in the flow.
problem Most functionality is either broken or not present 1. delete real estate company not present 2. create house not present 3. On user create get,"Welcome to the Real Estate Manager,user1 User was successfully created." 4. Send inquiry, logs out the user
problem 1. Cannot test as delete functionality is missing. 2. Cannot test as functionality is missing. 3. Cannot test as delete functionality is missing.
problem Most of the edge cases cannot be testedÂ due to problems with accessing admin's account. Functionality pertaining to inquiries add/edit/delete is not implemented.
problem There is only a single test file included with this application, sessions_controller_test. The functionality tested within this file attempts to cover starting a new user session. The test ensures that a new session is returned through an assertion statement equating to true. There are many additional functions of the sessions controller that should be tested including create, destroy, successful log in, etc. Making sure that each of these methods are functional will aid in the development of further successful application flows. I would recommend testing the basic models and their accompanying controllers before you begin implementing things such as house inquires and user responses.
problem The application seems to have been developed, but not tested enough, as apart from just naviagtional bugs, there are also functional bugs. Many of the required things are also not implemented, hence there was not much stuff to rate for.
problem No tests have been written. At least under the Tests folder.
problem No tests performed seem visible as executional flow is uneven.
problem No, they have not. No models were tested.
problem No tests added for model or controller
problem Testing has not been performed appropriately. Handling only one case isnt called testing
problem No tests for either model or controller areÂ present.
problem There are no test cases other than those auto generated by the scaffold generator, thus cannot comment more on testing.
problem The code has been implemented in a modular way. However, there are few functions where Ruby naming conventions has not been followed for example : "authenticateAdmin" in UsersController class.
problem Code is well written. Functions are well defined. Some areas where it can be improved is moving the house search logic from controllers to the respective models.
problem The code is clean and readable, but there's only one suggestion. The page which lists houses (index) and search houses are handled by different controllers, whereas, they could have been easily integrated into one, without compromising code readability. It would have lead to a more integrated and a cohesive web app. In one or two instances, there were several functions performed within a function, which could have been better modularised too.
problem They continued to update their project. However, some changes were made after the due date.
problem Yes, the system handles all the entity relationships well. There is no mapping table as such, but all relationships has been addressed in correct association degree in the application.
problem Relationships have not been defined in the models.
problem Inquiry mapping is not done.
problem Inquiry doesn't belong to either a house or user
problem The system has all the basic functionalities as per the program description. As per the last feedback, validation checks for invalid data has been added to the application. However, the system still does not have the null checks for field.Â For example: If a user creates a house without adding most of the details, the application breaks. Â https://housefocus.herokuapp.com/houses
problem Realtors can sign up without specifying a company. This means if there are no companies in the system, realtors can't sign up. While creating a new company, address field is given as a drop down, with only two options - Raleigh and Cary. Can't specify any other address. Also, in the create company page, size of the company is again given as a drop down, with limited options. Can't give any other value. Admin can't create new houses.
problem Except inquiry reply all other functionalities work in my opinion.
problem multiple success message still not fixed
problem The system works well in most of the cases, except when the realtor creates his company, and then after successfully creating the company, he get's an option to edit his company details, but then when he clicks the edit button, it redirects to the homepage, and is unable to edit his company info unless he choses to belong to the particular company. A minor bug, but still breaks the consistency.
problem The system works exactly how it is supposed to work. I could not find any functionalities that are still failing. No bugs or error messages. It would have been better if the realtor could send replies to inquiries directly from the application than opening a separate mail application.
problem Search is not working. Anyone can login as admin. no house picture is displayed if it is saved.
problem Admin should not able to submit an inquiry and put a house in interest list. Also, the user should not able to sign up as an admin. And reply to the inquiry function must use the email system to reply, cannot do it onsite. When creating a company, the user can only choose Raleigh and Cary as their address. Cannot see the house list by other company.
problem The edge case when a admin deleted the real estate company hasÂ been handled as after the adminÂ deletes the real estate company the houses listed under that company are all deleted. Â The realtor when changes the company cannot see the house listed under previous company so he would not be able to delete the houses under previous company. Â No, the readme.md does not contain any detailsÂ on the edges cases handling.
problem Deleting a company doesn't delete its houses.
problem When a real estate company is deleted, the respective houses are deleted, the realtors are not. Further, even after deletion, the company of those realtors remains the same. They can even edit the deleted company from their profile and list a house on behalf of the deleted company. When a realtor edits and updates his company after it is deleted, it actually gets created again. When a realtor changes his company, he can view only the houses of his current company and is prohibited to delete houses of his previous company. This works as expected. When a house hunter is deleted, (s)he gets removed from the potential buyers list, but inquiries are only partially deleted as in the row is still there but only two columns show data.
problem (1): when an admin deletes a company which has existing realtors, it shows on the admin page that the company is deleted, but when the realtor signs in, it still shows that he belongs to the deleted company, and is able to update all the profile information of the company. So, it means the company is not being deleted, even when it says so on the admin page. (2): the realtor isn't able to view any houses except his own company. (3): No, the inquiries are not auto deleted, nor is the househunter removed from potential buyers list.
problem 1. This test case is a flaw as an admin can hitherto delete whenever and whatever he wants.Â 2. This too is not strongly tested and runs into glitches on doing so.Â 3. This too falls through when tested.Â 4. The admin can be deleted and edited with. System fails overall when this case happens. Biggest flaw yet unresolved.
problem Edge cases are not explicitly handled, but the validations and logic will limit edge case scenarios from affecting the application.
problem 1) If the admin deletes a company, all the related properties will be deleted and will remove the company name assigned to any realtor. 2) If the realtor changed his or her company, the realtor cannot make changes to old posts which they have posted for the previous company they worked for. So they will not be able to edit,add or remove the houses listed in previous company. 3) If the house hunter is deleted by the admin, all the inquiries by the house hunter will be deleted and their names in the potential buyers list is removed. The README.me did not cover how the system handles all these edge cases. README.md could be updated.
problem If company is delete, the house will also disappear, and the realtor need to find a new company. But the README does not cover edge cases.
problem The team has not created any test cases to test the model and controllers of multiple entities.
problem No test cases could be found.
problem Yes, the login / signup module seems to be very well tested, considering the fact that all the three types of users (admins, househunters and realtors) are managed by using the same table. But, there's also a small functional bug. Even if I hadn't regisitered as a househunter or a realtor, I am able to switch back and forth between the roles, which is kind of counter-intuitive in many ways.
problem None of the controller or model are tested.
problem They test the controller but not the model.
problem Since I couldn't view the test plan,Â i am unable to comment on it.
problem The test plan seems to be missing
problem I could not find any test plan or documentation and hence could not verify whether the tests have passed or no. Tests for checking for duplicate directories due to assignments having same names is missing.
problem As mentioned earlier, they have not considered testing at all at this point and hence, we are assuming that they are to implement testing at a further point in the project. Of course, mentioning an approach to the testing framework and how they would be going about it would have helped. Moreover, the absence of a wiki doc only adds to the grievances of beingÂ unableÂ to decipher the problemÂ statements.
problem No tests added or at least link isn't provided
problem Unfortunately, the team has not provided any link to the write-up. Hence, I would not be able to provide reviews for this question.
problem They don't have a Test Plan.
problem Could not see the Test PlanÂ as write-up link has not been provided. Looking at the code also, it seems as if no tests are written. It is always a good practice to follow TDD. Please write test cases to test the changes made.
problem The names are all proper. However, there are lines of code which are commented out. Cleaning up that would reduce the clutter.
problem The links provided are only of commits and not the code added.
problem Names could have been better designed especially the 'quesparams' variable. I get no idea about what that variable is used for or what that implements. You can rename it to question_params, or duplicate_directory_params etc.
problem On checking, the code, we find that, in agreement with @TravisBuddy, the code had a build error which seems to be unresolved, which is strange, and should have been looked into. Moreover, the overall coverage shows a good amount of increase which is good. But one must say that the details in the code changes as few as they seem have been to a good extent for the majority of the part and thus worth the merit.
problem Good work. Need to work on tests.
problem The team has only made one significant change to the following file: app/controllers/assignments_controller.rb . It is an if statement which is difficult to follow since the team has not written any comments for the same. Â Suggestion: The team could add comments and screenshots for better understand of the workflow in the second submission
problem I can guess the array 'quesparams' means questionÂ parameters, but this variable name is confusing, I think they should use question_param instead.
problem Issue #1201 Below is the change made in _general.html.erb Directory name will be autogenerated if not provided. In the form of assignment name_id_course_id. The last part could be modified to something with a bit more clarity. From the assignments_controller code it could be seen that the auto-generated directory name follows the format <assignment name>_<assignment id>_<course_id> which is not what is specified in the text. There is a typo in the word 'autogenerated', it needs to be hyphenated as 'auto-genera
problem Comments needed.
problem More comments are needed because I had trouble following what the code was doing in some places. The code follows Ruby Style Guide and is DRY in its design. Functions are small in size and naming conventions have been followed. Kudos!
problem I feel you guys should add a few comments for a third person to follow.
problem The team has only made one significant change to the following file: app/controllers/assignments_controller.rb . It is an if statement which is difficult to follow since the team has not written any comments for the same.
problem Issue #1201 In the assignments_controller code, the team has checked in a puts statement (line 48) which looks like debug code. Even though these are helpful during the development phase, we need to remove them before finally pushing them. Issue #391 The comment (assignments_controller.rb:85) is not descriptive enough. The author has commented out a method call. It would be beneficial to the person reading the code to understand the intention behind this. Please provide a detailed comment on why this was done. Again the author has use a puts statement (_submitted_files.html.erb:29) which should not be committed and should only be used during development/debugging. Please remove the debug code.
problem Since the test plan is not included, i am unable to do the manual testing.
problem Manual testing seems an impossible task since it is not having a wiki doc itself which makes it impossible to have a specific design flow for the project in question to go ahead and check the program.
problem The features work as intended however I am having trouble navigating and checking what are the differences between the original system and the improved system. Could have made a demo video showing the improvements or a step guide to follow. They could have also provided some steps or a visual navigation guide to see the changes. For edge cases you could check what happens when assignments have same names, blank or whitespace containing names etc.
problem The team has not provided any link for me to manually test the project
problem They didn't provide a link for me to test their work.
problem No video or deploymentÂ link provided to test manually.
problem The link for the writeup is missing.
problem The writeup seems to be missing.
problem No clear explanation is given as to which files are edited for which reason. Only file names are stated along with changes made. Why the changes were made and what do those changes correct is not given. No write up link has been provided. It was tough to navigate the code myself. No demo or link provided as well.
problem No, the team has not been diligent in specially making a section of "what it does" as the introductory section of the doc so as to make us understand the goals of the project. They have seemed to not even make a Wiki page for the same or have seemed to forget to upload it. Because, how am I supposed to follow the approach and solution of the problem if there doesn't exist any documentation to check for the same.
problem There is no write-up provided as of now. The wiki page is also not done yet.
problem Didn't find anyÂ documentation link. But it was understandable from the code links on github. Â Goal is to create unique directories for each assignment.
problem No writeup link provided.
problem They don't have a wiki page link, so I cann't see their OSS writeup.
problem The link to the writeup is missing.
problem Testing is absent in the project. This could have been because (by the looks of it) the issues were too small (only 20-30 lines code). Refer RSpec documentation to write tests. It is easy to follow.
problem Unfortunately, no mention of the word "test plan" has even taken place in their whole doc. So, it seems that they are yet to implement the testing functionalities in their project. Although, it would have been better if they had checked if the checks or the tests already existed in the first place in the git repository. Â Â Moreover, as a part of their project, one of their problem statements is in fact to write the tests for a specific problem scenario. IÂ haveÂ reason to b
problem Issues #391, #1201 were fixed but i dont see any tests as mentioned in issue #1190.
problem There are no tests. Probably you guys will do it in the next phase.
problem TheÂ writeupÂ seems to be missing.
problem No mention is made as to why the changes were made in which specific files.Â The code is well written but hard to follow (what is the functionality of the code is tough to decipher). It would have been better had there been some comments or documentation as to what those respective methods do.
problem No, since no write up or no wiki page exists. it is clearly not possible to ascertain any of the above clauses.
problem Write up isn't provided. I went through their git commit and the requirement forÂ issue #1201. There is a 'puts' statement in the controller. I feel that should be removed, you guys might have added it for debugging purposes, but it should be removed before committing. Also, not sure how the changes made are applicable to the problem at hand which is to check if assignments have the same name if I'm not wrong.
problem No writeup/documentation found.
problem I cannot find test plan.
problem No, they did write the test plan.
problem Authors have followed Ruby style guide. Test cases have not been discussed in the write-up.
problem No Test Plan was included. The bare minimum of description was given for each test, and the project preamble. As far as I can tell, though, there is no document that says we should have created a Test Plan, and I bet it is safe to say that their mentor did not suggest creating a Test Plan either.
problem the writeup is lacking in terms of explanation of how to test the funcionality thoroughly.
problem Variable names and test cases are named appropriately. Explanation of reasons for the style of code and problem solving approach is lacking.
problem It looks like if they fix some style issues then it could increase the code coverage. I don't understand why their last unit test does not pass though.
problem Some of the functions are too long such as #delete function.
problem All their test pass, but they don't have a test plan section
problem Some "let" methods, likeÂ participant2, student2, response_map2,Â are repetitive.
problem All of the code appears to be above board, and no functions are overly long. The test did take like 28 seconds to run, which seems like a lot.
problem The video shows all the test cases pass, but I'm skeptical that they got all theÂ corner cases. Looking at the review_response_map.rb model, there are a lot of methods which aren't explicitly tested.
problem Code is running and no errors are encountered. However, very few tests have been written and coverage is low. A way to make the testing more robust is to test every function with a known success case andÂ an edge case or potential failure.
problem Source code is good in all spots, except the last unit test. I was unable to figure out why it did not work.
problem some branches are skipped by the "allow" statement. If a method would raise an exception, then test whether it would raise it.
problem They don not have any test plan, and some functionality of code is not adequate for the test.
problem There's basically no documentation outside the source code itself.
problem Naming conventions that are used in this project are clear, reasonable and follow standard Ruby practices. There are some instances of variable names that are concatenated with numbers like topic1, topic2. While this approach can be justified in some cases, I would suggest using more descriptive names instead or arrays if multiple instances are required.
problem This is semi-passable. The wiki is hosted on Wikipedia, so they clearly didn't read the directions. I mean, I get it, though. I wrote tests, and was also unclear about what exactly the Wiki should contain.
problem I can not find the test plan.
problem They don not have a test plan.
problem It's unclear how complete the test plan is because their wiki does not contain their total branch or mutation coverage.
problem No, this writeup doesn't have a test plan section.
problem As this rubric calls for a section called Test Plan, I suggest adding it and rearranging the wiki content, so that a description of the tests is given in this section
problem The approach taken by the team to increase the code coverage has not been clearly stated. Also there is no mention about what was the existing code coverage and how much did the team increase it to?
problem Test Plan is missing
problem The test plan is not added as the part of writeup
problem There are some functions long for example like scores , However, as this function is handling all the required cases hence , that length is quite valid and considerable
problem the team does not show up any design patterms. in the wiki page, the authors did not explain how and why they did, and what I can see is just the final code for some perticular exmples.
problem Yes they have explained the way and why they did, and in their writeup, they does not mention any principles or patterns.
problem There's not really a rationale for why these particular tests are sufficient.
problem The authors have included the different tests that they wrote, however a description of what the test is testing would be helpful.
problem 2 Code climate issues pending. No explanation provided for why gemlock file is being added.
problem They wrote the literal least possible, but again, I get it. Learning how to test with doubles, mocks, stubs, and spies, to peek in on the innards of a high complexity OO system was actually really difficult.
problem The code is well-formatted and structured very clearly. It is easy to follow the expressed intent. Every 'it' block is succinct and contains one assertion. Indentation and styling are consistent.Â One suggestion is to improve the expectation for method #scores by testing the attributes that are relevant in that context as opposed to checking the string value of #inspect method.
problem No details about what was changed only details related to already existing implementation has been stated.
problem There many comments by auto bot on indentations and coding standard. Could have resolved it.
problem several methods are missing in the document and the rspec file likeÂ review_response_report, import.
problem nly one test case implemented and executed which verifies whether the correct email has been sent to the reviewer.
problem Test plan is not described fully. However whatever is mentioned in the wiki doc has been implemented via Rspec. But there are some previously running tests which are failing because of the changes.
problem An old test case fails.Â Looks like it was broken before and therefore not a result ofÂ your changes
problem Most of the cases are covered in "should send an email to the participant"Â test case. Reviewer part and its mail content checks are not covered.
problem I did not find the test plan in the documentation. However, there were details mentioned about the tests that the team wrote. One Test related to the issue has been written in the assignment_participant_spec file. The test works works properly. I feel that the Test plan should have been explicitly mentioned in the documentation.
problem There are some repetitions in the code which can be avoided by creating a helper function and calling that function from each place. But apart from that code is well thought out and implemented nicely.
problem The naming conventions have been followed. The professor had frequently asked the team to improve the naming conventions and it seems that the conventions have been properly folowed.
problem Looks good. Comments could be improved. For example, In submitted_content controller there is a comment which says sending email to users. However it is just a method call which redirects it to delayed_mailer.rb. So this should be properly mentioned as it will be helpful for someone refactoring or understanding the code later.
problem The code changes in "app/controllers/submitted_content_controller.rb" line 60-78, could have been in a separate method, such as send "email to reviewers". That would make the controller code clean and clear. Â Â Code changes does not followÂ the DRY principle in atleast two places. 1.Â In
problem I feel that the code from line 64 to 76 could have been written in a separate function to avoid making the functionÂ submit_hyperlink from becoming so large.Â Additionally, the functionality inside the functionÂ review_reminder_email could have been separated into 2 different functions.
problem The features work. However the notice messages could be improved to state exactly the action that is conducted. Eg. One of the notice message says either user is already added or it doesn't exist. Narrowing it down will be of great value.
problem The primary objective of the project is defined clearly. A comprehensive description is provided for technical steps needed to set up the environment and the functionality which is related to the test suite. Furthermore, the team provides a detailed explanation of each test case along with the corresponding code. My suggestion would be to remove or reduce parts like Expertiza, BDD and Rspec description (http://wiki.expertiza.ncsu.edu/index.php/CSC/ECE_517_Fall_2018_-_Project_E1852_Write_unit_tests_for_participant.rb#Expertiza) because they are redundant in this context.
problem Authors explain the functionality of the test in wiki page pretty clearly, including participant_spec.rb, participant.rb and assignment_participant.rb. But there are not explain in video, it might be more convenient for reader to understand if authors add some short explanation in video.
problem The writeup is thorough but screenshots could be added. The instructions are missing too. Rest all looks good.
problem Only one test is implemented and validated for .
problem The authors have mentioned the test they have performed but no specific plan is presented. However they have adequate details about what is done and what is tested and how will the corresponding changes look like. edge case descriptions could have been included
problem there was no test plan section
problem More edge cases can be included. For example, for Participant#team, can include a case when user does not exist.
problem The test case, does not handle the case when the imported csv is corrupted.
problem The "Test Plan" sectionÂ is missing in the writeup. But, they have included aÂ separate section for explaining Rspec based automated test cases.
problem Test plan is comprehensive and covers most of the edge cases. The test suite is achieving test coverage of 99%. One minor issue is that wiki is missing two cases that are implemented in the code (#name, #fullname).
problem The details regarding testing are mentioned in the writeup. But I did not find anything about the Test plan as such, in the writeup. The assignment_participant_spec containsÂ a test. One edge case has been considered. I feel that the Test Plan should have been mentioned in the writeup explicitly.
problem A short description fo everyÂ method change was required.
problem Code changes does not followÂ the DRY principle in atleast two places. Also, the comments in the code are not helpful. All code comments are like "# E1834 Fall 18"Â which does not explain what is the code does, it only says when the code was added. Such comments may be removed.
problem The author has well listed the steps adopted to implement the test cases by giving a code snippet for each and every test .However, the author hasn't mentioned that why does particular test cases have been written in the spec file.
problem They did not explain why they did what they did, just what they did
problem Authors mostly discuss the technical parts of each test case, i.e. how it works and whatÂ functionality it is testing. There is almost no emphasis on any design decision or pattern. There is a mention of mock objects being defined at the beginning of the test file, however the wiki does not elaborate on the reasoning behind those decisions. Some improvements can be done by explicitly stating and justifying the structure of the code. For example, discussion on why there are no instances of before(:each) statements and how defining every let statement once at the beginning of the file is superior to having that data defined for each test suite separately.
problem Some changes needed explanation.
problem Test Plan hasn't been defined because the testing is carried out by Mozilla
problem Could not find any
problem The pull request does not show any Tests done on the project
problem I don't see any test plans.
problem The newly added code has not yet been accepted in the pull request but it does build. The corresponding rust implementation, however, has not been added and so the test coverage hasn't improved by much.
problem The newly added code includes the attribute height, the getContext() and transferToImageBitmap() method in the OffscreenCanvas.webidl file. The name height given for the attribute height for the Canvas makes complete sense. Similarly the name getContext() given for the method that returns the OffscreenRenderingContext is also intuitive. The name transferToImageBitmap is a little long which might be the code less readable if the method is called often. Instead the accessor convention of using getImageBitmap() feels more intuitive and also logical at the same time.
problem The build did not pass due to some minor inconsistencies.
problem There are almost no comments.
problem All codes construct perfectly, though not much code I could see in the git.
problem The team has not implemented any function in the pull request. They have basically defined the ImageBitmap interface that will be implemented in the future by Servo.Â There can be a few comments to describe their code and about the previous implementation.
problem The code is really well written and follows Ruby Style Guide, except some areas.
problem The implementation does not seem to be working, so it would be difficult to test this. Also, I am no Rust programmer, so there's that.
problem The features cannot be tested until the final changes are completed
problem I have no idea how to test the code manually.
problem The code is running. However, few functionalities are not there.
problem TheÂ background sections were fairly clear, but the details could have been fleshed out more. Some description of the code would be better than a dump of the code.
problem Yes, the Wiki is clear and explains most aspects of the project but there could be a better explanation for the IDL files that were added and the corresponding changes that were made because of adding these files
problem The Wiki lists a lot of terminology but few with how they do this project.
problem A little too brief.
problem The write-up gave a good introduction to the project by providing the background information about the Servo parallel web-engine project by Mozilla for web page rendering and Rust programming language to execute HTML5 and CSS3 parsers. It then highlighted the OffscreenCanvas API that can be used to generate frames and also return the rendered image using the transferToImageBitmap() method. The writeup covered how web workers can be used to implement OffscreenCanvas API to render images as an independent process isolated from the webpage. The problem statement of of creatingÂ OffscreenCanvas and OffscreenCanvasRenderingContext2d interfaces withÂ OffscreenCanvas Constructor, propertiesÂ (width and height) and getContext() method was defined. The use of Web IDL to describe interfaces for web browsers was briefed and that was followed by the code flow and the code
problem There is no test plan section or any information on how or if the feature was tested.
problem Test plan missing.
problem No Test plan was provided
problem The write-up does not include a test plan section. If a test section had been included then the different scenarios, pre-conditions, edge cases and invalid input values would have been dealt.
problem The project didn't involve any kind of testing.
problem The writeup does not include any test plan.
problem The writeup clearly explained the need for the off screen canvas API; however, the explanation of how the feature was implemented was too shallow. What is in those .rs files?
problem The writeup includes the code used but it would help if the Wiki also explained how the authors came up with that solution
problem It is not explained why the work was done, the way it is done. But the implementation looks promising
problem The write-up did cover about the efficiency of Servo to render webpages quickly and smoothly when compared to Mozilla's other rendering engines. Servo does this usingÂ parallel layout, styling, web-renders and constellation and in turn sandboxes the processes,Â threads and tasks that allows the browser to fail better, hence making it more robust and secure.Â It justified the use of Rust to rewrite C++ and effectively the browser as well.
problem The writeup explains what is intended to be done. However, still the information is somewhat incomplete.
problem A test plan is not included. Although the explanation of the work is very well done.
problem Did a good job.
problem The units test cases look complete, but a bit more edge cases could have been implementedÂ in the tests.
problem Although they did not have a Test Plan but they had a section called project description which is the same as Test Plan.
problem There is no TestPlan section as such but why the test cases areÂ added are mentioned correctly. Could have given a brief summary on TestPlan.
problem Some are missing, such as delete, destroy and submitted_files
problem Code Climate has detected few blank lines and missing space
problem The functions are not too long and the code doesn't need to be extracted into separateÂ methods. Comments could have been added for a better understanding of the test cases. The code follows ruby style. The lines are compressed to reduce the number of lines in the code.
problem Code follows the Ruby Rails Standards, there are some comments by auto bots(spaces, blank lines etc), which if resolved would have been more better.
problem The class names, variables and methods are named appropriately. The variables suggest the functionality and their purpose.
problem There are few small spelling/grammatical mistakes, but the write-up is very descriptive and thorough overall.
problem The write up explains the units tests elaborately. However, the problem statement could have been explained a little more elaborately.
problem The authors did not use any design patterns. The write up explains the unit test cases and they are implemented in the code.
problem The features work as mentioned in the write-up. Edge cases could have been tested.
problem They haven't added any test plan but the test method in documentation shows that all test casesÂ has been checked properly and coverage is also 100%.
problem The pull-bots CodeClimate and TravisCI suggest there are a few issues with style and integration that need to be addressed, respectively.
problem Didn't find any pull request. Code coverageÂ has increased as more tests are written and it is one of the required outcomes. Wiki states that 100% coverage is achieved and the same is demonstrated in the video link provided.
problem Can't find the Pull Request
problem Most of the source code is following standard Ruby practices. However, some cases could be improved. There is a number of variable names that are concatenated with numbers for example user1, user2 etc. While this approach can be justified in some cases, I would suggest using more descriptive names instead or arrays if multiple instances are required. Moreover, indentation needs to be fixed to improve code readability.
problem The code is mostly clear and easy to follow. Test blocks are succinct and containÂ oneÂ assertion per block. One exception is the #score method. It could be improved by decomposition. The code for set up could be extracted into a separate before(:each) block and multiple 'it' statements could be usedÂ for testing expectations.
problem 1) No all functions are reasonably long if not too short. 2) No all methods seem about right 3) no but the team could have provided some comments in the score test function, as multiple expects are included 4) The code follows ruby guidelines and they used factories efficiently 5) Yes the code is DRY, they have used after each method to achieve it
problem Tried to run the RSPEC test by copying the _spec.rb file and enusred that the Factory method is inserted, I got an error in 2 examples Â Participant#email sends an email to the participantÂ Â Â Â Failure/Error: assignment = Assignment.find_by(id: self.assignment_id) Participant#score Get participant score within a roundÂ Â Â Â Failure/Error: scores[questionnaire_symbol][:scores] = Answer.compute_scores(scores[questionnaire_symbol][:assessments], questions[questionnaire_symbol])
problem yes all the test written passes. They could have written a test to check if self[:handle] is returned if no nil parameter is sent
problem Under 'tested methods' they have explained everything really nicely. The video is just to long, 22 minutes. You have have made it short.
problem Team could have given more description on what is the Participant.rb is doing
problem The wiki clearly defines the primary objective of the project and justifies the reasoning behind introduction of additional helper constructs like participant factory. The authors complement the descriptions of each test case with associated block of code and elaborate on the details ofÂ their inner workings. I would suggest removing parts like high level descriptions of Expertiza and Unit Tests (http://wiki.expertiza.ncsu.edu/index.php/OSS_E1852.rb#Unit_Test_Description) because they are redundant in this context.
problem The test plan section is really well written. However, pre-conditions, edge cases are not very well discussed and talked about. I would suggest the team to add these into the wiki as well.
problem Magic. How did they know they needed a Test Plan?!? They did a great job laying out how they created an environment to unit test Participant with their design choice, and chosen variables and factories.
problem The authors mostly focus on how they did what they did, i.e. inner workings of each test suite. Little to no discussionÂ isÂ provided on the overall decisionsÂ pertaining to design principlesÂ and patterns that have been utilized in this project. For example, there are no instances of before(:each)Â blocks in the source code. This decision could be discussed and clarified in the wiki page.
problem The team has not added any test cases.
problem No new tests have been written
problem No test cases / Test plans
problem Unfortunately, the test cases are lacking This could be improved before the second submission
problem There is no Test plan.
problem Test cases are not being taken cared.
problem There a large set of variables that do not follow typical ruby naming convention. An example is that "existAssignment" should beÂ "exit_assignment". Additionally, some names are not very helpful. For instance, the variable "frm" is used for a form, but why not just use "form"?Â There is also a lot of javascript written directly on the page and are difficult to read and understand as there is missing method names or other non-intuitive variableÂ names
problem The code is clear and concise. The variable, method and class name choice is correct.Â One variable i feel can be changed isÂ top_max_choosers can be renamed to topic_max_slots, as slots has been used in the function name as well and it will be more consisted
problem For the Ruby changes they have made, they have used intuitive names and used naming conventions as much as possible. def update_feedback Â Some places, the variable names are used in CamelCase whereas few places they werent used. Few variable names were directly used from legacy code, although refactoring could have been done
problem Most of the variable names and function names are named based on proper convention. Suggestion: function addCreateTopicSection()This function name could be changed to maybe CreateTopic() or AddTopic()Apart form this, all other names look good
problem All the variables are defined with respect to the functionality like - max_team_size, get_participants_without_team.
problem Ruby coding standard has been followed. Only one function has been added in controller as per requirement. Code follows DRY principle. TheÂ team can add comments for the code added which would be useful to understand the code.
problem def create function in assignments controller seems to be long and could have been refactored. Considering that they used most of the legacy code and most of their work was on UI, their part on ruby changes werent much
problem The team has written a concise and efficient code with proper implementation. However, some additional comments in some parts would improve the readability and make it easier to comprehend
problem The code is well structured. Could have added more comments for easy understanding of the code. The functions are not long.
problem Functions are of appropriate length and code is in proper methods. However, no comments are provided what so ever.
problem The group has not shared the link for the test environment. Hence unable to test the edge cases. However, in the screen cast they have covered the functionalities mentioned in the requirement document.
problem I have not been supplied with a link to manually use an instance with their changes and I have not been able to find a link in their PR or write-up.
problem I could not run it locally and hence I am not sure about the edge cases. Code looks clean and should not break in most of the cases
problem The youtube screenshare clearly shows the changes made and works perfectly. Since the edge cases arent defined, not sure about the functionalities of edge cases in this case as it involves UI most of the time
problem There is no link provided to test the code manually. However from the video provided, I can infer that all the features have been implemented and are working properly. Issue #718 and #926 are working as expected. In issue #971, I could see that the previous version of the 'add new topic' page had a topic description and topic category field which is not seen in the updated version. Suggestion: The team could implement that or if already implemented, add that to the wiki page to reflect the way in which that is handled
problem No deployment is provided, soÂ couldn'tÂ test manually.
problem I was able to understand the changes they were making and why, however I thought the write-up was a little too verbose and had too much code - I can find the code in their PR.
problem The writeup s format on how they distinguished the features and explained solutions for each and everything is good. First they give a bird's eye view of the problems and then deep diving into each problem with solution and screenshot is good. The background explanation given could have been more specific towards their problem statement, rather than just about expertiza. The images tend to occupy the entire page and its little difficult while going through it, a little foramatting could have made their page really good.
problem The write-up is well explained but could have described more on the methods whey implemented and why did it implementÂ in a certain way.
problem The team has not included any test cases. It would be easyÂ to include the test cases on theÂ Â app/controllers/suggestion_controllerÂ for theÂ update_feedbackÂ method that has been added. AlsoÂ the team may add some features test cases as most of the changes made are in html files. TheÂ team can referÂ the existing features present in theÂ .spec/features folder.
problem There is no explicit test plan section, but all the scenarios are covered with appropriate images.
problem Text Plan is Missing
problem There was no Test Plan
problem The writeup does not include the test plan as of now, but that is the only thing which is left for the team to complete. The team could work on this and try to improve the test coverage.
problem There is no test plan.
problem No test cases or test plan mentioned in the write-up.
problem They explained it well, but there were noÂ larger design patterns they seemed to be following. I did think that they used AJAX in the appropriate way, but it could be improved in the future.
problem Their solutions are well explained. The way they have explained, attaching a screenshot of a code snippet and telling, this is where we made this change, and this is how it works, gives a better understanding of their project. It could have been better if they could have compare and contrasted the previous codes, where the features where not there. That way, the background of the why this feature could have been clear.
problem Yes, the team has explained their code and the reason for the additions made. However, for the issue #926, some more information about the Tablesorter and some additional comments would improve the writeup. Solutions to issue #718 and #971 are explained clearly and are easy to follow.
problem Design patterns were not used. Rest of the code is explained and easy to follow.
problem Code snippets are given butÂ need explanation.
problem Writeup explains what was to be done and how they did it, but does not give rationale behind the way they coded, and any alternative approaches.
problem The test plan is not about what they test in the Rspec test.
problem Most of the naming is reasonable and follows standard Ruby practices.Â One problem is that code makes extensive use of variable names concatenated with numbers. Example: allow(participant3).to receive(:topic).and_return(topic) Here it is not clear what distinguishes participant3 from other participants and why it is special. It would be better to avoid using contractions such as stu1 or p1 (.sort_by_name method, Line 130). Furthermore, I would suggest using consistentÂ indentationÂ (for example .get_authorization method, Line 113).
problem The code looks clean. Though I don't understand why you have used this line in the test for responses " puts participant.response_maps". I feel some of the code that isntÂ needed is commented out. Please remove this code as it was mentioned in the details. Naming and cnventionsÂ seem to be fine.
problem the code looks clean . However, some of the comments are not provided for the test cases. apart from this the naming and the conventions seem to be fine
problem The test for sort_by_name redundantly checks implementation parts. It needs only to test the result.
problem CodeClimate bot reports 73 style issues, which is an awful lot.
problem There is no need to use the student3 and participant3.
problem The code is concise and readable. It consists of mostly small methodsÂ that test one thing. OneÂ exception is #.sort_by_name method where several assertions are made in one method. It would be better to use several 'it' statements and DRY out the code by utilizing before(:each) statement. One further suggestion would be to shorten the code by using one array statements instead of individual expressions. For example replace: stu1 = build(:student, name: "Student1") stu2 = build(:student, name: "Student2") Â stu3 = build(:student, name: "Student3") with: students = (0..2).map { |i| build(:student, name: "Student#{i}") }
problem Yep, the spec.rb file works fine. I think only handle method hasn't been tested. This is why the coverage seems to be 94%
problem Yes all the features work as intended. The participant that is created using the build method describes participant as an instance of the assignment participant class. I observed the handle method has not been tested yet.
problem Tests in the file pass, according to the video, but less than 100% coverage implies that corner cases aren't being handled.
problem No, the test failed.
problem Features implemented in this project work as intended. After running the code manually I am getting the same coverage as stated on the wiki page. One problem is that the main object under test - participant is createdÂ using build method. factories.rb describes participant as an instance of AssignmentParticipant class. There is a possibility that this is complicating test cases or will complicate them in the future. The solution is to either define a new Participant class instance in the factory or to define it in the code itself.
problem The Wiki is descriptive and covers the essentials of the project. In my opinion, I think the code for every test is not required. It is enough to explain the structure and code for one test, maybe and what each test is supposed to do for the rest of the tests. That should suffice.
problem Project purpose is write test cases for participant model and increase the test coverage. This seems to be easily understandable but plan of work should nainly concentrate on how we test this functionality rather than just mentioning that test cases need to be written.
problem The doc says participant.rb model isÂ changed. However that file is not currently committed. However assignment_participant model file is committed. Seems to be some mismatch at one of the places. Correcting it will help in understanding what work is done and how does it impact the functionality.
problem The problem being addressed by this project is defined cogently without any ambiguities. Test cases are considered separately starting with description of the given method followed by how theÂ functionality is being tested. I would suggest removing parts like Expertiza description (http://wiki.expertiza.ncsu.edu/index.php/User_talk:Rshakya#Expertiza) and rationale behind using Rspec (http://wiki.expertiza.ncsu.edu/index.php/User_talk:Rshakya#Unit_Testing_with_RSpec)Â because those parts fall out of the scope of this topic.
problem The test plan does not include details on preconditions or edge cases. I suggest the team to elaborate on Test Plan. Otherwise a good start.
problem Test plan is not included however they have included the diffeedif test cases implemented and the exolaexplan is good.
problem A more through explanation of what each testcase does will be useful. Its documented well about what the testcase will return but not what it does. Mentioning that will be useful
problem The test plan could be more specific. For example "Writing testing conditions for different functions" doesn't indicate what strategies are being employed or what edge cases are being tested.
problem The document states they have a 77% LoC coverage, but the assignment description states they need at least 90%. This is not complete.
problem Scenarios that are discussed in the wiki have comprehensive descriptions and justifications. However, clearly a number of edge cases are not considered as the test coverage is ~77%. Â I would suggest using mock objects which will both decouple tests from database and increase the overall coverage.Â For example mocking find_by method of TeamsUser would allow covering participant#team case: allow(TeamsUser).to receive(:find_by).with(user: student).and_return(team) Â Another minor issue is that wiki is missing some cases that are implemented in the code (#team, #fullname, #scores).
problem They have mentioned that they use "factory", but it hasn't been mentioned clearly how they use factories. It would be great if they can incorporate this in the Wiki.
problem The writeup explains why the tests they write relate to their respective methods, but doesn't justify a 77% LoC coverage, which is below the requirements for the project.
problem Authors describe the strategy they utilized for tackling theÂ project and the detailed mechanics of each test case. However, there is no mention of specific design decisions or patterns that were used in the implementation. My suggestion is for the team to elaborate on technical decisions made for simplifyingÂ test cases for example the majority of mock objects is created at the beginning before every 'it' statement.
problem The test plan was not present. But the team have done a good job in implementing tests.
problem The test cases have been developed into automated tests however edge cases or failing cases have not been considered. Only simple and straightforward scenarios have been tested. The video shows the test cases and the document shows the coverage. The document is well made.
problem They did not have a Test Plan.
problem Class and variables are name correctly. get_bookmark_rating_response_map is an not an apt name for a function. The word bookmark can be omitted in function and variable names inside the bookmark controller. .when a student requests a bookmark it should show a bookmark test is failing
problem All methods and variables are suggestive of the functionality. Only some of the code changes are explained and reason of taking a particular problem solving approach is lacking.
problem Build fails, pls look into it.Â BookmarkRatingResponseMap has been replaced by BookmarkRatingQuestionnaire but the earlier naming convention just by looking at the name let the reader understand the data structure being used. I would have liked similar approach here.
problem Use ofÂ a few variables is hard to understand. For e.g. :Â x.assignment.id Otherwise, most variables and classes are aptly named.
problem The code follows most of the standard practices except the 3rd one. It does falls short of comments. It took a very long time to make sense of what the changes made by the author in a particular file does. This scenario could be improved in the future iterations.
problem More comments are needed because I had trouble following what the code was doing in some places. The code follows Ruby Style Guide and is DRY in its design. Functions are small in size and naming conventions have been followed. Good work in this area.
problem Function names look good. And most of them have len < 20 which is good.Â The tests make use of contexts effectively. This is great to see. Â Â Yes more comments are required especially in the controller code telling why an approach was taken and what the function does.
problem Code is clean and variable names are readable. Need a bit of formatting as some lines are not 'aligned' well.
problem The code is well written, follows ruby guidelines and functions are of appropriate length. Â No comments are provided what so ever, making the huge code change very difficult to follow.
problem Cases mentioned seem to be working fine. Can be a bit descriptive about the steps though.
problem The features work as intended however I am having trouble navigating and checking what are the differences between the original system and the improved system. Could have made a demo video showing the improvements or a step guide to follow.
problem Yes.Â I suggestion, since they deployed the code and video, it would have been good if they put a view of the UI usage similar to what they have put as screen shots in the code.
problem The write-ups been written well. A small suggestion to the team would be to explain their solutions in more detail as it would better the understanding of what the project does. Also the team could use code snippets instead of screenshots of the code.
problem The writeup seems apt. I had a little problem understanding the solution to problem 1 but otherwise it seems fine
problem The method names and variable names are very well defined ! The best I have seen so far ! No clear explanation is given as to which files are edited for which reason. Only file names are stated along with changes made. Why the changes were made and what do those changes correct is not given.
problem Write up is good. Great job. However I could find few points that if rectified would make it even better.Â It would be good if the problem statement could list the issue (hyperlinks) that are being fixed. That would make it easier to navigate Instead of pasting screen shot for solution it would have been good if few words detailing approach would be put. Post that screen shot could be put.
problem Write-upÂ clearly explains with screenshots what is done. However, does not say how the changes have been implemented.
problem The test plan is not there.
problem The Test Plan was comprehensive. However, in the video they could have explained which screens and which methods they were testing instead of just showing some test cases pass on the screen.
problem Yes they have a test section. The amount of coverage added for the new tests is great. Keep it up, however I would have liked that the authors added more negative cases as part of t heir unit tests.Â I see mostly the +ve test cases being handled in the tests.
problem The writeup is well written. But I feel there are some missing details about the project. The team could elaborate on the issues in the project and the solution that they have implemented. This way it would better in understanding how and why the authors did the work that they did.
problem It mentions what they did but doesn't highlight why they chose to implement that way. Don't seem to have implemented any design pattern as well.
problem The writeup expalins clearly enough what the authors did. Though, the part of "Why" the authors did what they did isn't elaborated with much depth. From the authors perspective, the articles seems exhaustive and comprehensive, but for a person reviewing the article, who doesn't have much background of the problem at hand, the article make it tough to decipher why certain program is written the way it is.
problem The authors do not explain why they did the word the way they did. Entirely new pages have been created with no indication as to why those pages were needed . Old redundant code has been commented but not deleted. Naming and code pattern wise, very good job.
problem Writeup does not mention anything about how the code works, alternative strategies possible or strategies they used.
problem The write-up only tells what is to be done and how it is done. The rational behind choosing the approach is not mentioned, neither are any of the principles mentioned.Â It has comparisons between the previous and new versions and why they made they made the necessary modifications.
problem No. I think the authors should have mentioned why a particular solution was taken. What was the main driving force for taking the approach that they have taken. This was entirely missing. Pls work on that. They could also remove much of the commented code.
problem I didn't find any information about how and why they did the work, they only show me what are the issues and the results after they fixed these issues, for example, in problem 2, they told me their is an average rating metricÂ bug and they fixed the bug, but they said nothing about how they fixed the bug.
problem As given in wiki for their test plan,Â The admin tests include building and deleting both Administrator and Instructor accounts using Capybara for testing the front-end web functionality. it 'delete instructor successfully
problem Build is failing. Correct it by understanding the reason. Good job on Ruby standards for the naming convention.
problem Functions are not long but are sufficient enough to understand what changes are made and how they are implemented
problem methodÂ remove_instructor is written twice in the same file, delete it.
problem The code works well for edge cases as well. As they mentioned in the wiki sometimes the app throws an error (in English or SQL). It would be nice to know if they could debug a little and find out in which case the SQLException is thrown and in which case the English (handled) error is thrown.
problem The test for each functionality is written. However,I could find only 2 tests running , that too not with satisfactory results.
problem The document clearly explains what was the problem and what was the solution they proposed.They have also compared and contrasted with the previous solution which is good. They have talked about how different roles come into play with respect to security perspective and what the pros and cons of having/not having those roles. Comparing the code changes gave a clearer view of the code changes. One improvement could be in the 'background' part.Â Taking it as it was: The majority of the project was related to solving issues regarding the deletion of Administrator and Instructor accounts. Administrator and Instructor are both account types that inherit behavior from User but are (1)handled and deleted in different codepaths. Furthermore, properties are used on a User that aren't on an Administrator, (2)such as team ids or course associationsÂ <
problem The test plan is missing in the wiki page. The content in this section could be the one suggested in the above comment, to just include all the test cases added and write a brief description about each.
problem The writeup explains how the changes are made but does not state about design patterns used and the code dose not show any use of patterns
problem All the cases in Test plan are included in the automated tests.
problem The writeup clearly explains the issues and the approach used to achieve the desired results. Suggestion: The authors should try to include the rspec test documentation, for the newly fixed issues.
problem The writeup does emphasize on how the issues are resolved, however lacks a reasoning as to why did they choose it.Â Suggestion: It is hard to follow the code, as there is lack of comments. You can try to include meaningful comments for every function you have introduced. That will increase code readability
problem The code is readable and no function is too long. Suggestion: The impersonating_as_admin? and impersonating_as_ta? function uses the same session variable, so you can try to declare it above these functions and reuse it to follow DRY principle
problem The names are very intuitive and one can easily understand the reason for each of the variables from their names. In addition the test coverage has increased however it is not very good.
problem The test code follows standards. Context messages can be shorter and precise.
problem The test cases are quite illustrative, however they have not been automated.
problem The link to the deployed application was not available.
problem Except the comments, everything seemed to be fine. The code seemed to lack proper comments, and as a result of which, it took several seconds to determine why the author did what he did. Apart from that, the code seemed perfect. Functions were sufficiently long, and code was DRY enough too.
problem They have added new test cases and hence code is not DRY.
problem The team should add more comments for the codes include in the two issues, it is a little bit hard to follow what the author want to do without comments.
problem The wiki is well written and contains all required information regarding the project. The only scenario missing from the documentation is the scenario where the TA is assigned to a instructor , what will happen to the instructors impersonated students when the TA of the constructor login to the application. Apart from this , the team did a great work.
problem The write-up contains the information about how the solution was achieved. The details about why the solution was implemented in this way is currently missing from the documentation. The team should include the same in the documentation as well.
problem all the scenarios are explained in detailed. The only edge cases which is missing from the documentations is: the scenario where the TA is assigned to a instructor , what will happen to the instructors impersonated students when the TA of the constructor login to the application The team should this scenarios and include the same as the part of the documentation and automated script in the test plan.
problem The code contributed by the author contains long functions which are adequate and consistent considering the amount of task that is carried by each function. The team could improve upon the comments to enable high understanding of the flow of code written. The code does follow the Ruby style guide and supports the DRY principle.
problem none of the functions are too long could find changes where DRY principle was violated the code follows ruby convention and guidelines Although the code is easy to follow, the comments should be included for the created methods/changes. apart from that Good Job!
problem The authors work seems to work fine in theory. But unfortunately, the link provided by the author does not work, and hence there was no way to manually test it. But the demonstration video provided was a big thumbs up.
problem all the basic scenarios are working fine. No issues or problems were found with the functionality. There is an issue related to the CI built which is failing at the moment. The team needs to analyse the root cause related to the build failure and fix it. Also the scenario where the TA is assigned to a instructor , what will happen to the instructors impersonated students when the TA of the constructor login to the application. The scenario could not be tested as the same is missing from video and the application is not deployed. Other than that it was a great team effort
problem Deployed link is not worKing
problem The link is not up. Could not test
problem The URL is not working
problem The writeup was clear enough to be understood by anyone familiar with developing or contributing on expertiza. It provided a high level view, and then dug deep into implmentation, which is great since it saves time, and also look concise. But for someone outside the domain of expertiza, it feels too sudden of a transition that it takes time and in many cases other resources to figure out why the author did what he did. But the overall flow and structure was very great.
problem Excellent writeup. The instructions were clear. The screenshots were apt. One suggestion: Could be shorter and precise.
problem The description for the first issue is confusing, I am not very sure about what the function of the old version looks like. I am not sure what mean by the instructor under the instructor.
problem Yes, the tests are thorough. Needs some formatting in the code.
problem The writeup provides a gist of the project implementation stages. Though it does specifically include a test plan section, it has the list of tasks performed while testing for various scenarios as a part of the issues to be resolved section.
problem Yes, the writeup explains explains how the authors did their work and they have mentioned the steps behind each functionality. Design principles are not used but overall quite nicely explained.
problem The team has explained how to fix the issues but not clear enough, it is confusing what is each pre-existing methods they have used done and why these methods were used.
problem They did not write test code.
problem The test plan could have been explained more elaborately. Edge cases could have been covered.
problem The functions are not too long and the code does not need to be extracted to separateÂ methods. COmments could have been added for a better understanding of the code. The code follows Ruby lines and the lines are compressed. for eg : Unless and if statements are compressed
problem Test plan could have covered more edge test cases. the test plan mentioned in the write up are executed.
problem Edge cases could have been implemented.
problem The authors have documented the steps they did to solve the issues in a clean manner. Although they haven't mentioned any particular design principles or design thinking that went on in solving the issues. They have explained all the functionalities of each file they have modified and stated why they have modified the particular file. One thing they could have added were class diagrams and dependency maps. Or some pictorial representation of the flow of each task which will help the reviewers and instructors to quickly catch up on their idea.
problem The code seems to follow good Ruby on Rails Coding practices. The implemented code is DRY. they could have increased commentingÂ by making comments more descriptive.Â The comments for say a particular function could have includedÂ the input arguments, their data types and the return value and its data type if any. But overall it looks to be good commenting coverage.
problem The write up is good as I was able to understand the issue to be fixed and the implemented approach.Â I would like to suggest the team to standardize the size of their screenshots though.
problem The write-up explains what they did but doesn't mention why they choose to implement the feature this way
problem Although the test plan looks good, I am not able to see any test cases added in the pull request.
problem They don not have any test plan, So I can not judge it
problem The team has added test case for just one scenario. There is no test plan. It is advisable to add more test cases for all the methods in the sub classes to check if the existing functionality is not breaking.
problem The test is explained with the file used in the tabular form. It would have been good to attach a screenshot of the test if possible.
problem No automated tests.
problem Test case has been added, however no way to test it.
problem They discussed just 1 test case and did implement it. Some more corner cases can be thought of.
problem The query is well mentioned but I would suggest the sql be mentioned in the below manner for code clarity. Select ... From table name where condition;
problem Almost all variableÂ and method names are well-defined. Suggestion: Try to refactor method 'render_report' in module ReportFormatterHelper by using hash instead of really long case when statements.
problem review_response_map - can be modularize. Extract the various finction and write new methods for each.
problem Really nice-code with implementation of strategy pattern. Code follows DRY principle However, render_report method is long.
problem the code is well written but few more comments before every functionÂ could have made it easier to understand the code.
problem The features do work as per the mentioned functionalities. There are some suggestions mentioned and would be good to include test cases for the same in future.
problem No link provided of the deployed application or screencast video where I can see the changes done.
problem No link to the application or a screencast of manual testing. Â Suggestion: You can try to add screenshots of the testing performed and attach it to the writeup
problem Yes, the wiki does explain the functionalities well. Could have been better to have more attributes in the subclasses in the diagram. This could help the user know about the details of the strategy pattern used.
problem Doesn't contain the snapshots of the code that was changed.
problem The team has not included the test plan toÂ explainÂ the end user about the steps for testing the functionality.
problem The test is added under the Test Added section and is well explained under the tabular form. Could have produced a screenshot of the test, if it was a possibility to generate. This helps the future teams to know what kind of test result to expect.
problem Just contains the test name and file name. Doesn't show how the test was done and the output obtained.
problem Edge cases missing from the test case. Write more test cases with invalid input types. Example - give a string to an int type and raise an error accordingly.
problem Since the project involved deletion of obsolete methods and SQL, it would be good to explicitly state in the test plan if there were any tests previously that used these methods/SQL. Also, if they are present they need to be modified.
problem Authors have converted test plan into an appropriate test case. Suggestion: Â The authors can improve the writeup if they elaborate more on the testing approach used for the newly added code.
problem just one scenario has been tested and couldn't see any further test plan documented.
problem The team has done great job by describing the approach and explaining same in detail by adding a pictorial representation of the pattern used.Â However, it would be more helpful if the team could add details about the names of the classes and the exact code changes done in the wiki page. As it would help anyone in future to understand what are the exact changes implemented. In this way the comparing code with the original code in github can be avoided.
problem Yes very well written. I would have given full marks if you would have added code snippet and screenshot of the before and after feature. Visually it would have been great to understand the changes quickly.
problem It would beÂ good ifÂ the functionality of the obsolete methods(that were removed during the refactoring) is mentioned; and also explain why they were obsolete.
problem There aren't any test cases listed in the writeup. Can explain the test cases a bit in the github commit message.
problem Test plan not included
problem Testing has been done well. Testing could have been more extensive. Currently the system only tests if the responses are correct for proper input. Blank or no input or failing cases should also have been tested.
problem No cases were mentioned in the Test Plan hence could not tell it is converted into automated tests. Please elaborate it.
problem As stated above, the writeup has a missing test plan which could be added by the team for the second iteration of the submission.
problem Couldn't see any testing being done.
problem The team has modified the existing test cases to cover the new changes made. But this is not detailed in the Test Plan.
problem Naming looks fine. Could probably have usedÂ is_submitted? instead of is_submitted.
problem All methods and variables are suggestive of the functionality. The vm_question_reponse table could have been named/edited to be named in a more descriptive way. I do not understand what is the meaning of VM.
problem Everything looks fine, except for a few places where there are issues with indentation.
problem A small suggestion , new_feedback --> author_new_feedback The variables, methods and class names are aptly named. I could not find names which are not suggestive of functionality.
problem All the names are reasonableÂ except for a few like the function name "get_feedback_assessments_for". It is ambiguous as to what the function will be doing.
problem grades_helper.rb:62 The parameter id is not descriptive enough. Please consider changing it to be more descriptive.
problem The code has comments at the beginning of the functionality. Could have added some more comments where the functions are larger for followup. Can add why a certain change in the fetching process was made, so that next time it can be referred while coding further.
problem More comments are needed because I am having trouble following the code. The code follows Ruby Style Guide and is DRY in its design. Functions are small in size and naming conventions have been followed. Good work in this area.
problem The team has done well to follow the Ruby Style Guide and has ensured to keep the code DRY. However, my suggesstion is to add comments in the code for the reader to follow the code easily.
problem The comments were sparse. Maybe, coming up with a few words before every method would make the project more understandable.
problem The code seems to work for basic required functionality. Need to add more number of edge cases with test results where there is a possibility of a failure and a look into the work around is required.
problem The author's work runs smoothly. It could have been better had they provided a short demo video. I could not figure out where were the changes made in the system. They could have written the navigation steps. Directly giving the flow without any context is tough to understand.
problem I would only suggest you to add more comments to your code. I know that no comments were previously added for you to feed off of, but I guess a major aspect of these OSS projects is to add as many comments as possible to the existing code.
problem Functions are really small and absurd. Does not go along Ruby Style guide.
problem Could not do the manual testing since the link mentioned did not work. But, the code seems good enough to work.
problem The deployed app on VCL doesnt work. Their testing plan on wiki is clear, although their app is not deployed / screencase is available, so not sure how to test the functionality.
problem Difficult to test and review the work one since there were no screenshots provided. I was not able to find an instance of a review which could be submitted as a team but not by individual members of the team. Some of the webpages crash after clicking on a particular assignment to view the review report. Suggestions: The team could explain steps to access the "review view", so that manual testing could be done. The team could create dummy assignments for testing. Maybe, adding screenshots would help in the process.
problem The Test Plan is not complete.
problem I think their introduction and issue sections clearly shows whatÂ functionality the work is related to, they also add some screenshots which help me understand what they have done. But I can not understand what is bookmark and what it is used for, I think it is difficult for someone like me who have not used bookmark to understand these with only a short description. If they can write something more about bookmarks it will be better.
problem Test plan is included in the Writeup section. They have explained about the basic test cases and how it is implemented. Edge cases, invalid inout values arent explained in the writeup.
problem I can not see any test plan section in the writeup.
problem Not completely clear
problem The writeup includes some of the work done.Although it looks a bit incomplete and does not convey much about the project.
problem The explanation is quite good to tell what is the current and the required functionality. The screenshots placed are not complete, as in they cut the code at the right end. Instead I would suggest to placed the github link to the code changes, so that the wiki becomes shorter and you can explain each code change better in the wiki. Also, the reviewer can compare the code with your explanation properly if he has the link to the code.
problem The write up is okay but could be a bit more descriptive. Could have provided screen shots of the changes to help reader understand better. No initial instructions on where to get started.
problem No clear explanation is given as to which files are edited for which reason. Only file names are stated along with technical changes made. The method names and variable names are very well defined ! Kudos!
problem Code snippets are provided but the functionality that was to be implemented and how has that been achieved is not explained.
problem This project is on implementing a single rejoinder per team for reviews instead of per participant reviews and also makes the feedback link for reviews more accessible. The writeup explained the background about Expertiza and the motivation for the project. It then moved on to list the tasks that were implemented and files that were modified in the project. It showed the current and new implementation clearly. The writeup, however, could have quoted the tests done using RSpec and the UI, instead of plainly mentioning the that the tests were modified to suit the current implementation.
problem I was able to understand what the project does to a certain extent. The writeup could have been more eloborate with views/snapshots of the page before and after the changes.Â It adequately indicated what functionality the work is related to.
problem The team has mentioned the problem statement and the methods which they have implemented to solve the problem.Â However, there is a difficulty to follow the workflow since there are no screenshots attached or any video link provided. The team could improve this by adding a screenshot of the updated workflow below the changes shown in the writeup
problem The team has written a well structured write-up, but it lacks depth in certain areas. There is need for more background on what an author feedback is. The project description gives a better idea. Please try to include details from there. The last sentence under the 'Motivation' head, "You should change this to list the teamâ€™s collective feedback to its reviewers to a particular assignment" is a bit confusing. Please rephrase the sentence so as to add clarity to it.Â Â Instructions on how to manually test the functionality is missing. It was difficult to figure out how to navigate to and test the functionality. It would be really helpful to add this in the wiki.
problem There is a separate testing section in the writeup, but it does not have much explanation. Could have added a couple of test case explanations. Also, a screenshot of a passed test case could work wonders.
problem Test plan not included.
problem The authors have considered various preconditions but edge cases are not tested. No test plan has been provided. Some tests have been edited to meet the new requirements. Many conditions have been checked using 'if else' cases which could have been more elegant.
problem The test plan section just states that the existing test cases for feedback per member is fixed to satisfy the new feedback per team implementation. It would have been effective if specific pre-conditions, edge cases, invalid input values etc are handled. For example, in this case the input with missing team id or one member teams can be used as good candidates to test the implementation.
problem The test plan does not look complete. It just saysÂ Fixed the existing test cases for the review feedback by a team instead of a team member. Could have mentioned the edge cases and how they tested it.
problem Just aÂ one-line summary has been provided about the testing but it is not clear what the test plan is.
problem The authors have just mentioned that the test cases were updated. It would be good if the code diff for the test case modification were also provided so that we get an idea about the kind of changes made.
problem The writeup mentions about the changes done in the code but not how and why it was done. Instead, the team could explain each code change more and give a link to the code change(from github)
problem They have provided code snippets explaining what they did. No design pattern used or specified.
problem No mention is made as to why the changes were made in which specific files. A few lines are given before each image but they are too succinct to understand anything. The code is well written but hard to follow (what is the functionality of the code is tough to decipher). Code is well written.
problem No, the write-up doesn't describe why certain methods were chosen and written the way its implemented.
problem The functionality provided as a result of each issue is not explained. The way of work or design principle is not mentioned.
problem The writeup clearly explains the project- a single rejoinder per team for reviews, but does not explicitly say the advantages of having such a system. On the other hand the authors do justify the need to fix navigation issues for giving feedback to reviewers as it results in a user-friendly UI. The modification to summary report to accommodate collective feedback is logical and directly implied if the main problem statement of single rejoinder per team is properly justified.
problem Could have been more eloborate. No mention of design principles or patters used.
problem The team has explicitly mentioned the classes and the name of the files where they have made changes. However, i would suggest the team to add the filenames above code snippets that they have attached in the write-up. This would make it easier for the reader to follow the workflow.
problem The classes where the changes have been done are mentioned. However, it is unclear as to why those classes have been changed and the real pattern behind picking those classes or methods.
problem The write-up has detailed how the author has done the changes. But it fails to address why the particular direction was taken, in some cases. It would be good to elucidate on that as well. In ' Solutions Implemented...' section, it would be good to include the names of the files before each code snippet and not just the description so that it is easier for the reader to relate.
problem The test cases are cleanly written following good practices. Some of the indentation needs to be adjusted to contain better readability. Also, within the menu_rpec file, you are essentially testing two classes Node and Menu. I am not sure why that is. Is the node class and inner class of menu?Â Maybe these two classes should be separated into different rspec files to ensure a better naming setup. Maybe this could be clarified in the wiki so that readers would understand the design choice. Overall great work.
problem Most of the codes are well strutted, but something like "returns an equivalent item" is long and it is better to separate them.
problem all the tests are working properly except one. A pretty good work has been done.
problem The team has introduced the functions clearly, but it may be better to also include the introduction of expertise itself. Besides, the motivation is general, add some specific details for this project would be better. As far as I am concerned, for the functionality of the menu, the introduction is also a little bit general. Adding more details about what the function of the menu, so we can know clearly what should be tested and if the test is enough.
problem The test plan describes the flow of the tests and what the expected values of the objects should be in certain scenarios however I didn't find any mention of edge cases or invalid input values.
problem The overall purpose of the project, the need for mocks/stubs, and the scenarios of each test case are very well presented; however, there is little explanation about why certain tests were implemented in any particular fashion. It would be aÂ nice addition to include a few of your test cases and explain your reasoning behind why/how you implemented that test case. Adding this would further clarify your design/testing plan choices and make for a fantastic read.
problem The wiki give the motivation for this project, but it is general and should be more detailed for this project.
problem They are done with one of the Test Plan scenarios. Second one is yet to be done.
problem Test cases are not part of requirement spec.
problem Test plan is manual. No RSPEC files included.
problem No test cases is included in test plan.
problem Testing plan didn't outline what the automated tests were or how it is done.Â The video showed the features being fixed. Also the hosted expertiza site was not working.
problem No tests added
problem Not many functions defined. Only database changes made and inbuilt function used.
problem Please make sure code like puts X is avoided. Remove them and commit the code again. Builds are failing. See the TravisÂ CI build details andÂ code climate errors and fix them
problem One failÂ Two successful.Â Over all coverage increase is 9.9%.
problem Function, variable names are ok but there were ruby coding style issues like not using elsif blocks, not keeping code concise andÂ not following ruby syntax.Â Scripts for converting non UTF-8 files is a good approach.
problem Not many functions defined. Only database changes made and inbuilt function used
problem ConvertÂ ifÂ nested insideÂ elseÂ toÂ elsif. Unused variableÂ key inside remove_non_utf8 method.
problem Code had a few guideline misses which was noted and suggested by the automated tool on pull request.
problem 1) No, function length is good 2) No. they are apt. 3) comments are not included, which makes it hard to follow, as the changes are not regarding functionality rather than system implementation, comments should have been elaborate and detailing why the change is done 4) Yes they did 5) No. the code was DRY and reused efficiently
problem Cannot test the code as the application is not opening and the videos uploaded are binary files.
problem http://152.46.18.195:8080 Â is not working. Also, the video is not running, Please upload in youtube.
problem No work shown.
problem The written explanation is good. Add few screenshotsÂ of the change to be able to understand the changes done visually.
problem Yes it explains with clarity the issue at hand, UTF-8 only support & how that causes trouble. Also improper formatting of HTML tags.
problem The document directly dives into issue, they could have provided more information on different scenarios that are currently facing the said issue and its magnitude. This could have been helpful to counteract the problem in the future in other scenarios
problem As explained in the test plan, rspec test is not implemented.
problem No, one of the functionalities of the Test Plan is not yet done.
problem Testing was not part of the requirements. Team did manual testing.
problem No there is no test plan included
problem The write up does not mention any patterns if used, and could not identify the pattern from the code as they have made changes using the database and not any function
problem The folders/binary files in the drive cannot be played. Can you upload the video on YouTube so that it is easy for everyone?
problem Yes, it does explain but could have added more details to make it clear.
problem Though they have detailed their approach on DRY, they haven't documented the core issue beyond non UTF-8 not accepted. Its hard to follow their scope as only review or entire expertiza use, as the table alteration is done as a whole
problem Yes, the writeup explains the problem statement the solution implemented. But snippets of code not added and screenshots missing too. Too many github links. Could just add some snippets to make it more readable.
problem The test coverage has increased significantly from like one test to 100%. Kudos to the team!! The team's pull request hasn't passed due to inconsistencies in following Ruby styling guidelines.
problem Proper naming conventions are followed for variables and methods and classes. The only thing I think can be improved is dummy names for files and hyperlinks.
problem There are some duplicate codes could substitute with "before" statement. For example, line 100 are exactly the same with line 108, it is better to use "before" even if there is only one line duplicate.
problem Overall the team has done good job in maintaining Ruby Style guide. The team could add more comments and reduce code redundancy in scores() method.
problem I feel that they have achieved a 100% test coverage, although the design principles or patterns used haven't been listed. Listing that would help understand the testing strategy used.
problem Since it's a test project, there are not much design patterns to follow, but they should list what tech they used to test the rb file.
problem The authors mention that they have followed DRY Testing practices but there are few test cases where they have notÂ implemented it. For example scores(questions) method. I would recommend to make the use of factories. Overall well written test cases.
problem The writeup is really nicely written. It clearly mentions the work done. However, the problem statement could have been explained a little more.
problem The test plan is too elaborate and doesn't exactly cover different pre-conditions, edge cases, invalid input values, and other possibilities under the corresponding headers. Please include this as it improves the readablity and understanding.
problem They have a very detailed Test Plan section where they explain every method and whatÂ they did. They don't talk about pre condition or edge cases or invalid input or things like that
problem The test plan seems to include examples of tests and the explanation of the same. However, I didn't find any description of edge cases or invalid input values.
problem The test plan section is really well written. However, pre conditions , edge cases are not very well discussed and talked about.
problem The Wiki has all the relevant information though I feel it needs to be a bit more organized. The titles and order need to change. The content needs to be placed at proper places. For example, test plan lists all the test cases and code, whichÂ according to me should be covered in the implementation.
problem The wiki talk about what they have done throughly, it could be better if they have mention about how they do that.
problem The test cases are working. The coverage also as i can see is 100%.Â I could find only one test for which the edge case failed.
problem There is no Test Plan yet implemented in the wiki documentation. Be sure that when you include this section that you make the inclusions specific and intentional.
problem The team has not included a Test plan that models their tasks for running the test cases. It should list the overall procedure adopted by the team from scratch to getting the tests running.
problem I am unable to find the file review_response_map_spec in the github repo that was supplied. However, there was a ruby file that was attached in the submission. The variable names are also clear and unambiguous. This file is incomplete but the tests that are complete seem to follow appropriate syntax and guidelines. I would suggest to add some describe and context blocks that would clarify the purpose of each test case rather than just have the it statement saying the name of the method being tested. Keep working to finish up the remaining tests in this fashion and it would be great.
problem inÂ test file, you can give one more line of it, for each test to describe the purpose in a little more detail than just the method names.
problem The functionality added to the pull request is reaonable and makes use of appropriate keywords. It could be improved by giving names according to convention like feed_ back_ review_response_map could just be feed_back as jt is part of the review response map model file.
problem There are 7 issues pointed by the auto bot which require code to follow coding standard.
problem The code seems to set up a large list of factories only to then in many cases make these redundant by creating mocks for each test case. It is unclear what the code is trying to do and many of the test cases are large with many mocks with stubbed methods. It would be helpful if explanation for the code was given. When using factories it is generally unnecessary to stub the all the methods of these factories as they are in fact actual instances of the class. The code not very DRY. In many the cases the mocks and stubbed methods could be moved to a before_all or before_each block.
problem Except the lack of comments in the code, the code seems to be perfectly fine. Could be improved in that scenario.
problem As mentioned in the above comment, Add these describe and context statements to further comment on the purpose of your test cases. This makes it easier to understand the why the test is there, I also find that it helps to clarify to the developer that the test is necessary.
problem ForÂ nil input test, they should separate them from the normal input with a new test, instead of put them in one. some missing invalid input testing, such as import, export methods.
problem The code written by the team includes the basic functionality needed to run the test cases. Some improvements might include keeping a function short like diving the import function into multiple contexts or reducing reduntant code by using the mock built.
problem Many tests are not yet implemented. More testing of the author's work in handling edge cases will be done in round two of reviews.
problem Not possible to test work manually.
problem I cannot find the code
problem Some edge cases are missing, so I assume most of them work.
problem Manually ran the Test and Coverage report says only 34% of Code is Covered
problem I believe the wiki is not complete. However, the content that is included so far does aid in the explanation of the project purpose. More elaboration and completion of additional sections such as the testing design and implementation of tests will help to fully clarify the project purpose to the reader.
problem They may misunderstand the meaning of test plan, they just put the code on test plan, so i cannot judge weather they are success or fail.
problem Not all i can see only some of the methods being covered 61% approx
problem The Test Plan is not defined formally in the wiki. Instead the reader has to reason about the provided code itself. All of the tests are passing, but methods like 'review_response_report' and large part of 'import' are not covered.
problem The writeup is sufficient in itself, but not as exhaustive or easy to understand from the perspective if an outsider. The author could have elaborated more on the problem statement, and how it related with expertiza. Also, instead of directly jumping to the implementation, the author could have explained a little bit more about why and what was the approach taken by the author.
problem The functionalities are working fine. The describes in the tests could be a little more verbose.
problem Can not find pull request link.
problem I can understand what the project does. I cannot, however, understand how the project does what it does. The code is not explained at all.
problem The Write Up can be improved by explaining all the Methods which are tested
problem The wiki document for the project does not provide enough details about the project and the task performed by the team. It contains of only a rough overview of the project at this stage. It does not reveal much about the functionality of the program.
problem There is not a specific Test Plan section in the wiki. There is a Work to be Done section that discusses the work that should be completed for project success. I would suggest rearranging or rename this section and continue to describe your plan of attack for testing.
problem I cannot find the test plan.
problem There is a section titled Test Plan. However, it does not seem to be a plan or give an outline for the development of the code. Instead it describes what the methods do, but shows the testing code for the method. This is confusing as no explanations are given for the coding design.
problem The writeup does not include the Test Plan section. It is suggested that the team add the section and include a number of different aspects such as specifying the edge cases and preconditions considered while working on the test cases.
problem there is no explanation in the writeup.
problem Little explanation for the code is given. The only case in which code is explained comes in the section titled Test Plan under the subsection Mock Instance. Here, it is mentioned that the project uses mocks to aid in testing functionality. However, the code example is actually of factories, a different but related concept. It is unclear if this is a typo or a misunderstanding because in later code snippets mocks do appear.
problem The writeup lists the task to be performed under the Work to be Done section. It enlists the criteria required to be achieved as part of the project submission. The team can adopt a workflow that can give details about how the team managed to reach the current implementation such as understanding the files involved, steps taken for setting the expertiza environment etc.
problem covered all the edge cases but have not provided any explanation.
problem ThereÂ are some instances of variable names that are concatenated with numbers, for example answer2, questionnaire2 etc. While this approach can be justified in some cases, I would suggest using more descriptive names instead or arrays if multiple instances are required. For example team could be used instead of team1 because that is the only Team instance variable in the source code.
problem I did not see pull request
problem The code does follow all the standards and steps to cover all the test cases. Could include some more comments to make the code self explanatory.
problem the code does follow the ruby style guide.
problem Their code is good, but some of them are too long.
problem The source code is mostly following standard Ruby practices, but there is a room for improvement. Firstly, the source contains large chunks of code blocks that are commented out. I would suggest removing those chunks as they reduce the overall readability. Given chunks can always beÂ retrieved via commit history. Secondly, some application level objects like Answer or Criterion are used to create corresponding instances as opposed to mocks. It would be better if the authors either used mocks or provided the reasoning for this decision.
problem Yes, their code works pretty good, but their coverage is a big problem.
problem Code is nicely written and runs well. However, more edge cases should be included. For example, each function should be tested for a known success case and an edge case or potential failure.
problem Running the code manually resulted in 69.61% coverage. However, there are four methods that are in a pending state.
problem The coverage could be higher.
problem The wiki looks too long with a lot of code. It does have all the code and test cases, but its better to have git links to each code and more explanation of the code used above it in the wiki. This will help the readers to compare the changes in the code with the explanation parallelly.
problem No clear explanation for the work.
problem No, I don not think their writeup is clear. In their writeup, they just paste the code without any explanation.
problem The wiki page is divided into some nice sections, however the authors have just included the code as it is without any description of the work that they have done.
problem The write up is written adequately. Only thing is to reduce the code shown on the wiki page as I feel that it might be irrelevant to have the whole code increasing the reading page size.
problem Its a good write up, additionally you could try to explain method and test rather than including all the test cases
problem This team used migrations effectively, and generally had DRY code, but it still felt very ad-hoc. I couldn't find any patterns that drove the changes they made.
problem The wiki defines the primary goal of the project but it does not contain a discussion about the plan or strategy that is utilized to solve the problem. Raw code is copied from review_response_map.rb and review_response_map_spec.rb files, however this does not give the reader any useful information.Â I would suggest replacing the review_response_map.rb code with a short description of what the team needed to understand about the given code in order to write the test suite. Furthermore, the team can provide a listing of higher level method descriptions from review_response_map_spec.rb, what are the expectations and which mock objects are being used to achieve the result. One minor improvement would be removing parts like Expertiza description (http://wiki.expertiza.ncsu.edu/index.php/CSC/ECE_517_Fall_2018/E1850._Write_unit_tests_for_review_response_map.rb#Background) because it is redundant in this context.
problem There should be more explanations.
problem Not perticular test plan section, but there are some different possible results have included.
problem In their test plan, most of it is code, without any explanation or cases.
problem As this rubric calls for the need of a section - Test Plan, I suggest adding it and including the work done in that section along with why a particular test has been written.
problem Most of the scenario is covered, the total coverage needs to increase a bit.
problem The Test Plan is not defined formally in the wiki. Instead the reader has to reason about the provided code itself. Given test suite covers every method of the object under test. ~70% Coverage is achieved. It would be better for the team to define the test plan and decouple it from the actual code. This could be done by firstly stating all the 'describe' constructs, methods that they are testing and secondly,Â elaboratingÂ by listing their descriptions.
problem All the functionalities are listed and code also attached for the same. But, if the code changes were highlighted in color as in git, then its better comparable.
problem No, they explain nothing, just put the code on it.
problem The wiki page is divided into some great sections that provide details about the project.Â I appreciate that the team provided actual code snipits along with explanation of the test to afford the reader a deeper understanding. The first paragraph in the design section is a bit hard to follow. It would be helpful to have this explanation accompanied by the tests these stubs were associated with and/or the actual implementation of these stubs for a better grasp of their purpose. IÂ would recommend combining the test and design sections for a easier flow of reading and following test implementations. Thank you for the Results section of the wiki that wraps up the project and is an easy point of reference for the reader to see the outcome of the project.
problem Please explain your test work rather than just paste your code.
problem The authors have not provided any explanation of the tests that they wrote.
problem There could have been certain negative scenarios tested as well.
problem Writeup can be improved at the task section and more information could be added
problem Some cases yes but most cases it needs more documentation
problem The wiki does not include any discussions about design principles or patterns that were used in the project.Â One thing that stands out in the code is that every mock object is defined at the start of the file. The team could provide a rationale for this decision and why it is superior to for example using different mocks for each separate test suite.
problem There is no explanation.
problem I felt the section "conditions tested in menu" could have been more verbose.
problem Again the test plan is not about what they test in the Rspec test.
problem They add a lot of tests but they did not mention which test they plan to do in the Test Plan section.
problem The code follows the DRY principle and the Ruby style guide for writing the test cases. The code could be improved by providing comments. The code contains optimum length methods and the variables and functions have been properly named.
problem Not sure what ca_test1 really is. I also didn't find an explanation in the write up for "node"
problem The code looks very clean. I am a big fan of the set up of the describe/context/it nesting that clearly defines the test cases' purpose. I am confused why there are two classes being tested in this spec. Is the purpose of this class to test Node or to test Menu? If two classes are being tested they should perhaps have separate rspec files to make clear the point. However, the actual syntax and implementation of your tests is beautiful.
problem There are some small problems like finalÂ newline missing, but overall looks good.
problem The tests describe the code they are testing not the behavior/functionality. Like for "In this scenario, the controller_action attribute of the menu item is unavailable. In this case, the expectation is that a customized pathÂ is assigned to the URL variable." This just specifies whatÂ variableÂ is being updated and I have no idea what workflow it represents. This is at least a brittle description for a test. Suppose tomorrow the variable is removed or some function ends up calculating the value, while the test it self might pass if the change was passive, the description is now stale and will confuse any user trying to update the tests.
problem The Menu test case violates the DRY principle. The team can make use of factories to get rid of code redundancy. Overall good work!
problem Except for the lack of comments, the code was relatively easy to understand, and was sufficiently DRY.
problem The team has leveraged the existing test cases to align with the changes implemented; they have not created any test plan.
problem All the test cases are passing however code coverage is low. Various different scenarios must be tested thoroughly. Travis CI build is passing and efforts were taken to work on this. Appreciated!
problem A few tests were added, though I'd like to see more tests regarding edge cases or invalid functionality.
problem Too long if statements areÂ written.
problem The team has followed Ruby coding standard. However, function names could be refactored for example the function "get_time_diff_btw_due_date_and_now" name is just too long and can be modified into "get_time_diff" or any other meaningful name. Also, it is advisable to keep the function name singular or append the name with list; so instead of using "find_participant_emails" the team can use "find_participant_email_list".
problem The code has been implemented in a modular fashion. However, the team can improve the readability of the code in mail_workerÂ and assignment_form. Currently it lacks readability because of too long comments between every line of code and poor alignment, which makes it difficult for user to understand.
problem At several places, the code used a lot of nested if else statements and some methods were very long. These lines could have been refactored. Also more comments are needed that explain what a method/variable does (just good naming is not enough). The code is DRY compliant and follows style pattern well.
problem Function length is good. General convention of having function length < 20 has been followed. What I found lacking was additional 2-3 lines of comments before each new function to understand what has been implemented.
problem The issues in the code has been resolved. But the wiki only addresses the technical changes done. It does not address the functionality details; which makes it difficult for the end user to test all edge cases. The project deals with the emails which can only be tested in production and not in test environment by any end user.
problem The authors work functions well but the code uses redundant/bad logic in some places. Code could have been put into methods and reused. The code functions as expected in almost all cases
problem Yes features work as intended but I would like to see tests as well as testing case were job addition to queue fails. I understand this would be edge case and not likely to happen but still needs to be handled. Other edge cases such asÂ participant_mails is nil have been taken care of.
problem The wiki as well as a design document has beenÂ created for the write up whichÂ explains theÂ refactoring requirements. The team has explained the technical aspects in a very detailed manner. However, it would be helpful for users if the team could add more details about the functional aspects so that a end user can test the impact on the existing functionality due to the changes done.
problem Write is clear and well written, a trivial formatting mistake ( new implementation bullets ) but that is fine.Â Problem statement is well define and the existing solution too. Problem statement does not need to state that RSpec tests have been added.
problem The test plan is not present.
problem nothing mentioned about test plan only snapshot provided.
problem The team has leveraged the existing test cases to align with the changes implemented. It would have been more helpful to include the test cases in the write up as well.
problem Test cases are failed
problem The tests look detailed and clear. However no edge cases or failing cases are tried. Simple and straightforwardÂ tests are implemented. They could have tried more corner scenarios more..eg. fields are missing etc
problem No test plan is included. Testing is mentioned briefly but does not mentionÂ what tests were added.
problem Existing tests have been modified to changed to pass for the new implementation.Â News tests could have been added
problem The team have explained why and how they did the work they did. Feel they should elaborate more on the tests that they have implemented.
problem Yes the authors explain the existing solution and explain the drawbacks for in them.Â I would have liked to see a point wise comparison on how their solution overcomes the existing drawbacks.Â I would suggest not to hard code the mail text/subject in the code and use a config file instead. This will be easy to modify in future. I would have liked if the authors added why they took sidekiq and not rabbitmq or celery
problem The writeup is good and it clearly meantionsÂ the issues to be fixed in the problem statement and the code modified is also displayed.
problem No the writeup does not have a test plan
problem Testing has not been done yet.
problem I have been unable to test the users work manually as expertizaÂ does not allow me to send a mail to my existing mail id. I have also tried adding a new student to the assignment which was not possible( i got an error stating the student does not exist) and all existing students have the mail id(Â expertiza@mailinator.com) which cannot be accessed to verify.
problem they explained how they made the changes. Patterns if used are not noticed by looking at the code and not mentioned in the writeup
problem no test plans mentioned
problem Authors could use empty? instead of checking unityId != ''. Another thing that the authors have taken care of ttml mails but what if the somone needs to non-html mails.Â attribute copy_of_all_emails does not look like a good name, it would be nice if they could rename it to email_copy_all or so this help in reader understand as well as in ide intellisense.Â Code coverage has decreased
problem Comments in code are missing. There are few lines that need to be removed but still exist, it would be nice to delete those eg #emails << assignment.instructor.emailÂ Â Function length looks okay, most functions have len < 20 lines which is an acceptable number. Since the code is implementing very specific issues over it has specific local changes.Â Other change are okay and ruby like
problem There is no test plan included.
problem The writeup was fairly specific on how the solution was implemented, although more qualitative description should have replaced the source code dumps. The writeup barely explained why the improvements were needed, focusing on what was implemented.
problem Commented-out code should be removed (at least one example found in participant_spec.rb). Also, there are some indentation issues as well as other issues flagged by CodeClimate. Otherwise, the code seems to comply with the Ruby Style Guide and be fairly DRY.
problem Minimal changes were made to the test suite and new tests were not written for the new code.
problem No test plan added in writeup or explained otherwise.
problem set_proposer is a setter but appears to be used as a getter.
problem Code climate show 99 issues in the code. Many lines aren't properly aligned. Commented code hasn't been removed.
problem The tests scripts are not written for the changes.
problem The coverage has decreased as per the tools that run by default on raising pull request by 13.6 %
problem Build isn't passing. Write up isn't passable.Â No screenshots or explaination in write up of what you h=are doing and why.
problem The pull request did not pass the tests and the names assigned seem appropriate to their functionality.
problem All the names are intuitive and reasonable apart from "drop_topic_deadline1". The team need to change this variable name to something more precise other than that Good job following naming conventions!
problem Code looks good. Namings are also ok. Print statements are also pushed(not expected!).
problem Some functions have the same code deleted and added again which could've been avoided, likeÂ schema.rb line 105 & 110, lines 741-743 & 745-747 and more lines similarly in that file
problem In the codeÂ topic_id1 and @drop_topic_deadline1 name doesn't seems to follow the ruby guide line and you should probably name them differently like first_topic_id and first_drop_topic_deadline.
problem none of the functions are too long could find changes where DRY principle was violated the code follows ruby convention and guidelines Although the code is easy to follow , the team needs to add comments for the changes which is currently missing. Good Job!
problem This section of the wiki is currently missing. When you write this section be sure to state why you tested certain cases in a particular fashion accompanied with code examples so that the reader can clearly see what was done.
problem The information provided is good but the page is not organised and the code is confusing. Team should work on improving the format of content(the way they are representing info).
problem The code you have added in the write up isn't indented, its hard to understand this way. You need to make the write up more readable.
problem Write up doesnt include test plan. Good thing would be include the testing steps they have performed. Few screenshots would be helpful as well.
problem Test Plan section is not maintained in the documentation
problem The writers have explained what they did in the project and how they did it. But, I could not find a 'why'. No reason behind the approach is specified.
problem Inadequate information
problem The writeup mentions what lines of code were changed but it does not clearly specify what each changed portion of code means.
problem I don't see any new tests
problem On checking, the code, we find that, in agreement with @TravisBuddy, the code had a build error which seems to be unresolved, which is strange, and should have been looked into. Moreover, the overall coverage shows a decrease of 0.1% which should be a cause worth looking into. But one must say that the details in the code changes have been to a good extent for the majority of the part and thus worth the merit. One thing that surely catches the eye is variable naming, especially 'handle_dups' which is a strange/ amateurish way of variable nomenclature and there is reason to believe that it may result into conflict in code at some point.
problem There are many places where "puts" statements are used where a logger statement should be used. There is also a set of if/else blocks that check to see if a variable is of a certain type, which could have been abstracted with an appropriate design pattern.
problem While some functionality works, the replace existing team functionality did not work when I tried using the examples in your write-up.
problem Crashed for me once randomly. Might be not because of these changes but I am not sure
problem NO TESTS added.
problem Test cases were not mentioned. Can't test as the link to the deployed application is notÂ working(Unable to login with correct user credentials. Even after giving forgot password, did not receive password reset email)Â nor the screencast video link is provided. Please include check either of them.
problem I could not figure out how to test the code. I could not make an account for myself because Expertiza is not set up that way. There were no setup instructions in the writeup for testing the emailing capabilities.
problem Can't test as the link to the deployed application is notÂ working(Unable to login with correct user credentials. Even after giving forgot password, did not receive password reset email)
problem there are issues in the build
problem no test plan availble in the documentation.
problem The Writeup does not have a test plan. Not able to check if they consideredÂ different pre-conditions, edge cases, invalid input values, and other possibilities
problem No the writeup does not mention the test section.
problem The 'why' part is missing for the code changes. What does each code line of change do? Maybe you'll can incorporate that.
problem The writeup explains to a limited extent the approach that was followed.Majority of the writeup consists of code and not how it was implemented.
problem You could have made the empty method end on one line. I think _args could be named args.
problem The writeup does not explain the changes. Also the wiki page is not elaborative about the changes made
problem The testing of initialize is very well described with descriptions of how and why the tests were written in that particular fashion. However, all other tests are not discussed. When looking at the github it seems that there were many more tests that were not elaborated upon. The test descriptions were included at the bottom of the page but without explanation of implementation or purpose. It would be helpful to include more of the test cases. If anything, it would be a good idea to discuss them without the code inclusion like that of initialize because that section of the wiki is very well presented.
problem This doesn't apply here much as its just writing testcases. However some of the tests documented in Menu like Mean with role and without role are confusing. I had to look through the entire doc to figure out why is that written that way. It could be better to have comments as to why a particular test is written , what does it test and why is the expected output the way it is.
problem Does not apply much.But instead of using names like temp and temp 1, a more significant name which is self explanatory of its content will be useful.
problem They could have also documented their design approach if any and also useÂ of mocks and stubs. Their test intentions could have been more detailed
problem There could have been other tests with different inputs tried on the setup, initialize and select methods. the pre-conditions could have been more eloborate.
problem 1) No, they have modularized well. 2) No 3) They could have provided more comments on tests where they set nodes at few places. 4) They could have used factories more extensively, due to various mock data they might have needed to cover different inputs 5) Their code can be more DRY, as they seem to repeat instantiations in all places
problem The whole wiki page is complete and neat, while it might be easier to understand if they reorder the test plan with other parts of the page.
problem Though the authors have included a thorough testing plan Inside the commits I couldn't find any commits for adding testing files. they could have added basic UI testing using Capybara and cucumber.
problem Both the specs fails spec/controllers/student_task_controller_spec.rbÂ fails spec/features/airbrake_expection_erro
problem The test plan needs to be significantly improved.
problem The pull request link is not provided to verify the tests.
problem Pull request not created / link to pull request is not found in this submission.
problem I could only see 3 commits with no significant file changes. I would request team to add and contribute the changes as soon as possible. With the present changed code, methods names and variables and class names are proper with reasonable naming conventions.
problem Link to the pull request is missing. Please add it.
problem The variables, methods, and class names do seem to follow proper convention and are suggestive of the functionality they are being used for. In some cases they could have used a liitle more desciptive names for variables for example inside app/helpers/student_task_helper.rbÂ they could have used background_colour instead of rtn as a variable name in the due_date_color() method. It will become more readable for the reviewers to understand the functionalities.
problem @all_task vs @student_tasks Â The name 'all_task' does not sound appropriate. It should be
problem No pull request has been created as I can see from the link provided. The commits have been made, though. I think they are just one step behind creating a PR. Some variables like, @students_teamed_with, seemed ambiguous as to what do they represent.
problem The variables, methods and classnames are aptly named. I could not find names which are not suggestive of functionaliy.
problem In due_date_color switch case would have been a better approachÂ then if else if block. Lots of code that is done in viewÂ can be moved to the controller. Follow MVC architecture.
problem The functions seem to be implemented in a good manner and the code seems to be DRY.. In some cases though the authors could have improved as in the i app/helpers/student_task_helper.rbÂ file. In side the due_date_color method they could have used case expressions in Ruby instead of the if else logic implemented as that would be a more Ruby on Rails way of doing it. As it will reduce the lines of code as well as being a more elegant way of handling it.
problem In the due_date_color(due_date
problem Not possible to test - neither a deployment nor screenshots provided.
problem Can not find any video or link or Ip address link to manually test the changes. I would request team to deploy the changes so that we can test the system partially.
problem Can't test as the link to the deployed application is not given nor the screencast video link is provided. Please include either of them.
problem Student dashboard Â Please see the dashboard. The UI elements are not properly aligned. The title "Current Assignments" is not where it should be.
problem Couldn't test it manually as no link/guide provided for the same.
problem Whether the task is due is determined by a date str and it may be go wrong under different timezone.
problem Thee writeup page is concise and easy to understand but there is no insight into the code.
problem Screenshots are missing under Test Plan section.
problem Writeup is readable and written properly. Team could have added code snippet and pictures of changed or improved functionality. Also team could work upon formatting and could also add links and references.
problem Please include the code snippet that was changed and also a screenshot of the view before and after the change.Â Also, Please provide the link to the pull request and not the repo created. Good written explanation of the changes done in WIKI.
problem Wiki page does talk about test plan. But it is explained in brief,Â but no details of test scenarios or testing technology to be used.
problem Few test cases are missing context and it block so it is difficult to understand what the test case is doing unless you read the entireÂ code.
problem I could think of 1 missing test case, where an assignment due date changes from future to past, that assignment should now appear in the past assignment section, Â apart from this test case, all edge cases have been covered.
problem It feels like test plan only covers one aspect - "changing of the background color for tasks as we approach the deadline." Â here are other aspects which can be automated for testing, perhaps by Rspec or the likes: Add past due assignments to the studentâ€™s task list (on Student View). -- Verify if they are being added/saved Check for correction in due dates of assignments (when an assignmentâ€™s due date is edited, it should be appropriately moved from the â€œPast assignmentsâ€ list to the â€œCurrent Assignmentsâ€ list if needed) --- Check if the functionality works. On Student Task page, separate the list of 'teamed with' students from the cur
problem There is no edge case.
problem Yes, Writeup explains the approach taken by team to solve the issue, theoretically. Team could have explained the issues and resolution practically. Also no design pattern or principle were used.
problem It only explains how they did but not why they did. The various approach could have been mentioned in the WIKI.
problem The authors have documented the steps they did to solve the issues. Although they haven't mentioned any particular design principles or design thinking that went on in solving the issues. They should haveÂ explained all the functionalities of each file they have modified and stated why they have modified the particular file. One thing they could have added were class diagrams and dependency maps. Or some pictorial representation of the flow of each task which will help the reviewers and instructors to quickly catch up on their idea.
problem The writeup only tells what is to be done and how it is done. The rational behind choosing the approach is not mentioned, neither are any of the principles mentioned.
problem It is better to state the change of the feature or added feature with diagram to show the difference, to state what remains the same and what is added or update understand certain circumstances.
problem Cannot check. Link
problem Test plan is clear but doesn't have any test cases.
problem Functions are named properly.
problem The functions are not too long so the code doesn't have to be extracted into separate methods. More commentsÂ could have been added for easy understanding of the code. The code follows the Ruby style guide and the code looks refactored, statements "unless" keyword are written in a single line.
problem I was able to create a new user with the username "abc def". Although the changes made to the code seem to be sufficient to fix this, the deployment does not seem to reflect the changes.
problem Wiki or read me does not include instructor or student credential so couldn't check anything.
problem The author's work is implemented well and is implemented as expected. Few edge cases can be written to test the code completely.
problem Yes, I was able to understand the issue as well as the solution overall. But I couldn't understand why there is a need to append a team name to an assignment. It was just mentioned that it is done in other part of the code as well. Mentioning that would have given me a better idea.
problem The write up has been written well. There's obviously some additions possible to the write up. The code changes/additions have been shown, I would recommend description of why those changes/additions were made. I would also suggest the team to standardize the size of their screenshots.
problem While the test plan for fixing team names have been shown, i couldn't find the test plan for validating username.
problem Test plan has been well implemented for one of the issues. The test plan does not show what happens if a user tries to create a new account with a space in the username.
problem The test plan is explained in a good manner, but the edge cases and invalid values are not mentioned. What if a space is in front of the username.
problem The how part is clear. As to the why part, thought they have clearly mentioned the the problem statement, i think a little bit more of an explanation could go into why is that actually a problem.
problem How has been shown well through the screenshots but why has not yet been described. No particular reference to a design pattern has been made, but that is understandable since their project was based more on changes and less on additions to the code.
problem The writeup does not have a test plan or any related info on why it is not covered.
problem No,test plan has not been implemented but I don't think a test plan is required for their functionalities/
problem Could not see test plan as well as automated test cases are not included Team could work upon adding test cases to test the functionalities. That would make the issue resolution more robust.
problem No tests added.
problem The test cases were not created.
problem No new test cases have been added to test the newly defined functions.
problem No test plan or the test cases.
problem Some checks fail in the build. But I feel that few checks are much intricate (one failed because of a score of 15.07/15) and can be neglected. The TRAVIS CI Build error was faced by many teams too. The namings are not unclear or ambiguous. goto_controller('Questionnaires','3') goto_controller('Review','3')
problem The code is well written and very understandable Newly defined function parameter name isÂ self-explanatory Suggestion: 1. Rubric Array can be declared outside the function, so as to follow DRY principle.Â 2. Meaningful comments can be included for the function definition in tree_display.jsx, explaining what does the tree_display represent
problem For the discussed solution, the code does not smell or does not need to have separate methods. The commits show the contributions by only one author.
problem The code is nicely written 3 More comments needed 5 Not DRY in one place (rubric array definition) Â Suggestion: Â 1. Simply define a getRubricArray function to return the rubric array wherever required.
problem No information on two other issues that need to be covered.
problem 1. Clicking on action from manage menu correctly opens the corresponding tab. Â Â Clicking on any manage sub menu action, correctly loads the corresponding rubric. 2. Whenever is rubric is changes, user is being asked for confirmation. Â Â On conformation from user, correspondingÂ review response is deleted and email is being sent to user. Â Â When user declined the confirmation, rubric is set back to original one. 3. Issue#1173Â does not seem to be resolved.
problem The team has only fixed one issue related to selection of questionnaires according to the video. The other part of the problem statement is missing. The application could not be tested as the application is not deployed.
problem After manual testing, issue 1 seems to be fixed and reflects the changes properly. Nothing seems to be done to fix issues 2 and 3 of the problem statement. Suggestion: 1. You can include any approach or design of functions to resolve remaining 2 issues in the writeup
problem The code has not been deployed. But according to the video, the workflow has been demonstrated properly. Out of the 3 issues, 2 have been resolved. One is not done.
problem The Fixes Required part has been explained well with the cause of the issues. But, more lightÂ could be shed on what the formative and summative rubrics are.
problem Writeup is written well. Understandable and clean explanation. Team has explained the problem statement and issues well with good amount of pictures. Team can improve on formatting.
problem The writeup was written well enough to understand. Screenshots were also attached along with the steps making the documentation better. Can definitely understand what project does and how it is done.
problem The wiki is well written and contains all required information for issue 1. The documentation for other issues still needs to be included. Apart from this , the team did a great work.
problem The writeup is lucid enough to explain the details of the issue and how the system works after fixing it. Suggestion: 1. The authors can add a section on testing, explaining about how the issue fix can be tested. 2. They can improve the readability by mentioning issue numbers (from document issued by the prof.) on the write-up. It will save time of the reader to go through the document and map which issue has been fixed.
problem The write up is clear and concise. The details about the functionalities are adequately explained.
problem The writeup does not have a test plan.
problem I could not see any test plan. Team could work on writing test plan and implementingÂ the same for the issues resolved. Also where team is failing to implement some functionality, as future scope, they can try design the solution and also test cases for the same,
problem The test plan column is missing from the documentation
problem No. there is no test plan section included
problem I did not find any test plan in the documentation.
problem What and how explained well but they explain the why behind their actions a bit more.
problem Writeup is written well. No design principle or pattern involved, But the approach taken is explained in detail, step by step.Â Â Team could add references and links.
problem Yes, the writeup seemed to include everything that was required. Code was also attached along with the screenshots and steps.
problem The writeupÂ explains the problem statement well, but fails to explain the approach and just have pasted their code. It also fails to have a reasoning behind the approach they chose. Suggestion: 1. The author can describe how they came up with an approach starting from analyzing the issue. This will remarkably improve the writeup. 2.Â The author can talk about atleast one more approach to fix the solution and explain why they chose a particular approach for implementation.
problem The implementation details have been mentioned in the writeup clearly. Information about what every function doesÂ has been explained in an eloquent manner.
problem As mentioned earlier, they have not considered testing at all at this point and hence, we are assuming that they are to implement testing at a further point in the project. Of course, mentioning an approach to the testing framework and how they would be going about it would have helped.
problem No Test plan included in the submission.
problem No tests were added. No test plan too. So, difficult to interpret
problem No tests have been discussed in the test plan.
problem They have not provided a descriptive test plan, however they have added rspec test cases for their code changes
problem The Test plan is not a part of the writeup. The team can improve upon this by following the general guidelines of writing the document. The test cases can be coherently designed following the Better Specs documentation. The team must have the test cases designed that span the required goals.
problem Their methods name is too long such as "#copy_questionnaire_details and #assign_instructor_id':
problem Not only does the build fail with multiple errors, the overall coverage is shows a significant decrease instead of an increase which is a real cause of concern. Moreover, the number of commits even though impressive does include a lot of minimalistic changes which one does beg to question the necessity of. But that's still fine since, I am assuming that the complexity of the code may require so many commits. But still adding a line break as a commit? I am unsure if its a great way to go about it.
problem I feel that the writeup was incomplete and none of the code changes made have been explained. It is difficult to see what approach they took.
problem All the names and methods look reasonable but some of the function size is still long.
problem The variables, methods and class names used do not justify the features performed and do not implement the desired functionality expected. Also, the code added does not improve the coverage of the files. The team should look towards using appropriate names and provide desired code segments to get a high coverage.
problem They did not offer any link to code of their project.
problem The functionalities relating to Questionnaire have been moved to Questionnaire from QuizQuestionnaire which is very helpful. Suggestion: 1. You can try to create sub functions for code inside create and view, as they are really long functions
problem (1)Functions are still long, save choice and save quizes are the top two, consider increasing more internal methods
problem The code contributed does not follow the test rule in that the tests are made using create instead of build. The code functions do not implement much function and does not follow the Ruby style guide. The team should focus on getting the tests running by following the DRY principle.
problem Not possible to test as no way of testing has been given at all. No procedure to be even followed has been mentioned in the poorly constructed Wiki page. All that is possible is to try to infer whatever is possible through the pull request in which I have reason to believe as suggested by the code tester that multiple files are failing in the build stage itself.
problem No link to the deployed application is provided. Hence, cannot be tested manually.
problem Cannot test the work as application link is not provided. They have not provided a screencast for working code
problem Couldn't test manually as no information regarding the steps to take to test is provided.
problem Upon manually testing the author's work it is noticed that the functionalities have not been implemented to the full. The team did perform migration of the CRUD functionality for the Questionnaires from QuestionnairesController and removed large patches of if-case statements by placing it in the helper function in the apt model. This however has reduced their coverage.
problem No, their writeup is neither clear or adequate, which just contains a few lines without any explanation or introduction to the project. So i think their writeup is terrible.
problem The write up does not show any detailed explanation of the project.
problem No, the team has not been diligent in specially making a section of "what it does" as the introductory section of the doc so as to make us understand the goals of the project. They have just copy pasted the problem statement on the wiki page in a single paragraph. Even, that statement seems to have been incompletely pasted in just a single paragraph. So, it highly unclear what they are doing. I had to open the projects assignment doc of the professor to try to make sense out of the motivation of the problem.
problem I think they have simply copied the text from the requirements document presented by the professor. The page is not well documented
problem The writeup can be improved to begin with a short description of the project backgound so that anyone reading the writeup can understand what the project is all about.
problem They don not have a test plan
problem Unfortunately, no mention of the word "test plan" has even taken place in their whole Wiki page. So, it seems that they are yet to implement the testing functionalities in their project. Although, it would have been better if they had checked if the checks or the tests already existed in the first place in the git repository.
problem No test plans has been explained. But the Git repo shows one test successful.
problem There is no mention about their Test Plan. The section has not been included in the wiki page as well.
problem Writeup doesn't conatin the test plan section.
problem Couldn't find any test plan.
problem No, there is no test plan included in the review
problem The writeup does not have the Test Plan section. They need to include it by specifying the section that describes the pre conditions considered by the team while working on the refactor review on the different question types from the uiz feature.
problem No they did not mention any design principles or patterns in their writeup.
problem No explanation is given.
problem No, the write up is a simple copy paste of sir's doc on the wiki page which half-heartedly states the problem statement in question. Also, what or how they have worked and approached the solution is not even mentioned. Difficult to follow any flow.
problem There is no mention about what work they did. The wiki page hasn't been properly formatted and the information is not adequate.
problem It does not show any code or any thing related to the work they did
problem The writeup should be written in a emore elaborative way clearly stating at the minimum - the problem statement; new implementation strategy; design principles; test plan and references.
problem The writeup states correctly the changes performed, but fails to provide a reasoning behind every change. Suggestion: You can include reasons behind choosing an approach, for atleast one refactoring code change
problem It was difficult at first to understand why they are doing what they are doing. I feel that the information is right there, it just needs better elaboration and description.
problem Not completely its lacking lot of informations, consider writing the code before and after the changes to explain the changes done
problem The team needs to provide a list of sections including the test plan and unit test cases that would make it easy to refer to the pull request and the github code. They must also work on designing the wiki page making it easy to read and understand it.
problem The writeup gives a high level overview of the work done Suggestion: 1. You can try to make the write-up more illustrative by discussing which refactoring principles were implemented in which files and how does it make a difference. 2. You can take help of code snippets to make it more understandable.
problem Good description. I think with the use of headings and subcategories it will look good also need lot of conteent to mention the changes done
problem The write-up is pretty ambiguous and feels all cluttered up. Maybe elaborating on few lines and separating the one whole paragraph into bullet points under different headings would have made it more readable and clear.
problem The writeup is disorganized and does not specify the function carried out by the team during the project.Â It does not follow the typical format of the writeup and provides a list of items such as files involved and task expected.
problem Although no specific test plans have been mentioned, the wiki page does show screenshots of the changes that are visible after logging in.
problem It does not seem to be an automated test plan. There are screenshots placed, which seems to be manual testing done.
problem I could not see any mention of test cases in the wiki or github. Team could add/mention test cases surrounding the change that lead to checking the changes in this merge.
problem There are no test cases
problem Testing for the UI changes has not been done. Maybe they were not supposed to, but if they were, more documentation in the wiki would be helpful.
problem No they haven't added. But i think its not required for this project, as its just UIÂ change.
problem There is a change in the colour code required, so there was not much of a naming convention to be followed here. Dint find any instances in the attached code where name could be changed. One instance ofÂ is_submitted could be changed toÂ is_submitted?
problem In-line CSS style tags inserted instead of linking external CSS file.
problem The naming looks fine in html file. Although your pull request shows changes in schema.rb file which i don't think you have used any where or had to make changes int it. Probably is went through by default when you pushed your changes. You might want to revert that from the pull request. That way I think your build will also pass.
problem The build seems to have failed due to some unknown reasons. Travis CI states something unrelated to tests or something about dependencies that I can't quite comprehend. The names are quite comprehensible and the code was written well.
problem The color combination could be changed for buttons. Maybe for someone who has a difficulty while differentiating colors (me) faces a lot of problem.
problem Code does follow the conventions. Just that the comments could be better explained for the functionallity
problem 1. Code is simple and written efficiently without long functions, unnecessary looping or dead code. 2. Shown snippet itself is well modularized and no need to be written as separate methods 3. Code is well understandable. 4. Code does follow ruby style guide. 5. Code follows DRY principle.
problem I couldn't login to the deployed website since there were no credentials which I could use. Perhaps the wiki page should have included the credentials for logging into the deployed website. However, from the screenshots it seems that the functionality works.
problem The page is complete. Only thing which I mentioned is a good color combination is needed.
problem Writeup is written very neatly and in elaborated fashion with understandable images. Team could have added Github Expertiza link and pull request link at the bottom of the wiki page. AlsoÂ references and credits.
problem The write up has not been formatted well, most of it consists of what can already be read from the OSS assignment specifications document. I would strongly suggest the team to include screenshots of their commits instead of using wiki code formatting.
problem The write up is well documented. There is a clear flow from the code change part to the screenshots of the implementation. It would have been better if there was a screenshot of the code from git or a link to git so that the code changes would have been more defined as per the green and red colour. Also, the code change could be explained more.
problem The code block runs out of the space. Needs to be corrected for proper look.
problem Looking at the commits, there is hardly any work done by the team other than adding style tags in 2 commits.Also, the wiki link attached is of Fall 2018. New Wiki has not been created.
problem They dont have a test plan in their write up but they showed the screenshots for various cases.
problem There is no separate test plan section, but the test functionality has been shown in the form of screenshots. Could add it under the Testing header in the document so that the code and test would be separeated.
problem Project does not have test cases included, hence can not check further functionalities. If team is not able to add test cases for exact change, team could add/mention test cases surrounding the change that lead to checking the changes in this merge.
problem Team has used in-style tags to add CSS styling in HTML pages. They instead need to create an external CSS, define the styling there and use the class names in HTML tags. This provides styling maintainability throughout application.
problem The writeup clearly explain why the team did the work that they did. Good job on that. The only thing I may have preffered to have as a reviwer is a detailed step by step instruction on how to view the changes made by the team in the app. This could be added in the wiki, or a short screencast could me made to help follow the steps.
problem Yes, the code change along with the screenshots does explain the ordeal, but the git screenshots and some more explanation would be well appreciated.
problem They have not yet reached the desired goal of 90% coverage.
problem Some cases haven't been implemented yet.
problem The tests have been added as per the test plan but some of them have not seemed to have passed. The team could have a look at the tests not passing and work on them.
problem Test plan is not mentioned. Currently test cases are not running because of model file missing. Youtube video with description will be useful to show how the tests are running and if any of them fail
problem No Automated tests.
problem Not enough data for judgement
problem One file is missing. May be a commit issue. Test coverage is not mentioned. Pull request is not raised so it does not mention about the whether the test coverage increased or not.
problem Haven't uploaded the link for the pull request.
problem Pull request has not been submitted or uploaded at all which makes it hard to decipher any of the above data hence make it a problematic scenario to certain what all changes have been made in the first in the terms of number of commits or pull request.
problem Can't find the pull request to comment on this
problem Code follows standards but variable names can be better and more 'readable'. Another suggestion: declare ALL variables first then use those variables to call methods. When you add/declare variables in between method calls, it looks as though you 'forgot' to declare earlier and added them later. Just a thought !
problem Some names are ambiguous, like pptn, I cannot know clearly what this name is for.
problem Just one contributor
problem Please extract all "let" to avoid the repeat code.
problem For each cases, it include too many things need to be test, it is better to separate them into different cases. Also, the object used for this test seems not be put into the factory, it is better to make them into factory which is a good practice. The use of context is not good enough.
problem Including basic Understanding of the problem statement and work will help in manual testing.
problem Impossible to do since no submission or uploading of the image have been done for this project. It is unclear how to decipher any meaningful data without the help of pull request as well.
problem The functionality has been written well. Though I do feel it would have been better if the test cases implemented had been explained in more detail as to what the do.
problem No pull request link
problem The write has only details of team members and files changed. Out of the two files mentioned , only one is currently committed in git(vm_question_response.rb) is missing. May be a commit issue.
problem More details required regarding the functionality for which the test cases have been written.
problem Yes, the team has taken care of it by specially making a section of what is the problem as the introductory section of the WIKI doc so as to make us understand the goals of the project. They have even attached code snaps of the relevant changes they have in mind whilst explaining the error. Although, one questions the details in which they should have gone into explaining the errors and resolution. More mentioning of details is required.
problem The writeup has proper instructions but needs some improvements: 1. Explain the problem statementÂ 2. Explain 'why' you need the solution 3. Explain the steps you took. The code snippets are added but could be improved by adding explanation of the tests. May be adding 1-2 lines can help.
problem There are not enough introductions about what the functionality of the class they will test and what it is used for. The team can introduce more about what expertiza is and what the role of the class will be test and its functions.
problem Test plan documentation is missing currently. Plan will help to relate with the code and understand if things are tested appropriately and the response is as expected or not
problem The plan is simple and don't list detailed cases for each method, also it does not include various Â conditions may include.
problem No details about the problem statement is mentioned currently. So it is difficult to understand the test code directly.
problem Yes, they surely have done a good job in mentioning the errors in the wiki doc.Â They have vaguely described the handling of the same, but doubts remain in the details or the changes in the code.Â WhichÂ means that a better jobÂ andÂ a more technical description of howÂ It is happening should be given so as to grasp aÂ better understanding for the same.
problem Need a bit of detailed explanation on 'why' and 'how'. Too many screenshots with little explanation in words.
problem The motivation is not enough. It is a little bit simple and general. The team should add the introduction to the specific motivation for this project.
problem The team has implemented automated tests. There could be some addition to the test, which I have suggested above.
problem All the cases discussed in the Test Plan have been converted into automated tests.
problem all the test scenarios are included in rspec. The tests are also increasing the test coverage. Great job!
problem The variables, methods and class names are aptly named. I could not find names which are not suggestive of functionality. (i) The writeup is well written and easy to read. (ii) It is adequately descriptive of the work done. (iii)Â Explanation of reasons for the style of code and problem solving approach is lacking.
problem The features work correctly, as expected. The instructor login only has one "Student View" tab under the Manage menu. On clicking it the instructor is successfully redirected to the student view page which has the "Close Student View" button to redirect to the default view.
problem "Switch to student view" - But to which student? Open and Close student view is handled on clicking it to switch the type of view. Same changes (to delete session[:student_view]) need to be doneÂ on logout in auth_controller as well.I logged in as instructor6,Â clicked on "Open Student View" and logged out. When I login again as instructor4, I must still see "Open Student View", but I see "Close Student View" while I'm not in the student view at all since I just logged in...
problem Covers all edge cases like checking whetherÂ AssignmentsÂ is absent in the menu in default view and present in student view.Â Could not view the reviews done by students.
problem Yes, the team has considered the two important and required test cases- 1) To check whether "Assignments" is not present in the Instructor view, and check the presence of "Open Student View" button in the flyout menu. Here, the team has also checked the precondition whether the user is viewing the correct page (tree_display/list) which is meant for the Instructor.Â 2) To check the presence of "Close Student View" button for the instructor to return back to the default view and have the "Assignment"Â tab for students.Â Suggestion: The team could add a line to check whether the system returns back to the instructor page after clicking the "Close Student View" button. maybe include : "expect(page).to have_current_path('/tree_display/list')" .
problem The writeup clearly explains the implementation details and why those changes were made. It is nicely articulated and leaves no ambiguity.
problem The explanationÂ of the why they write the test code like that could be more clear.
problem The unit test step section is included, but there is no test plan.
problem There is no test plan
problem The test works well, but there is no edge case.
problem The project is about adding tests to the a model. So this is okay but there is not sufficient background on the model itself. More details would be good for the uninitiated.Â Also they mention that the number of tests for the model were not sufficient. It would have been better if they would have quoted the code coverage numbers before and after.
problem TheÂ submission is about adding tests to the projectÂ and authors have done a great job of adding 92% code coverage.Â I would have liked to see more -ve test cases for example cases such as user with incorrect names. As of now the test cases only checks of the user name is present or not. How about the case where user name is such that it is not allowed. User class throws an exception or add method can. This could have been documented.
problem I would have liked to see more use of context in the tests and grouping of similar test methods in context.
problem Could be better if contain withÂ more info about the test itself instead of the rb file they tested.
problem Nope, again they did not mention a lot about how they test but what they have done .
problem Since it is a test rb file, there are not many variable need to be named.Â The "it " part at line 362 in the assignment_team_spec.rb file, "get max num" could be better if substitute with "get maximum value" or something like this, max num seems little bit wired.
problem Writeup is very clearly explained. Writeup clearly explains how they are doing their work but why team is following approach is not explained.
problem there is no test plan.
problem The write up as well done. However, the write-up is missing the test plan.
problem The writupÂ includes the work done. However, there is no explanation about why that
problem Please add the test plan to the write-up.
problem Even though there is a no test plan available in the write-up, however, a lot of tests have been added.
problem Naming is good. There are few names(eg. is_selfreview_enabled ) which don't seem fine but they were from before, any thing new that has been added by them follows proper naming convention.
problem The code has almost no comments. I found someÂ lint, particularly some commented-out blocks of code.
problem Code looks good apart from a lot of commented code. If that is written by the team and was not already present, then it should be removed if not used before submitting pull requests.
problem The code is very well written, there are no bad names or long and complicated functions. However, there are no proper comments that have been provided for the viewers understanding. One suggestion would be to include some comments for better understanding.
problem Could not find any test cases. The team seem to have made changes to only the views. The team should implement test cases for the issues they've fixed.
problem New code was committed but all at once on the same day.
problem The code has been modified to include the modifications requested (test cases added for failing scenarios and edge cases - two assignments with same name) in my previous review. Appreciated! Overall the code quality is good. Only some variable names are ambiguous for example: check_validate.Â What does it validate? Name it like validate_same_name or validate_common_directory etc
problem No deployment link was provided, but from the video and tests they provided, the features works as intended.
problem Since, the git repo link of their hasn't been given it can't be certainly said how well the code has been written. But going by their video in which they have meticulously explained step by step what they have done, I would day It is reasonably well executed and follows the Ruby style conventions.
problem Some small coding guideline related problems are there which can be addressed.
problem There are commits on a single day, that is yesterday. One suggestion would be to commit regular progress on the git.
problem The tests were mentioned in the report but not in the pull request. There was also no coverage information. The approach looks good though.
problem The code is well written but it can use comments to help explain what the code is doing. For e.g. the code below is hard to understand: if quesparams[:assignment][:directory_path] == "" and quesparams[:check_validate] == "on" quesparams[:assignment][:directory_path] = "#{quesparams[:assignment][:name]}_#{quesparams[ :assignment][:id]}_#{quesparams[:assignment][:course_id]}" end
problem The features work properly but still need more tests to test the functions.
problem The suggestions have not been improved. Comments aren't explanatory and does not give an idea about what the author intended to do. It would be good to include meaningful comments. Debug code is still in the commit. Even though we may used debug code like the puts statement, we should not commit these as they could create junk data in the application log. Please consider removing them.
problem I don't see any tests added by this team, although they do mention that their code additions were not particularly testable except with the existing automatic tests, which they enabled.
problem I don not think their code is good, because they did not solve the problems existing in the first round.
problem The build fails so this project will not work in its current state. There were instructions however on how to set up the project and show that it is working.
problem Some parts of the code are still left to be implemented
problem It's fine to good. I wish y'all would have posted a link to your repo in stead of the pull request.
problem No link was given to the demo of the project.
problem the latest commit is on 2nd of Nov.
problem No, they did not commit new code.
problem This system doesn't have a UI I can view as it seems to be a browser add on.
problem No new commits in the second round.
problem The wiki is quite comprehensive and gives the build steps clearly. It could also include a more basic explanation in layman terms about what the OffScreenCanvas API does
problem I cannot find any new test cases.
problem No, they did not add new test case
problem No the team did not add any new test cases. Coverage is low.
problem Only 34% of the lines of code in review_response_map.rb were covered, according to their video. This is much lower than the 90% required by the project descriptions.
problem Not cover all theÂ scenarios.
problem No, changes made from last review.
problem Although the write up clearly explains the problem statement and also contains the changes made, it doesn't include the test plan which would give a clearer picture of the changes added.
problem basically, it is good. however, i cannot find the test paln, and some explanation is not complete.
problem No, it is not good at all, they didn't explain the functionality of their test code.
problem Y'all did the least possible work, AND put it on wikipedia instead of the expertiza wiki.
problem No, they code is not complete, and many cases are not covered.
problem 34% is better than nothing, but it's still a far-cry from a complete unit test suite for the review_response_map model. I'd recommend it be merged, but it needs to be completed.
problem Still 25 issues, checked byÂ codeclimate, to fix
problem The build does not pass. Also, the coverage is very low. Not many testcases.
problem It's probably fine if the integration tests can be resolved, and the code smells from code climate can be fixed.
problem The biggest concern are the simple code climate issues.
problem No, they did not pass Travis Ci.
problem Passed Travis but had many lingering CodeClimate failures.
problem The project does not pass the Travis CI integration tests. I looked at its output, and I cannot tell how significant the failure is. Maybe its an easy fix?
problem The reason to give 3 is that there are certain simple code climate issues regarding spaces, indentation and so. These are easy to fix and are related to code quality.
problem They have kept up to the standards of the goof coding practice , like they have given reasonableÂ variables names and functions name which makes it easy to understand what is the function supposed to do. However, they haven't added the comments
problem There is some repetition of code but overall code quality is ok. There are some comments from the professor which should have been addressed.
problem There were some issues which I reported regarding comments and Notice messages displayed to User which needs to be improved. But they haven't been incorporated. It is not a blocker but definitely an important change to improve User Experience and better code readability. For example, In submitted_content controller there is a comment which says sending email to users. However it is just a method call which redirects it to delayed_mailer.rb. So this should be properly mentioned as it will be helpful for someone refactoring or understanding the code later.
problem No new code was committed during this review to incorporate the changes suggested
problem No, I don't find such commits during round 1.
problem Test case has been added, but Since i cannot run it locally, i am not sure if it is passing or not.
problem Yes, they have added a few new test cases. But all scenarios are not covered.
problem The team has added one test to check if email is sent or not. However, the coverage as I can see on Github log is not increased.
problem The team added a test case. However coveralls shows the following.Â Overall coverage decreased (-17.2%) toÂ 19.566% I interpreted this as as decrease in coverage.
problem The project is to refactor the existing functionality and code. The functionality seems to be working fine.
problem Could not find steps to replicate on UI. Documentation does not mention steps how to test the feature. More information required as I was not able to follow the steps
problem They should have added the code as a part of the writeup instead of providing links to github commits.
problem Write up is really good. but little short. Could have been described with more details. Also, it would have been better if they ha uploaded the screencast of the work they had done.
problem Writeup is descriptive. But missing the following: 1. Screenshots of implementation 2. Steps to replicate the problemÂ 3. Instructions not provided. 4. Too many sub topics for solution implemented
problem The writeup is written in a very verbose manner. They still haven't added the test plan which was missing.Â Suggestion: I feel that the test plan should have been added explicitly.
problem Needs some work, code climate changes, a bit of DRYness and a passing CI is needed.
problem First review comments not addressed.
problem The team has added the test case for issue#1190 which are Rspec tests. The test plan includes how to test issues #391 and #1201 by logging in as an instructor, but test cases do not seem to be present for this part.
problem I think User experience and code readability are as imp as producing a working code. So based on how urgent is the requirement for this functionality, I would prioritize refactoring the Notices and Display messages to more appropriately indicate what action was taken when we try to add a participant to the assignment or import using a CSV file. Secondly improving the comments as explained with an example in the first question.
problem The code is well-structured and easy to follow. Styling and indentation are consistent.Â One major issue that was not addressed is that the object that is being tested is an instance of AssignmentParticipant as opposed to Participant. As a result, the team had to comment out the #scores method of AssignmentParticipant to hit the #scores method of Participant. One possible fix is to define a new participant instance in factories.rb. One further suggestion is to improve the expectation for method #scores by testing the attributes that are relevant in that context as opposed to checking the string value of #inspect method.
problem The overall test coverage decreased by 0.6%. You could have added test cases toÂ response controller.rb and application helper.rb. These files have contributed the most to the decrement in test coverage.
problem Build issues to be fixed. This pull request is not in "ready to merge" state.
problem Not sure, since could not replicate.
problem Yes, a fairly good job in that regard. They have first explained their test plans, then even provided links to their RSPEC tests which I checked. Then they have run and shown their screenshots of the Rspec tests going through successfully. Even, so theirÂ coverage seems to be anÂ issue since itÂ hasn't been updates since the last submission that was 19 days ago as per their pull request whichÂ even shows aÂ decrease in their coverage.
problem I'm unable to get a really good idea of exactly what was done here for this project other than that it can be used as a display and rendering port and that it improves fail-safeness of browsers.
problem The build is failing, but it seems the team has it working locally. I think they can get it working with this approach.
problem They have added a test for the feature implemented. But coverage has decreased by a little.
problem The Pull request shows that the code has failed all the checks. Therefore it should not be deployed.Â Suggestions: Rectify the code climate, Travis Build and the merge conflict that is being displayed on the Pull request(Gemfile.lock conflict) . Once done, the code could be deployed. Functionality is working fine, no doubt but build must not be deployed unless the above issues are resoled.
problem The team has added one spec to check whether a different directory path is generated after generation of a duplicate assignment. The overall coverage decreases by 0.6% The written test covers one of the three issues given to the team. There is scope to add some more tests
problem The build hasn't passed in the travis CI
problem Because of the merge conflict in gemlock file, it is not merged and travis CI has not run.Â i believe they ran bundle update and committed the file which should not happen as it updates the dependencies and might break some features.
problem Travis CI tests have failed. But there are no conflicts and the build is ready to be merged with Master branch.
problem Travis CI build is failing.
problem No, Travis test did not pass. In fact, I can see test failures for each commit. Continuous integration tests has failed.
problem The Travis CI build does not pass.Â Suggestion: Team should have rectified this.
problem Pull request failed the tests, so that must be fixed before merging.
problem There was no new code been committed in the 2nd round as the last commit can be traced back to 7 days ago
problem The last commit was on 11.04.Â There's no new commits. sadly.
problem They did add one test case, but I think it is not enough.
problem no new commits after round 1
problem The team has added a new test to cover the functionality. But this test is failing. There could be an issue with the notice that is generated, as during run time it is set to nil and this is checked against the string provided in the test. The overall test coverage has decreased by 0.6%.
problem TheÂ last commits were made on November 4 which was prior to the first review.
problem As suggested by the Mozilla team themselves, a few errors need to be rectified. The final code also needs to be formatted using rustfmt to make it consistent with the design
problem Did not even pass the auto test.
problem There can be a few changes incorporated to the code- especially the name mismatch of the web IDL and corresponding Rust file needs to be fixed. The unnecessary comments have to be removed. Moreover, the pull request shows that there are a few changes that have been requested and all checks have failed. So, the code can be merged and deployed only after these are incorporated.
problem I think that they need to fix some things that are mentioned by travis CI. Once they do that they are good to go.
problem I don't think this project is the type that would be deployed on a production server,Â and I can't say it's ready to be added because every thing in the pull failed on github.
problem Still did not pass the Travis CI
problem Everything in the pull request failed (although this is not an expertiza project)
problem The system works well and performs all the operations correctly. -1 for the aforementioned errors in code.
problem Yes, the code has been refactored to cover all the intended scenarios and the tests have been very well documented along with testing the edge cases as said from their videos. TheirÂ Rspec howeverÂ doesn't seem to test many test cases butÂ that's expected I guess given their problem statement.
problem Everything works as per the video linked in google drive. A link to the same can be added on the wiki page.
problem One of the videos linked in the wiki has a broken link. The other link shows the functionality is working correctly.Â Even though the wiki has given instructions to test the functionality, the team has not deployed there code. This has blocked manual testing.
problem The writeup is great. I could get all the info i needed to understand the problem. Could refine the describing issues section a bit as I could see sentences like "Â Please take a look at the Github issue for suggestions on how to solve this."
problem The team did not have a writeup in the last submission. In this submission, they do have a writeup with the problem statement, the files modified, approach to solving the problems, and test plan. This seems to be a significant improvement from the last submission. As for the screencast links, I think one link is absent and the other one is a YouTube video of the same project submitted last year. Please check this, I think you have added the wrong link. I would also suggest that a references section needs to be added to the Wiki page so that the deployment, pull request and other project reference links are shown.
problem It is very well written with a nice flow diagram. The secondÂ video link on the wiki page is unavailable, which can be fixed/removed in case it is legacy.
problem The team had not added a link to the wiki during Round 1 of the review.Â 'Issues to be fixed' section seems incomplete and not the right kind of writing. Please review and try to add more details on the issues that are being addressed. Otherwise the wiki looks good with relevant diagrams and code snippets.
problem The code can be deployed once the Travis CI passes and there are some 6 minor warnings to be fixed in code climate. There are 4 failing and 1 successful checks, the team needs to make sure these checks pass in order to be able deploy the code onto the production server.
problem This code is ready to be deployed if they ensure that variables are renamed to resemble their actual functionality.Â No big issues as such. Resolves the problems well.
problem There's no new commits after the first round review. But for the first time, there's already almost full coverage. The tests covered the range of the project very well.
problem they didn't add test cases in the second round
problem Once the issues with pull request are fixed it can be merged.
problem Unsure in this regard since they neither have the deployment neither the GitHub link to their repository, and also the coverage and the Travis CI say otherwise. Even so, in their video they show in proof that everything runs. One does wonder though, how to test without actually having the links of the repo.
problem Some improvements are required before deploying it to the main server. There are changes suggested by codeclimate which need to be looked upon. The future team must ensure to pass the build. There is scope for the new tests to be written and code that would improve the overall coverage. Overall, the team has done a commendable effort with respect to the difference in the first and second submission
problem I believe that code, as it stands, is not ready to be deployed. More comments are needed and the code is hard to understand, so even though the changes are small, one might need to see id the changes can be simplified. I believe testing can be more thorough too.
problem no new tests were added.Â coverage was achieved in 1st round.
problem If they can write more test cases to test their code and make sure their code does not have bugs, i think they can deploy their code onto server.
problem No. The code needs to be cleaned up before it can be deployed. The build failure needs to be fixed. Also, as the project is not deployed, manual testing could not be done.
problem Coverage is same as was in the 1st round. No further addition
problem On checking the pull request, it shows the Travis CI check has failed.
problem The build does not pass in Travis CI check. Â They build job for TESTFOLDER = controllers is failing currently. I would suggest them to investigate the cause of this.
problem The Travis CI build has failed however there are no merge conflicts. You could have fixed the Travis CI build errors in phase 2.Â Still overall good job.
problem No, according to Travis CI the build doesn't seem to have passed due to some bundle install errors. Although they surely should have resolved it because the code wouldn't be able to achieve the above results as stated by their video and wikipedia page.
problem Few of the travis tests have failed. The issues were code guidelines and spacing issues.
problem The build test failed in Travis CI. However there were no conflicts with the base branch.
problem The build fails and there are several issues and warnings that need to be fixed.
problem I cannot yet implement the environment to do the UI. The work looks very good. As test case, they have covered all scenarios.
problem Even though the build is failing in Travis CI, there are no conflicts. The controller tests are failing as there is no flash message that is appearing. Please look into this.
problem writeup is comprehensive and very carefully written. A lot of details included. I would suggest to add more examples, and more explanations of why there's such mock cases
problem The wiki page includes all the information. If they can add more details about how they test the methods, it would be better.
problem The write-up has been written well including the problem statement, test cases, andÂ the test result. However, I feel that informationÂ about tools such as 'Rspec' and concepts like "BDD" is not that necessary as the reader is most likely familiar with these concepts.
problem Though the code works well. The build does not pass. Also, some more edge cases will make the testing of the model complete.
problem The project is almost perfect. But, as mentioned above, they need to fix some issues.
problem The project fully covers the functionality for testing the participant. 100% code coverage is achieved. However, the biggest problem is that the #scores method is commented out from the class AssignmentParticipant. Obviously this will break the existing code that relies on that functionality. Furthermore, the future testing will possibly become complicated because the object under test for participant_spec.rb is an instance of AssignmentParticipant as opposed to Participant.
problem Need to fix the build issues and code climate issues(bank lines and indentation errors).
problem The build hasn't passed in travis CI. There areÂ some conflicts that are to be resolved example :Â SignUpSheet.add_signup_topic will return a SignUpSheet when the topic already has deadlines
problem it says that the Travis tests failed, but the teamÂ mentions that they couldn't get rid of two issues.
problem Unfortunately the build does not pass in Travis CI and there are still some code climate issues.
problem The project is almost done but the Travis CI build failed and 2 code climate issues need to fix.
problem No, the Travis CI build test has not been passed, but the forked branch has no conflicts with the base branch.
problem No build isn't passing. There's a test failing.
problem The build did not pass Travis CI. The reason is because #scores method is commented out from the AssignmentParticipant class.
problem Build has not passed and there are two issues which are required to be fixed(code climate ).
problem The writeup is explicit and easy to read. But it may be better to include the explanation of the test code.
problem The test file are almost ready to be deployed onto the production server, only one code climate issue need to fix.
problem Needs to work upon the build. Need to fix issues related to code climate.
problem With only one code climate issue and passing Travis, this pull request is ready to go!
problem Just a simple issue in code climate which can be resolved.
problem Travis CI failed. It seems that '47)Â assignment function review strategy tab sets number of reviews by each student' has some problem.
problem Build has failed and no new commits are done to fix it.
problem In the first round, which files were related to what issue was not mentioned. However, now they have edited the wiki to reflect the mentioned changes. Each file and its related functionality has been mentioned. Appreciated!
problem There is no change in the code in this round. The variable names and method names are intuitive. The code is well indented; some useful comments can be included to improve readability. The code is DRY.
problem The team has implemented proper functions and has used a proper naming convention. However, there is scope to add some comments. For ex: in the new method - get_feedback_assessments_for method which will return a feedback assessment, the team could have added some comments about the logic implemented. Apart from this, the code is concise and good coding and Ruby practices have been followed
problem The code is well-written with proper comments. But none of the suggestions from the previous reviewÂ hasÂ been implemented. Teams are provided reviews so that they can further improve upon the code.
problem The last commit was 21 days ago, so I fear that that there are no commits being made in round 2. Could have done a commit in round two just to confirm that there were no changes required in round 2, so that the reviewer may be certain about it.
problem Yes, the team has added test cases, the code for a couple of test cases are in the wiki in a separate section. Again, it would have been better to explain the test cases a little more, may be using screenshots of successful test cases.
problem The team has added test cases but the code coverage has decreased by 0.04%. The newly added tests cover almost all the new functionality implemented. The new test cases are pretty diverse.
problem The code was well written. Although there were some problems with codeclimate identations. The team have made changes to fix those issues.
problem The team have added the test cases which covers the range of the project. Coverage increased.
problem The code is structured well and is straightforward to follow. Test blocks are succinct and contain one assertion per block. The project has been greatly improved since the 1st round. Naming and indentation issues have been fixed. Furthermore, significant work has been done for the code to be consistent with Code Climate. One suggestion would be to elaborate on the #score method. Decomposition could be used to extract the common set up into a separate before(:each) block and test expectations using multiple 'it' statements as opposed to having everything asserted in one 'it' block.
problem The coverage has decreased by 0.04%. The team has added some tests which were not present in the initial submission. 44.9% of the changed lines are covered
problem The team has written new test cases, but the overall test case coverage has decreased by 0.04%. The tests cover the range of this project.
problem Yes commits are done to fix the code climate issues.
problem An unnecessary commit has been performed becauseÂ of whichÂ build has failed, and i think it wasn't required as already codeÂ had 100% coverage. You should check that out, it just an indentation issue i think.Â Format it using rubymine and push, it should work.Â AÂ shorter video to explain the work has been added as well.
problem I found many commits related to the code climate fixes.Â No suggestions.
problem Works as intended. Could have elaborated a little more like a guidance in wiki.Â Was able to test the features. Works fine.
problem The team has not provided steps for manual testing even though this was requested during round 1 review.
problem The authors have added the screenshots from github which clearly shows the code change. But since there are many changes, the explanation in the wiki is small. A better way would have been to put the links to the git files where the changes are made and there could be more explanations instead. This would also reduce the size of the wiki.
problem They should have included screenshots associated with the issue. it would help one understand the solution better
problem Dissatisfied with the write up because no clear explanation has been given for how they arrived at the design. At some places the documentation abruptly stops mid-explanation. The code screenshots and the accompanying explanation is good.
problem Could have been more elaborate how to check the work. No mention of design principles or patterns used.
problem The writeup was still on wikipedia and didn't expand on the reasons why the test cases were the way they are. No justification was provided for why only 34% of the LoC in the model was covered.
problem The write-up lacks screenshots/ relevant images/ screencast to explain the workflow of the project. This would increase the readability of the wikipage. Also, the team has added testplan and included description for the code presented in the wiki. These points were mentioned during the previous review which were picked up by the team. The team has done a good work in improving their writeup as compared to the previous version.
problem There has been some improvement in the content of the write-up, but not all suggestions have been incorporated. Adding more screenshots of the functionality, or a video of the project being explained will always be helpful.
problem When i try to run manually, i still see the same errors Â Participant#email sends an email to the participantÂ Â Â Â Failure/Error: assignment = Assignment.find_by(id: self.assignment_id) Participant#score Get participant score within a roundÂ Â Â Â Failure/Error: scores[questionnaire_symbol][:scores] = Answer.compute_scores(scores[questionnaire_symbol][:assessments], questions[questionnaire_symbol])
problem Yes, the test does covers 99% of the models variations. The team could have enhanced tests with varied inputs, such as for the handle method check. Even a more through test of the score method with different input data could have been done.
problem Although I believe this project is ready to be merged into the branch, I would still like to make sure as to why their build is failing in Travis CI. Most likely it's not because of their own code, but as a suggestion the team should have also looked into this matter themselves, and explicitly stated somewhere in the wiki by getting clarification from the instructors.
problem The document straight away starts with the explanation of the project specifics without any background as to what was the whole purpose of doing this. Problem statement is very general, it could have been more specific as to what was the drawbacks of the existing implementation and how that can be resolved with the new changes. The doc also lacks a test plan.Â It is preferable for the doc to be written in expertiza wiki rather than the normal wiki.
problem I feel confident if the Travis CI integration issues are addressed, then it can be deployed in the production server.
problem as long as they fix 3 indentation issues for code climate, they are good to go.
problem The test is almost ready to be deployed onto the production server. As mentioned above, there are some issues need to be fixed.
problem Build is failing, they should solve that issue, then it is ready for production.
problem 2 of the methods are resulting in Errors
problem The code can definitely be deployed but once the 3 pending code climate issues(I believeÂ the 3 are to be resolved by he mentor) and the Travis CI build have been rectified. Suggestion: Rectify the Travis CI issues.
problem The project is ready to be merged. The source code is clearly structuredÂ andÂ can be used for the future teamÂ to work on. The project has 100% code coverage.Â In order to avoid potential problems of using AssignmentParticipant instance, participantSuper object is defined in factories.rb, which is an instance ofÂ Participant class. The possibleÂ suggestions areÂ to deconstructÂ #scores method and introduce 'context' constructsÂ toÂ enhance code documentation.
problem It's a test project, so not applicable for production deployment. But the code can beÂ merged as appropriate test for participant model. Any future teams can enhance the test with varied input scenarios.
problem Conflicts were resolved to an extent for the Travis Cl. But not all the tests are passing.
problem Unfortunately, the build failed in the second round.Â But, in my opinion this was not due to the team's mistake. The build failure says the two examples failed are in files "assignment_spec.rb" and "assignment_participant_spec.rb", both files which the team had no connection with. I could be wrong though. As the build was passing and there tests were running in the first round, I am inclined to believe it was because of another team's incorrect code that this team pulled into their branch by mistake.
problem The pull request says the Travis CI build is in progress, but that seems improbable. Upon closer investigation into the Travis CI "details", it looks like the build is failing.
problem It is pending while I am doing this review. When I click on it, it did not pass Travis CI, but it fails on tests on features, while this group is testing participant, it happened to our group as well, I assume it is not an issue with their code.
problem The Travis CI is in progress and there are 3 codeclimate issue to fix.
problem Some travis ci tests have failed and some code climate issues are still pending, though the commit comments say that the issues aren't related to the project files. But they have tried to fix the issues though so good work.
problem A commit has been performed 4 days back , which isn'tÂ making any change to the code just the indentation, and since thenÂ build hasn't passed. You should check that out, it just an indentation issue i think.Â Format it using rubymine and push, it should work.
problem TRAVIS CI didn't Pass, but team have fixed most of CODE Climate issues
problem The Travis CI build did not fail exactly but it did not pass either. It showed in progress. But when I clicked on the details, it showed that the test failed.Â Suggestion: Travis CI issue should have been rectified.
problem The previous builds of this project did not pass Travis CI. The current build status is pending.
problem TheÂ pull request has failed but doesnt look like its related to the team's commit. there is already an existing issue present.
problem yes, the authors have improved the code. the team has worked on the issue which I mentioned in the previous review. The code doesn't seems to be confusing now but it still needs proper commenting to be done.
problem The function process seems to be a bit long. It could have been splitted based on oscillator types rather than having all of them in the same function. Apart from that rest of the code seems great.
problem The code seems to be fine but due to lack of comments a little hard to understand. It would have been better if there were some comments in get_due_date_data and addQuestionnaireTableRow.
problem There are lots of code climate issues to be fixed.
problem They haven't made any change since round 1 review. Haven't changed the naming as well egÂ topic_id1 doesn't seem right to me. But other than 1 or 2 names, everything else looks clean. Also you haven't added comments to you code. YOu should add comments when working in a open source project.
problem A few comments could be included in code to make it more clear.
problem Suggested changes related to naming convention are not included in the 2nd round.Â variable names : rop_topic_deadline1 , topic_id1 Puts statements are not removed : p topic_id1 Â Other than this the code is properly written following coding best practices.
problem there is only one commit made during the entire project. there is no new code added during the 2nd round.
problem There has been only one commit for the entire project.
problem No. There was a single commit throughout the project period and that was during the 1st round.
problem No commits were done in round 2.
problem Nothing changed since round 1. Haven't added a shorter video or a video with sound. Haven't made naming changes.
problem No, the code was last committedÂ on Oct 31st.
problem There were no new commits in the 2nd round.
problem I don't see any code changes after the first round.
problem No, there are no test cases added by the team.
problem No, the team did not add any test cases and the coverage did not increase. The overall decrease was -13.6% to 34.007%
problem No new tests were added and coverage has also reduced. Some UI testing could've been done.
problem They have mentioned that its UIÂ change and has been discussed that testing isn't required in there documentation. But i think you should still have mentioned something there. Steps to follow to check how your changes work.
problem The link to the deployed application was not available. So testing could not be performed.
problem the authors has worked on write-up.they have worked on the issue which I mentioned in the previous review. The code doesn't seems to be confusing now. the content on the page is in proper format earlier which was not. Test plan still need the team's attention.
problem Write up isn't good. They have just added there code in the write up without explaining anything. Plus no comments in code. Code snippets in writeup are going off the page.
problem The writeup is good and clearly explains the issues faced. However instead of puttingÂ in the code changed, I feel it would be better to have screenshots of git commit history where we can see both the previous code and new code to get a good idea of what actually was changed.
problem The write-up is well written and organised. Everything looks fine. The team should have mentioned about the approach taken to solve the mentioned problem statement which will make the implementation easier to understand. Also the team could have included few screen shots in the write-up.
problem *Â Test plan is missing. * Code is directly copy-pastedÂ in the approach section - pseudo code with properÂ comments would have been better. * Wiki alignment is missing in those places where the code is copy-pasted.
problem some improvements are required to deployed the code onto the production server. The code should included proper commenting so that if the future team picks up from this project, they could know what exactly the code is doing.
problem It might be good to move the long function to smaller functions. But the code looks clean and understandable.
problem The feature seems ok but it can't be deployed yet with all pending issues.
problem Writeup needs to be improved, video needs to have sound or make shorter videos. Build is failing, code climate has 56 issues. So no its not ready for deployment onto production. The way they have implemented is fine but they need to work on the said issue to make itÂ production ready.
problem Since the code coverage has decreased and the video demonstratesÂ a proper working
problem ll the checks are failing currently. The changes have a lot of robocop issues as well which should be fixed. Also the CI build is failing at the moment. Some of the tests are failing because of the change.
problem Code looks fine, but build issue has to be fixed.
problem the build is still failing and there are issues which needs the team's attention. there is one warning and 1 error which needs to be fixed by the issue. according to the error, team should remove the debug code from the pull request.
problem Travis CI build is not passed. Though this was a bit common even for the second review, the 'codeclimate' issues are still showing.
problem No, the build did not pass in Travis CI. Several checks had failed but there was no conflict.
problem None of the tests - travis ci, code climate have passed
problem Everything is failing. Code climate has 56 issues. Build is failing. Haven't made a change since round 1.
problem The TravisÂ test has failed and overall coverage has also decreased. There were many errors in the build log of travis.
problem All the checks including the CI build is failing.
problem Build is failing in Travis CI
problem Code looks concise. However at few places, indentation is messed up.
problem I'm essentially keeping my feedback the same. There are places where I believe that better names could be used and smaller javascript methods could be used.
problem max_choosers name was not changed. As far as i understand it denotes the maximum number of slots and should be called max_slots. which is not changed. Apart from this code is good.
problem The code was well written during the last review too, it only missed comments. A few comments have been added but still a major portion of code remains uncommented.Â Other than that, the code is nicely written, follows guidelinesÂ and variable names are appropriate.
problem The coverage is actually decreased.
problem The team has done good manual testing but it would help to add few test in features to test the impact of the changes done in functionality of the project.
problem The overall coverage decreased, but not significantly. It reduced by 0.01%/
problem No new tests were written for this functionality.
problem No New Tests
problem Yes, team has added the test case
problem No new test cases were added. The new code changes don't change the modify the existing code coverage. The modifications were mostly on UI. They could have added capybara testing.
problem Unfortunately, I could not see any code written by the team for testing. However, the team has provided a description on how some of the edge cases have been handled. According to coveralls, the overall test has decreased by 0.01%. This could be one of the major topics for improvements with regards to this issue
problem No deploymentÂ provided so can't be verified.
problem The operation works perfectly from UI as shown in the youtube screencast. The App was not deployed anywhere (or the link was not posted), so couldnt test it by myself. Application could have been deployed during the second review for better understanding and trying out how the feature works.
problem The write-up is well written. It looks like they have improved the test plan sections, but still no automated tests in the repository.
problem Write up is good and self explanatory. Test plan helped a lot in understanding how to test it. As discussed in the earlier review, images could have been resized for better visibility. Was little difficult when one had to scroll along the page to view the entire image.
problem The writeup is well written with proper screenshots. I liked that the team has provided appropriate screenshots for specific scenarios which covers all the aspects of the project. However, the Test-plan section could be improved by adding the test code
problem I think with proper testing, this code is ready to be deployed onto the production server.
problem The code has passed the travis test and has addressedÂ all the issues of the Change Request. The code should be production ready after adding few more edge test case scenarios.
problem Overall, I think it could be deployed. There are no tests however written for this functionality, and there are some UI patterns that should be re-consideredÂ before deploying that do not matchÂ each other. When saving feedback, the ability to save feedback is automatically present and there is a button per row, while in the other location, you must first make a row "editable".
problem Apart from some code-climate change, the code seems to be ready to merged
problem The code seems to be working good from the screencast. My biggest concern was, if the link to deployment was given, it would have been easier to try the features. Other than that, capybara test cases could have made it strong to go to the production server. If they feature did work the way as it was shown in the screencast, it can be deployed to production.
problem The team has checked most of the points given in the problem statement. However proper testing should be done before deploying this project on the main server. It must be ensured that the overall coverage increases. Other than the testing part, everything else has been implemented as expected.
problem The build has passed. The are only 2 syntactical issues due to version difference.
problem The Travis Build has passed. The only conflicts remaining to resolve are the Code Climate conflicts.
problem Everything but the CodeClimate checks passed
problem The build passes and there are only minor warnings and issues which can safely be ignored.
problem In documentation it mentions participant.rb model file is changed to for increasing code coverage. However the file is missing in the pull request generated. There is no mention about changes in the assignment_participant.rb file. But that is present in the pull request. It may be a name mismatch or some files are indeed missing. I pointed it out during the first review but changes are not incorporated currently. The code overall looks good. Proper variable names are used. Commenting is required
problem The code consists of small methods that mostly test one thing. This results in high readability. The team has made an extensive use of 'context' constructs which further enhance the code documentation. Moreover, the team has improved the .sort_by_name method making it cleaner and easier to follow. This wasÂ complemented by the fix of badÂ names thatÂ were presentÂ in the first round (e.g. stu1, p1 etc.). One suggestion pertaining to the '#scores' block would be to use specific assertions of fields instead of testing the object via inspect method and comparing it to the string value.
problem I do not see any new commit after 5th November. In my opinion, some of the tests could be made more articulate in round 2.
problem No new code was committed in the second round
problem Code was not committed in second round.
problem According to the githubÂ page, it doesn't seems that new code are commited
problem The team has made two commits since the first review. The issues that were covered were '#scores' block and mock instance handling. However, the primary problem thatÂ theÂ specÂ isÂ testing an instance of AssignmentParticipantÂ class instead of Participant was not addressed.
problem According to the githubÂ page, no new test cases
problem The coverage has increased from ~77% to ~94% which is impressive. However, the previous issue was that #scores method ofÂ Participant was not called because the objectÂ that is being tested in this project is an instanceÂ of AssignmentParticipant class. This problem was handled by commenting out the #scores method of AssignmentParticipant so that Participant #scores method will be called instead.Â ThisÂ breaks other parts of theÂ code which depend on AssignmentParticipant's #scores implementation. The solution to this problem is to either define a new Participant class instance in the factory or to define it in the test code itself.
problem There was no working deployment presented.
problem Write up is good but the explanation of plan of work could have included some points like the approach taken.
problem The writeup is excellent. Very carefully written, a lot of detailed explanation. Some more background information about the functions can be more helpful, as well as syntax summation.
problem Explains the testing functionality appropriately. As mentioned in Review one, technicalities are explained thoroughly but the functional knowledge required to understand what the test is doing and why it is doing what it does is missing. Along with mentioning what are the mappings and return values, proper explanation of what the test is written for will be more appropriate in a document.
problem The writeup is detailed, but it doesn't explain why code in the model had to be commented out very well. That was a bit alarming.
problem There are several minor issues to be fixed before the code is deployed.Â 64 code climate issues Travis Build 1 error and 2 warnings. I guess once these are taken care of, the deployment is likely.
problem Few checks are failing. The checks suggest to use build or double instead of create in test cases.
problem The unit tests affording 95% coverage is great, but the code climate and other build problems are a bit concerning. I think this could be pulled in with more attention from the developers.
problem If they had presented a working deployment, then rest everything was done. So it could be deployed onto the production server.
problem The project covers a significant part of the functionality for testing the participant. However, the biggest problem is that the #scores method is commented out from the class AssignmentParticipant. Obviously this will break the existing code that relies on that functionality. Furthermore, the future testing will possibly become complicated because the object under test for participant_spec.rb is an instance of AssignmentParticipant as opposed to Participant.
problem The build does not pass the travisÂ CI.
problem The travis test has not passed
problem Checks aren't successful.
problem Yes, no conflict that's not resolved.
problem Travis Tests have failed. No conflicts in the pull request with the master branch.
problem There were many lingering code climate issues, and the Danger bot and Travis didn't pass either. A little cleaning could be done.
problem The build did not pass Travis CI. The reason isÂ because #scores method is commented out from the AssignmentParticipant class.
problem I'm afraid none of the three checks passed.
problem The code is almost perfect except for the lack of proper commenting. The author has not improved or updated the ocde since the last review, as the last commit was about 11 days back.
problem Review 1 comments weren't addressed. Better name could have been used than ca_testx. Also scenarios test the code and not the behavior- instead of- "when x happens, this method does this" we have - "x happens so y contains this". This isn't maintainable as changes to implementation will break/stale out these tests.
problem As mentioned earlier, no new commits were added by the author.
problem The team did not perform any commits for the 2nd round. However, the team did take note of previous review and added comments to the test cases making it easier to understand.
problem The Wiki should not include Conclusion and learning outcomes part, it is not a report of the project, but a page to show what the project itself is.
problem The write-up is good, but it doesn't feel much refined or improvised after the initial edit. As mentioned above, the image isn't visible clearly, which means that it wasn't reviewed much after posting. But apart frm that, the flow of the write-up is very effective, in fact one of the best that I've reviewed. The concept of giving a higher lvel view, and then diving deeper into the implementation is very subtly applied.
problem Their writeup is good, but i think the test plan should show how they plan to test.
problem The write up starts with introduction about Expertiza, Test Driven Development and Unit Testing. It then moves over to describing the problem statement, team members, test plan and implementation that contains detailed documentation on the procedure to set up the Expertiza environment, functionalities of Menu model, sample views , declaration of mock objects as test entries and finally the conditions tested on each of the method of the Node and Menu class. The various methods tested on the Node class include initialize, setup, site_controller, controller_action, content_page and add_child. Similarly the methods tested on the Menu class include initialize, select, get_item, get_menu, selected, selected? and crumbs.Â The write up also includes the screenshot of the Rspec tests that were run. The screenshot of the SimpleCov coverage report is blurred and not readable.Â The write up ends with concluding remarks, learning outcomes and References. Overall, the documentat
problem Other testing projects I reviewed have also given code snippets under the particular scenarios they are testing. The writeup doesn't help mapping out the test plan written and the specs code.
problem Yes, if must be, they must need more test cases ot cover some edge cases.
problem The team has worked on achieving the path coverage by taking the edge cases into consideration. But, as most of the builds have failed, it may need a working deployment for it to being deployed on the server.
problem The build #6205 of this project failed inÂ Travis CI. I checked the conflicts and the failures that caused the build to fail, and they are: 1) assignment function creation page is able show tab due deadlines Failure/Error: JSON.parse(child_nodes) JSON::ParserError: A JSON text must at least contain two octets! # ./app/controllers/tree_display_controller.rb:96:in `child_nodes_from_params' # ./app/controllers/tree_display_controller.rb:207:in `children_node_ng' # ./config/diagnostic.rb:11:in `call' # ------------------ # --- Caused by: --- # Capybara::CapybaraError: # Your application server raised an error - It has been raised in your test code because Capybar
problem 1 check is failing so the build has not passed.
problem Travis build failing atÂ ./spec/models/menu_spec.rb:120
problem The Travis CI did not pass this time.
problem Travis CI build indicates that the tests have failed. The code climate issues in the Danger Bot also did not pass. The team must look towards cleaning up the code.
problem The travis CI test did not pass. Suggestion: Rectify the Travis CI issue.
problem Yes, the code already followed all the good conventions earlier, except the lack of proper comments. The code still lacks comments, and the author hasn't made any changes since the last review. But the overall code quality is upto the mark.
problem The code quality is good however, it can be improved significantly. The code lacks proper comments and contains many if else statements. They could have been refactored and avoided.
problem There are a few issues regarding code repetition and extra white space (especially in the controller rspec file).
problem Overall the quality of code is great. There some variable which does not follow naming convection.
problem Code looks okay, Suggestions for improvements not done.Â build still fails
problem The code is well-written, follows code standards. The naming conventions are followed. However, in some parts code is not formatted.
problem The code is well written, follows ruby guidelines and variables are aptly named. However, the changes are extensive and there are virtually no comments. The code can do with significantly more comments to explain what is being done.
problem Yes, the team did add test cases and the coverage increased too. But the team didn't put any efforts after the initial review round, since the failed tests are still failed, and there are no new commits since 12 days.
problem They did add the test-cases but the coverage only increased by .3 %
problem yes good number of tests added coverage increased a but but i would like to see more -ve tests. Mostly +ve test cases are covered in the tests
problem Seems to be working as intended. But all the features have not been implemented. The documentation mentions future work but no new code has been added.
problem It seems that everything works, though it was hard/confusing to find everything as per the instructions on the write-up.
problem Very good guidance. Works as intended. This project is about enhancing Juniper bookmarks. The features work as they are supposed to. Automated RSpec tests were added. Could have described the automated tests in the wiki.
problem The solution of problem 1 was not clear from the write up, no explanation has been given.
problem The writeup needs significant improvement. "No clear explanation is given as to which files are edited for which reason. Only file names are stated along with changes made. Why the changes were made and what do those changes correct is not given." - This review was given by me last time,and no improvement has been made in this regard.
problem The write up is good, contains lots of pictures to show the added functionality. I found the test steps a bit confusing and it made validation hard.
problem The write-up is very detailed with comparisons between previous and new versions, as to what features have been implemented but lacks on explaining how they are implemented. It can be improved by adding how the features have been implemented, why they chose this logic to implement the features.
problem the Writeup misses out on elaborating the approach taken, it just lists the problem statement and jumps to test cases and fix. I would like to see more details on the approach taken.Â The "why" is missing
problem Documentation mentions the steps, problem statement, solutions and screenshots. The description are detailed. However, I feel there is no need to give screenshots for tests written.
problem The write-up is well written and looks through. The write-up details what has been accomplished and there are plenty of screenshots to support this. However, there is no mention of what code has been changed/added and why the authors chose this change.Â Test plan has also been well written.Â The parts written are well written, but there's a good scope of improvement.
problem Since the TravisÂ test has failed, merging the code would not be a good idea. The project doesn't need to be redone from scratch, some modifications to the existing workÂ could make the project ready for deployment.
problem No, all the features have not been implemented e.g 1. A reviewer can be recognized or credited if he added useful bookmarks i.e if the author has made use of the bookmark. 2. A function to add badges automatically if a participant had submitted more than threshold number of useful bookmarks. plus build did not pass as well
problem Yes, the code seems good to deploy if we consider the manual testing and the video demonstration. But since it didn't pass Travis CI, this claims seems a bit of a concern. If we ignore the fact that lines of code was >500, and thats why Travis CI failed, but still there are a few lingering issues which the Travis CI pointed, which still hasn't been fixed. It seems more of a patch, which would require more patches to patch in the future.
problem This code will need to be refactored, however, we will not need to build it from scratch. Only some functionality has to be divided into chunks and moved into helper functions. The functionality works well.
problem No issues codewise. Can add test cases and after thorough testing It can be deployed. Yes other team can take up and fix the minor issues and build pass.
problem build fails that needs to be investigated , once that is done i dont see why the project cannot be merged with the mail branch. Loot of good work has been done and merge with the main branch would bring the work to fruition.
problem The code is not altered much but it follows the standards and not changed in the second round
problem No. I do not think the code is ready to be deployed. I found the code change hard to understand, there are no comments and neither has the logic or rationale behind the new/changed code been given in the wiki. Besides, the build fails and there are a host of issues thatÂ need to be fixed.Â Although all this might only be trivial issues and can be fixed rather easily, the code as of now, is not deployment-readyÂ according to me.
problem Unable to login to the expertiza url
problem The code has been merged in a good way and there have been no merge conflicts. However, the Travis CI was failing and the code climate check was failing too. This is something that the team must look into and make sure that the changes that they have made are consistent with the existing expertizaÂ code.
problem Travis CI did not pass. Code climate also has 121Â issues to fix.
problem No, the Travis CI had failed. Yes, there were a few conflicts, like the lines of code was very large for a commit (>500), also there were a few pending test cases in the pull request.
problem The build isn't passing one of the added tests, but it looks to be a simple fix.
problem Yes there is one conflict that must be resolved to go ahead reported by TRAVIS CI.
problem Travis CI build is failing. Lot of warnings and issues that have not been fixed. Many of them are trivial and easy to fix.
problem Build fails. pls check the same. There are no conflicts with the mail branch.
problem Build fails and there are aa plethora of issues (121 by code climate) and several warnings.
problem Code is written well with simplified approach. Naming conventions are standard without long functions. DRY principle is followed.
problem The build did not pass, their test failed. It seems that theirÂ grades_controller_spec.rb has some problems.
problem The code is well written. Although as suggested earlier, the team has not added comments to the code. In the wiki page, the team displays of how the code was before and after. But, I still feel this is not adequate information for a layman to be able to follow line by line what the code does. Adding comments in the code for future projects would be my best suggestion. Or, as an alternative, briefly explain in a line or 2 as to what the code does.
problem Code written well. Remove the unwanted methods, there are few duplicate methods which can be removed.
problem The code was well-written and no problem with long or bad names. But, no comments were present. Commenting would have made the code easier to understand. Also, refactoring was not done.
problem The code hasnt been changed from the first round. New definitions that were added follow naming conventions properly. remove_administrator remove_instructor Viewing their pull request and code climate bot, there were few places where identical blocks of code can be found.But they are in the spec files.They could have refactored those areas alone.
problem The code is really well written , there are no bad names. The functions are also easy to understand. However, I would suggest them to include more comments in the code so that it becomes clear for the person reading the code that what the function and changes are all bout.
problem The writeup is well written but not as explanatory as required
problem Unfortunately the authors have not added any more text to improve the writeup as suggested in the first round of reviews.
problem The code is very well written as previously said. However, some test cases are still not passing and that may be troublesome if deployed onto production server. It would be a really nice opportunity for students in further classes take this up and improve the work so that they can complete the work which was left incomplete due to time constraints.
problem Issues with the build Can be fixed quickly. Issues seem trivial.
problem The build passed in Travis CI and there were no conflicts. But, some issues are not fixed like refactoring is not done and block has too many lines. These issues should be considered for a well written code.
problem The code was already very well written. But the author did not made any changes after the first round. The lack of proper commenting still remains.
problem The code was written good enough. THere were problems with indentation. I have seen some improvement compared to the last round.
problem They have added test cases but very limited. The code coverage was just 14 percent.
problem Yes the team has added tests. I am not sure of the increase in coverage as it is not mentioned in the doc. however, the team has very well explained how the tests were done and what areas they have tested.
problem Yes, everything that the project required to do works. There were a few things which caused issues in the pull request, but none of it related to the functionality of the product to be tested, but rather related to the code complexity. Even the video demonstration clearly shows the changes implemented.
problem The link does not work.
problem Haven't deployed so could not manually check. Though according video and wiki page it look likes that teh code would work fine.
problem The test cases covers the required test scenarios and the system operates as intended. The video file submitted though seems to crash. A link could have helped.
problem The team didn't no provide the link for the deployment, but according to the video they provided, the features worked well.
problem The write-up is very self explanatory. It successfully covers each and every aspect of the work done by the team, and also, to an extend, delvers what mindset they had while working o the project, which is very great. Just one sugestion is that, instead of simply dumping the files, they could have made a quick note of what the code in the file does. No one want to go through each and every line of code just to get an idea what it is meant to be.
problem Overall the write up was not bad. Here were some of the things I believe that could be improved: Problem Statement;Seems to be wrong. I believe it should be included in the background as it merely describes the files that they are supposed to work on.
problem Very impressed by writeup. One suggestion: Problem statement is not mentioned thoroughly however, solution is very well ellaborated with screenshots and code snippets.
problem The wiki provides enough introductions for this project. According to the wiki, I can get a clear insight about what the project is, what's the issues include in it, why the team do things as the way they said and the tests they give to make sure the functions work properly. However, the description for the first issue is not very clear and makes me confusing.
problem The code is almost perfect, apart from the code complexity issues, which in my view isn't very tough to fix. The project need not be done from scratch, and it is certainly a good starting place for future teams to pick up.
problem The feature implementation section is good to go. However the test cases can be improved on a lot. That doesn't mean that the test cases shouldn't be deployed.
problem Excellent work but the codeclimateÂ build has failed
problem The team gave fixtures for the issues exist, but to make deployment, it is better to add more tests to make sure the function work properly.
problem Yes, the pull request did pass the Travis CI. It didn't has any conflicts with the base branch, but it did have some unresolved issues which needed to be fixed, namely: cognitive complexity was 6, and condition size for two files were too high.
problem The build did not pass travis CI. I did a demo of their project and it seems to work given the credentials provided. THe encountered some minor indentation errors but otherwise the feature addition/fixing part seems good. The test cases written for the controller was very little though. The code coverage was just 14% approximately.
problem The code passes for the Travis build as well as Danger Bot. However, it fails for code climate with 3 issues yet to be fixed. In totality, the pull request does satisfy the need to pass the required builds.
problem The code has no bad names, or long functions and follows a good coding style.Â However, the suggested change was not implemented which would make the code more "DRY".
problem There have been no new commits since the last round of review. The integration with master branch still has conflicts to be fixed.
problem The build for the pull request has not passed and has the same issues from round 1.Â Build logs suggest that out of 4 build jobs, 3 jobs pass and 1 job still needs work.Â According to the build job 4 log, there is a json parser error which needs to be fixed.
problem No, there have been no new additions to the test cases since last round of review. The code coverage still remains the same as before, with an increase of 6.6%.
problem Yes, both the the issues seem to be fixed from the screencast video. It clearly explains the before and after scenarios and the system works as expected.Â The test plan is still missing for the fixed issues.
problem Yes, since the issues are fixed as required, I think that the project can be merged to the production server. However, there is some work on the conflicts upon resolution of which the fixes can be included to the code. I don't think that there is a need to take another approach for solving the issues.
problem The code seems clear and dry. However, a few comments would have made the code more readable.
problem The travisÂ tests have failed. There was one main failure in the TravisÂ log which could be addressed.
problem The team did not add an automated test plan. But manual testingÂ was clearly demonstrated using screenshots.
problem The write-up was good and clearly explains the issues faced and the code changed. It would have been much more clear if screenshots of git file changed were posted.
problem well written document my suggestionÂ is put the cropped version of images or even links to images is also fine.
problem The CI build was failing in the previous submission as well in the new submission. The team should have corrected the same.
problem Although the test coverage is increased according to github, i could not find any new test cases in the project. The team has not added any test case for the correction.
problem the code looks fine. The only concern is related to the CI build which is failing at the moment. Some of the tests are failing because of the change.
problem No, the build did not pass. It seems that airbrake_expection_errors_feature_tests_spec.rb has some problem.
problem The code seems to follow good Ruby on Rails Coding practices. The implemented code is DRY. They could have increased commentingÂ by making comments more descriptive.Â The comments for say a particular function could have includedÂ the input arguments, their data types and the return value and its data type if any. For the second round they haven't added any new commits and haven't changed their implementation.
problem The pull request that the authors have submitted does not pass the Travis Bot builds. But the bot has failed in the tests for which the authors haven't changed any code. So overall the pull request doesn't seem to break any code.
problem The team has included a thorough testing plan but I couldn't find any commits to any of the rspec testing controllers. They could have added as per there test plan. These tests could have been included 1) Login as Instructor4. Add a new assignment Assignment_Instructor4 under the course Course 617, Spring 2016. 2) Make student6400 as the participant of that assignment and logout. using Capybara and Cucumber.
problem The authors have documented the steps they did to solve the issues in a clean manner. Although they haven't mentioned any particular design principles or design thinking that went on in solving the issues. They have explained all the functionalities of each file they have modified and stated why they have modified the particular file. One thing they could have added were class diagrams and dependency maps. Or some pictorial representation of the flow of each task which will help the reviewers and instructors to quickly catch up on their idea. It doesn't seem like the authors have updated their writeups since the last submission.
problem I think the authors have done a good job in fixing the issues but they should have added tests to check if their code does handle all the possible edge cases and does not break any other code functionalities. I think this is a good starting place for a future team to pick up this project and implement some testing specs regarding the functionalities that the authors have fixed.
problem Yes, theÂ code seems well written and there was no issue with the naming or functions used. However, a few comments could be added to impersonating_as_admin.
problem The write up is well written and self explanatory.Â It would have been better if the screenshots were of standard size but that is not a problem since the purpose of the document is just to explain the project.
problem The build was failing last time as well but not fixes were made.
problem The coverage has actually decreased.
problem The code is more about refactoring which is mentioned in the wiki, but I do not see any of the codeÂ in which changes are made. Could have mentioned them in the wiki for better clarity.
problem Bad names like "review_num" have been used.
problem The code is nicely written overall. It follows Ruby guidelines and DRY principle. It would be better if more comments are written.
problem The code is well-written and follows good programming style, has good naming and is DRY. The team has not implemented any suggested changes since there has been no commit after first round.
problem The last commit I see was 23 days ago, which seems that there wernt many changes done in the seond round. The wiki mentions the suggestions at the end, so it would have been good to have the code changes and tests for the same.
problem The team could have added more test cases as they have mentioned about refactoring the code. The refactored code and the screenshots of the test cases would have been better to display in the wiki for future students.
problem The team has added tests and the coverage improved by a small percentage. More tests can be added to further improve coverage
problem test cases were not part of the requirement doc. Test plan added in the wiki. Could have added more negative test cases.
problem I feel that the project could cover more test cases which would have explained the functionality better. The sql that has been mentioned, could have no results as well, so covering negative results would have been better.
problem Most of the functionalities that were required have been implemented but the final changes haven't been merged due to some build issues on Travis CI. The tests are quite comprehensive
problem I can't really tell how to navigate to this portion of the project in the application. The writeup is not descriptive enough for me to know where to go to test it.
problem I found the write up to be same. There is more scope to improve it with more explanation and test cases, specially the links to the refactored codes could be added for the other teams to know.
problem The writeup is clear and has illustrations to explain the flow. However, none of the code is added to the documentation. The project also only defines the test added but could add more details about the increase in coverage
problem The authors should have added screenshots for the changes made in the code. Otherwise, the purpose and work done has been explained well.
problem The writeup leaves me unable to really determine what was done to the point where I can examine the work in their application for correctness, especially since, as a refactor, the behavior should not have changed from the base expertiza application.
problem The writeup is good overall. ButÂ it would have been better if more code snippets were added along with explanation of why certain methods are obsolete.
problem YesÂ I think with additional testing it can be deployed.
problem The code is written in a modular way but there are some errors as shown by the CI. If these are fixed, it can be merged with the main project
problem I feel there are more number of test cases that need to be covered before deploying this in PROD.
problem The code build passes the travis CI test and it has notÂ conflicts with the base branch. However, the team should resolve warnings.
problem The build seems to have passed, but there are not many test cases listed to check the same. There is more scope of test cases in the same.
problem Most of the tests passed. However, a small fraction of the tests have failed and the code needs to be modified to incorporate these changes
problem Travis CI test has been failed on Github.
problem Few issues with the build but I feel they are trivial.
problem The pull request did not pass the automatic build requirements. It seems as though this team worked very hard to try to fix the build errors.
problem No new code was committed in the second round. I would have really appreciated it if the team could have taken the time to add comments, and fix some "codeclimate" issues.
problem I see really less commits in the second round. The last commit was on 31st October. It would have been really nice if they have worked on the project further to enhance the work they have done.
problem Same test plan as previous phase is present , no new cases added
problem Team has added capybara test. but team could have worked upon improving test coverage. Team can explain test description in test plan in wiki, step by step so as to understand what all test scenarios were covered.
problem The test cases added by the team pass. But overall coverage has decreased. I would suggest the team to have added more test cases for the new lines added in the controllers.
problem The team has added test cases. But, they haven't explained it well
problem The team added the test cases but the coverage did not increase.Â Overall coverage decreased (-1.04%) toÂ 46.605%
problem The team had added test cases in the first round of submission itself. The overall coverage has decreased by 1.04%. The test covers the logic implemented by the students.But reduces the overall coverage. The team did a good work in using Capybara and testing the web functionalities too.
problem The changes works as per the changes. Test does not cover entire scope
problem Everything works from their UI. Their peer review plan works as intended and clearly explains how to test on UI. There are SQL errors when trying to delete a user which is tied to some assignment. Although the team has mentioned it is out of scope of the project, future work could be to remove those SQL error displayed on pages and give a pop up / alert box, saying your user is tied to an assignment.
problem Writeup is written well and explained properly with good indentation, content and screenshots. Team could have explained test plan in more brief so as to understand number of test scenarios covered.
problem Yes.From the system and code, these code changes seem ready to be deployed in production after heavy integration testing as issues seem to be working, but github pull request shows more fixes to work upon.
problem Although as per functionality, this code is ready to be merged and the team did put in a fair amount of work into it. Still, I believe this project can be bettered by another team in the future by refactoring some the code to improve code writing principles and also improve the wiki documentation.
problem The code seems ready to be deployed as the features are working as intended but it would have been better if the code was refactored.
problem The code can be readily merged into production. 1) I felt code climate failing not an issue, because their similar blocks of code were on spec files and deleting 2 different roles is the same functionality in the end. Few places has indentation errors which can be fixed before merging. As suggested earlier, removing the error for SQL and replacing with some form of alert box could be helpful for a future work.
problem The build does not pass, but only because of codeclimate issues. The code written by the team, in terms of logic is absolutely perfect. But certain conventions were not followed, such as "proper indentation was not followed", "DRY principle violated". Although these have no impact on the functionality, these coding practices are industry convention and maybe the team would want to consider giving them equal importance for the next projects.
problem Build is not passed. Build failed Travis CI. Team can workÂ to fix suggestion given on the pull request.
problem I coud see only few builds passed the Travis Cl. There are many builds that are failing and should be worked on.
problem Build did not pass. Version compatible code can be written
problem A better explanation on the test cases would have made sure that the code is ready. I feel that some more tests need to be done before deploying the code.
problem The code is ready to be deployed on production server with few caveats. At some places values and logic is hardcoded. This project would be a really good starting point for further work.
problem The code is functionally ready to be deployed in the production server, because it is sound and even passes the build of Travis CI. There are a few minor issues due to Cognitive Complexity of names of methods, lines of code and a few indentation errors. If they are fixed, the code is complete and will pass the build of codeclimate as well. The team has proceeded in the correct approach and there is no need for the project to be redone from scratch using a different approach.
problem The team has covered the implementation of the points given in the problem statement. However, testing of the project is necessary. This is one of the point which cold be worked on by the future team. According to codeclimate, there are 7 issues which need to be fixed as well. The future team could improve on those points.
problem From the file diff in GitHub, it looks the code is in good shape. There were a few suggestions provided during round 1 review. If those could also be integrated, it would be better. The test cases are successfully running. But the functionality could not be tested due to lack for steps in the wiki.
problem The build seems to pass, but it would have been great if the test cases were explained better. Maybe some screenshots or a video would have been easier to test.
problem Yes travis CI is passing. Code climate has few issues but they can be easily resolved.
problem Build passed. codeclimate - 7 issues to fix. 2/3 checks were passed. Issues seem trivial.
problem Code is very neat and readable. I appreciate you attention to following good syntax practices. There is some similar code was exists in the controller action method and the content page method but simple to bring out and make dry. Overall great job.
problem The code is well-structured, the team uses context and it properly to separate different cases and using each to make the code DRY. However, it seems the object used to test are not all stored in the factories file properly.
problem The last commit was listed as 12 days prior to this review. But the code looks to be in great shape so there was no need for new additions.
problem Not ready. There are still a few errors in Travis CI and code climate.
problem As mentioned above, they can make it better by fixing some issues.
problem The travis test had failed and codeclimate shows indentation and other such minor errors. I think that the team just needs to work on the styling and following some Ruby guidelines and they are good to go.
problem The project is almost on the stage that it can be deployed on the production server. However, there are few test cases that are failing as shown on the git. If these minor flaws are fixed then the code is good to go.
problem There is a minor code climate error as mentioned above, similar code. An easy fix and you will be green with the climate check.
problem The build didn't pass in Travis CI. There is still an error.
problem They did a good jobÂ and they can make it better by fixing some issuesÂ . According to the pull request page, the Travis CI build failed and there are 5 code climate issues to fix
problem The pull request is the same as the previous one. And as in the case of the previous one it fails.
problem The code passes almost all Travis CI . However, there are really few which fail.
problem The code was not much changed after the first round. They added a few more sanitation check and rspec. Functions are not long enough and understandable.
problem Overall the code looks good with most of the coding standards being followed. However I think it lacks proper commenting and also there were few strayÂ pieces of commented out code lying around. Adding few more comments and deleting unused code would be better.
problem There were not any bad naming in round 1 as well. Comments could have been added for new additions which is still missing. There has been no DRY issues
problem Yes there were some commits fixing the travis and code climate issues.
problem Test cases added but the video is not very explanatoryÂ in itself to understand the test plan.
problem No new test cases were added
problem Automated and manual tests have been added and coverage has increased by a very tiny amount.
problem Yes the team has added test for the UTF encoding acceptance. the coverage is not 100% and not tested with varied inputs but i believe would suffice for sanity check. Although the description of test in rspec file is ambiguous not clearly mentioning what exactly the test is expected to do. There is no test available for the issue 2 documented
problem Videos provided and the project is not deployed so cannot test from UI. But the issues are fixed and the system is working as expected.
problem It was not deployed so couldn't check manually
problem Write-up is little vague. Some are not explained properly.
problem Watching the videos, I feel it is ready but no deployment link.
problem As It did not pass the test, it is not ready. For a future team, end of this project should be a good starting place.
problem According to write up, it's good to go but since there is no deployed link I couldn't manually check.
problem I believe this change that affects the system as a whole, needs more test to be performed in all affected tables and functions to be sure, no other part of the system is broken.My opinion is that, once all parts of the system test is done, corresponding to this centralized db change the code can be deployed to production.
problem Build did pass successfully. Could have written version specific code to avoid errors
problem Travis says some tests have failed. No conflicts though
problem No, It did not pass travis ci and there are many conflicts that must be resolved.
problem Few minor issues with the build which can be ignored.
problem No, build pass did not pass Travis CI
problem Not all changes has been verified successfully. few code climates rejects has happened as well.
problem There are no new commits during second round.
problem The team did change the project as there are 2 new commits. The CI build is still failing .
problem The team has added test cases but the coverage did not increaseÂ by much
problem The write-up is well written and organised. Everything looks fine. The team should have mentioned about the approach taken to solve the mentioned problem statement which will make the implementation easier to understand. Also the screenshots could be a little better.
problem The code has mast elements ready but there can be more test cases generated with better test coverage. The code need not be rewritten from scratch, it just needs to include some more of the expectedÂ functionality
problem According to write-up and video yes but since I couldn't manually check I would say no.
problem There must be some test cases that should have been covered according to Travis CI. Also the build has failed. However, the team claims that some of the tests are running locally. If some of these points are looked upon, the code would be ready to be deployed on the main server.
problem the build fails and there is one warning and one error which needs to be fixed.
problem There are build failures mentioned but IÂ don't think the errorsÂ are due to this team's code, hence, giving them the benefit of doubt.
problem There were some build issues raised by Travis CI which have not been handled yet. However, there are no merge conflicts with the master branch.
problem No pull request link is provided
problem Travis failed
problem No build did not pass. 1/3 checks very successful. It is fixable and the issues are trivial.
problem The build in Travis CI failed. 3 out of the 4 build jobs had passed. The build job failed in the features folder. The branch did not have any conflicts with the main branch
problem The code us good as mentioned in the previous rounds, except the lack of proper commenting. The authors did not improve the code from the previous rounds in this aspect.
problem The code is well written according to the video. Since there's no github submission, I went to the sumitter in the pull request to check his work. It seems that the code is relatively good. There's some minor indentation and alignment issue. And not much explaining comments. But other than that, no bad name, no long function.
problem The code is difficult to understand. There are cases where factories are used and then later replaced by mocks in the individual test cases. The code also does not appear to be DRY, as several of the mocks appear redundant in the context of the plethora of factories built.
problem For each method, there should be multiple test cases, but they put all tests for a method together wrap by a single it '.....' do, they should consider to add more it '......' do, to separate each test case, so the reader know what are they testing.
problem Yes, the team made commitsÂ days ago, but then it seems that they didn't follow-up with the feedback they received on the pull request, as their were 7 issues, though of minor severity, which required fixing, and then there were no commits after that.
problem There's no upload for the local folder. It seems that no new pull requests has been committed during the 2nd round, so I would guess no new code being committed for the 2nd round.
problem They are trying to fix code climate issues, but there are still many failed, and no code change to improve readability.
problem Involves fixing code climate issues.
problem The team did not attach the link for the github repo along with the other files submitted. This makes it difficult to comment upon the commits made. However, from the video link it can be seen that the test cases have improved to give a full path coverage.
problem FRom the Pull request i see Coverage Decreased, But from the Screen-cast looks like 100% covered When i tried running manually i get the below errors Â 1) ReviewResponseMap #final_versions_from_reviewerÂ Â Â Â Failure/Error: prepare_final_review_versions(assignment, maps)Â Â Â Â Â Â Â Â NoMethodError:Â Â Â Â Â Â undefined method `prepare_final_review_versions' for #<Class:0x007fab83429010>
problem The team did not add any test cases since they had achieved a 100% coverage in the first round itself. However, certain changes made to the test cases included using proper naming conventions for attributes and following the DRY principle effectively throughout the model file.
problem Build says the overall coverage decreased but the coverage of theÂ Test has increased.
problem The system operation is verified and works as intended as demonstrated from the video.Â Also, all the test scenarios are covered.
problem The write up has some great information and snip its of code. It would have been a great addition to have included more discussion on the overall design of your test cases. Overall a nice wiki.
problem This is where the project lacks the mos. The write-up isn't very informative, specially for an outsider. It states the points very shortly, without going into much depth. Also, the writeup bombards the user with lots of un-relevant information and pieces of code, which make it feel very long, although lacking significant content. The writeup could have been more detailed, and could have omitted the unnecessary parts, like dumping of code, and not explaining what it does.
problem The writeup is a bunch of codes, there's not enough explanation.Â The "allow" function is important for the mock functions. But it is explained in no place.
problem The write-up is difficult to follow, and doesn't provide much insight into how the testing code works. Despite having a test plan section, no test plan is included.
problem The team has worked on improving the wiki document. The writeup now includes the Test plan sectionÂ that was suggested in the first round specifying the how the team setup an expertiza environment, the model functions used and the mock instance built for testing the model file.
problem Still missing the details.
problem Yes, apart from the 7 issues of minor severity from codeclimate, the code is perfectly well to integrate with the project. No, the project need not be planned and executed from scratch, it is implemented well enough.
problem The code is good because it covers the scenarios. But one thing that prevents the 5-star is that they do not have enoughÂ commenting and seems to be not that detailed and careful in terms of the explanation.
problem It is very difficult to recommend merging this code. Although it builds and appears to function correctly, it is not properly documented. It is difficult to tell how the code works and whether test cases introduced actually function as they intend.
problem As soon as they fix code climate issue, and separate each test cases with more it '......' do, it is good to deploy.
problem It can be merged after fixing the code climate which has 7 issues(needs to follow the coding standards )and need to work upon the overall decreased code coverage.
problem Yes, the code did pass Travis CI successfully, but as mentioned earlier, the code did fail on 7 grounds, of low severity. This should have been fixed by the team, as the issues were very small, and required just minimal follow-up.
problem Great job with your pull request and passing the Travis CI build. There are several code climate failures that could have been addressed many to deal with incorrect formatting and extra parenthesis or braces. Simple fixes so great job!
problem Travis CI build passed, But Code Climate identified few issues
problem The Travis CI has failed and also code climate.
problem The Travis CI build passed for the test cases. Also, the code passed for Danger bot. However, there were some issues for the code climate that required to be resoled. Overall the pull request satisfies the required criteria.
problem The code is written very well. There's some minor issues (sometimes there's duplicate "allow"s. But actually in the same "describe"Â just one "allow is enough. On the other hand, there's no bad name, no hard-to-understand functions. Comments can be added just a little bit more to help people understand. Some comments are not supposed to be there (such as discarded codes)
problem The source code is mostly written in a coherent way and is straightforward to follow.Â The 'context' blocks are extensively used which increases the project documentation. The commented chunks of code blocks that were present in the 1st round are mostly removed. There are still a few instances left and I would suggest to remove them because they reduce the overall readability. I would also suggestÂ to decomposeÂ the 'it' block inside the '.final_versions_from_reviewer' by moving the common setup to a before(:each) block and spreading the assertions across several 'it' statements.Â Another improvement would be to remove the 'xit' code blocks because they only increase the clutter and do not add any value to the code. Adding one comment explaining why the blocks are no longer necessary would do the job.
problem The number of commits that are made after the 1st round is impressive. The team has made a significant progress during the 2nd round, however I would suggest using more descriptive names for the commits so that it becomes easier for the reader to refer to them in the future.
problem The command to run the test cases is given in the wiki. Better thing would have been to provide the screenshots of the test cases and git links to the code to make the wiki more concise and well explained.
problem The test coverage on the diff in this pull request isÂ 100.0%Â (50%Â is the threshold). This pull request will bring the total coverage in the repository toÂ 28.7%Â (-19.
problem The features work as per the given instructions. Though there seems to be more scope for extra test cases.
problem The write up has a lot of code in it, which does not show up what are the changes exactly made. It would have been better to put the links to the git files where the code changes are made for good comparisons. Also, with this the wiki size would have reduce.
problem The writeup hasÂ covered nearly everything we need. all the function details are in the writeup, as welll as each function. However, I think there's too much code and not enough textual explanation.
problem Some parts of the writeup are not includeed, such as test plan.
problem More details about the test cases can be given in the write up for a better understanding.
problem Still a lot of code on the writeup page.
problem The team has improved the writeup since the 1st round. The 1st round version consisted of the copied code from review_response_map.rb and review_response_map_spec.rb files. This version clearly defines each test case and in some instances elaborates on the inner workings of the blocks for example ".import" Method discussion. However, design principles and patterns that were used in this project are still missing from the writeup.Â One thing that stands out in the code is that every mock object is defined at the start of the file. The team could provide a rationale for this decision and why it is superior to for example using different mocks for each separate test suite.
problem The code seems good enough to proceed, but with few more test runs as I can see alot of code added.
problem Most of them are good, but some edge cases should be considered.
problem All is good. Only one code climate issue needs to be fixed before complete.
problem There is only 1 issue stated in the Code climate regarding code refactoring. If that is done, this code can be merged.
problem The given source code is ready for deployment.Â The object under test is fully covered and all of the test cases areÂ implementedÂ correctly. The build successfully passes Travis CI. The future team will have no problems in picking up fromÂ here. However, there is a room for further improvement when it comes to simplifying several test cases, especially the '.final_versions_from_reviewer' block. Moreover, 'xit' blocks need to be removed because the final version should not contain any tests that are in the pending state.
problem Not really. They did not pass.
problem Yes, passed Travis CI. Only one code climate issue
problem The most recent Travis build was run 2 days ago and the build log says that it has failed.
problem The team has completed the missing code in the file oscillator_node.rs which generates different wave forms like sine, square, sawtooth and triangle. They then created the file oscillator.rs that generatesÂ objects and calls methods to run the different oscillator type examples. The code in both these Rust files have good comments that clearly explain what every snippet does and the significance of variables. This made it easy to follow the syntax and semantics of a new programming language like Rust (Rust is a systems programming language that focuses on memory safety and concurrency). The variable names used are intuitive and the code is well indented. One issue that I can point out here is that the code is lengthy and complex with a lot of redundancy; especially those that define the audio context, destina
problem No test cases present but test plan covers it.
problem This project does not deal with UI
problem This project doesn't involve the UI. It focusses on audio processing by fixing the missing audio nodes in Servo's WebAudio standard. Precisely it generates the sine, square, sawtooth and triangle waveforms. The code that was modified and included from scratch works as intended.
problem The overall structure of the code looks good and all the coding standards have been followed. I feel like there could have been more comments to support the large amounts of changes that have been made.
problem No proper commenting . authors havent improved as expected.
problem The code has been written as per the coding standard. The code written by the team adheres to dry principle. However, as per my first review comments it is advisable to follow better naming conventions. The team could rename their function names such as the below one to something smaller such as get_time_diff. The code needs refactoring in names and addition of comments.Â def get_time_diff_btw_due_date_and_now(due_date)
problem Issues related to not mentioning the functionality of each method have been resolved. The wiki now mentions what each method does and what issue does it fix. Only issue with the current codebase is that it contains very long functions that could have been refactored and broken down. The 'perform' function contains a lot of lines and has tons of if-else statements.
problem There's still some minor style issues in the code regarding unnecessary parenthesis.
problem Yes, the team has made few code climate fixes and also added tests for the UTF-* encoding issue. though no test is available for the sanitize fixes.
problem Yes the team added test cases and the overall test coverage has increased. But the team seem to have only modified the existing test cases. The team could have implemented test cases of their own.
problem The team has added 2 test cases in theÂ sidekiq_mail_worker_spec. More test cases could be added to fully test the functionality.
problem Test coverage has increased by a very small margin. More tests would have been better. There are only 2 tests. There are various other scenarios that could have been tested like missing or wrong attributes in request,email.
problem Yes the team added the test cases. 45/69 new lines have been covered in theÂ tests. good work. but I feel that they could have added additional -ve test cases.
problem No new code or improvements have been done in round 2. Only documentation has been edited. The code could have been improved a little after the suggestions were given.
problem writeup is too concise code were addded. But the implementation was not explained in detail.
problem Lots of improvement over the last phase. Many recommendations have been implemented. The write up is well formed and structured. The entire flow is explained along with files changed/methods implemented in each stage. Some formatting issues so -1
problem The code is ready to be deployed in my opinion to the production server. The team could improve the quality of their code by visiting the code climate tests.
problem The code implementation is correct , so with more edge test cases and after resolving the warnings in the travis test, the code would be production ready.
problem The code is written well but there are some small build issues as pointed out by Travis CI which need to be rectified for it to be deployed
problem Code is ready to be deployed in production if it is refactored and broken down into smaller chunks. Maintenance might me tough on this one. Functionality wise, works great!
problem There's a lot of changes made to the project to incorporate Sidekiq, but assuming that's fine, the project is ready for merge.
problem There are a few warnings thrown by other tests that must be rectified, but otherwise ready to deploy.
problem The code has been merged in a good way and there have been no merge conflicts. The build did pass the Travis CI. The code climate test failed but those were small issues which can easily fixed by just revisiting the code. Also the team have added a debug code which will need to be removed.
problem yes build passed but there are many code climate warnings that can be easily cleaned up such as tips for refactoring and unassigned variables. A more careful look at the tool warnings was required.
problem Code build passed the Travis CI build with some warnings thrown by the other tests.
problem The overall test has coverage decreased. However, the RSpecÂ tests added to the project seem appropriate.
problem The code that is written has long functions. Few names do not really provide the gist of what the function is intending to perform
problem Write up is Okay, The test plan comes before solution / approach section . pls change the ordering. there is no reference sectionÂ instead of putting screen shots of code it would be better if the authors had put code snippets
problem 1) The write-up is comprehensive and clearly explained. 2) Should explain the test cases in more detail.
problem 1) Yes, just could not check the mailing functionality. 2) Also the test coverage needs to be improved.
problem Without a video or instructions, I cannot easily verify that the solution works since there was an error thrown when I tried to follow the recipe. The error occurred while I was trying to request an account. More detailed testing recipes would help. Getting the accounts and their email addresses set up in the deployment is the main difficulty.
problem The team added the test plan section but it was too short and did not explain all the test files created and/or modified. The implementation section could do without the many code dumps. Otherwise, the writeup was concise and effective.
problem It looks like the code is almost ready, but there are simply some failing tests to get past.
problem Build failing due to bad test. Log shows one error for now. Also, I have a feeling tests on some projects aren't able to run all test- the coverage log for this PR shows that none of the files are getting covered:Â https://coveralls.io/jobs/41685719
problem drying is possible
problem The git link to the code repository is not provided.
problem Code looks okay, changes suggested have not been implemented. I wanted to see more comments on "why" this is has been done, which is missing.Â Also strings checks for str != '' are still used and not .empty
problem I don't see new code being committed.
problem Lots of test plans are added. The coverage decreased for the plans added. The test plan covers the basic functionality and not the edge cases
problem 1) Yes. The team has added test cases.Â The newly added tests are not covering the range of this project well. The total coverage has decreased and more number of files have lost coverage. Â 2) Overall coverage decreased (-28.6%) toÂ 8.18%.
problem Didn't see any test cases.
problem Overall coverage decreased (-28.6%) toÂ 8.18%. The team did not add test cases that covers the scope of this project. Could have thoroughly tested with test cases. Also could have worked upon increasing test coverage.
problem Yes the team did add test cases but I am surprised on why the coverage numbers have fallen so much. This needs some investigation.Â I think good test cases were added as part of the work, i would have though liked to see more -ve test cases checking for the failure conditions
problem The basic functionalities are working as mentioned in the write-up. RefactoringÂ the code would hamper a few functionalities as there are multiple instances where a single function is performing different actions
problem Checked the following functionalities through UI:1) Log in as instructor. - checked2) Got to profile page. - checked3) Check the box that says 'Send me copies of all the emails'. -checked4) Log in as 'student2064' with password 'password'. - checked 5) Trigger any action that may result in mail being sent to the student. -checked6) Log in to instructor's
problem Was unable to test the work from UI , but the implementation looks okay. I would have liked some screen hots of mails and videos to be uploaded as references so that reviewers could look at them as well.
problem writeup covers all the specifications and descriptions but is too lengthy.
problem The write-up is well explained along with the test plans explained in steps to make it easy for testing but that just have a few cases with cover basic functionalities
problem A few changes to functions and their declaration have to be made to make the code production ready
problem No the build failure needs to be investigated. Some refactoring regarding the messaging should be done. instead of hard coding the mail it should be read from a config file.
problem The build does not pass. It looks like some failing new tests are the issue.
problem build not pass in travis ci.
problem Not it didntÂ pass the test.
problem The Travis builds have failed but there are no conflicts to be resolved.
problem The build did not pass in Travis CI. There was one failure which needs to be fixed.
problem No Build still fails in spite of asking them to fix the build issues in first place
problem Build did not pass Travis CIÂ but there are a lot of warnings and issues that have not been fixed. Many of them are trivial and easy to fix.
problem The code is visually stunning. I am a great fan of the readibility. There are some instances of redundancy in the #controller_action / #site controller tests. Also in the #get_item/#get_menu. Would be easy to pull those out into a begin block. Otherwise, very lovely.
problem Currently your team haveÂ 4 code climate issues that denote code redundancy as stated in the code comment above. Best just to bring those statements out to keep it as dry as possible.Â From what I can tell, none of the pull requests pass these requirements including my own teams so I am not sure what is the cause of this but I guess no one will be getting all the stars on this questions :)
problem The write up is good overall. I believe there could be more explanation or discussion into test cases not included in the design but otherwise a good wiki.
problem The test plan should have come before the implementation details. I gave this suggestion in my previous review as well. Still, the documentation is well written overall. It's just a puzzling choice to put the test plan near the end.
problem I had suggested changing the ambiguous or bad variable like temp, temp1. These changes have been incorporated. However comments missing. Adding these will improve the readability of the code and make it easy to refactor at a later stage as per requirements
problem I'm afraid that the build failed and there are code climate issues.
problem The wirteup is pretty good. It gives the test plan and all the test cases. Also, there is explanation of the test process and logic. Just one minor problem.Â The 29 tests provide 100% coverage of the lines in menu.rb. Before the project the coverage was only It is an incomplete sentence.
problem The introduction to the scope of the project has been written neatly, but I feel the test plan shouldÂ have been a little more elaborative, a short description of the tests would be nice to have.
problem While the test coverage has increased to 100%, the team has made some changes to "schema.rb" file, this might cause a problem on other dependent modules. Hence, I feel it is risky to deploy it on production. The project doesn'tÂ need to be started from scratch by the next team.
problem There has been few code climate issues reported, but few of travis tests has failed. mot all changes has been verified successfully
problem Yes the project is a test project for menu.rb. The code coverage has increased to 100%. Though the code covers all lines, i feel edge cases are not covered well.
problem Yes the coverage is good but the test scenarios are fairly straightforward and no elegant stubs or mocks used. The code isnt DRY
problem No significant improvements to the write up. It still doesnt explain clearly the functionality of menu.rb and the need for different tests. There is code provided in the write-up, which is more reductant than informative. No future scope or enhancements documented. They have provided all necessary links and coverage data.
problem As its a test project, deployment to production may not be applicable. The code can be merged, but i would suggest few changes to DRY the code as the test seems slow, which is a scope for improvement.
problem I don't see tests for the logout button on the menu.
problem The code written is following the Ruby on rails guidelines. The variables, methods, and class names do seem to follow proper convention and are suggestive of the functionality they are being used for. In some cases they could have used a little more descriptive names for variables for example inside app/helpers/student_task_helper.rbÂ they could have used background_colour instead of rtn as a variable name in the due_date_color() method. It will become more readable for the reviewers to understand the functionalities. Also they have added to few commits for the amount of code change that they have done. The commit messagesÂ are not descriptive enough about what changes have the authors committed.
problem Code Snippet added.Â Still, Git link is not of the pull request.Â Â No link provided for the change. Either screencast or the URL of the deployed application would have been ideal.
problem there is no code included in the write-up,but the team had mentioned the changed files in the write.As a reviewer, it is difficult to find out which code has been added by the team. The team should clearly explain what they are doing.
problem There have been only two commits - one on 30th Oct and second on 31st October. There have been no commits since. It would have been better if you people had given one more commit resolving the issues given by code climate, since most of them are trivial.
problem No new commit has been added since the last submission. The commit messages are not descriptive. They should commit small portions of code one by one with proper description of the changes in the commitÂ message. Also their functions seem to be very long. they may consider refactoring and creating more cohesive code. Each function should do only one task.
problem It is given in wiki that most of your test cases depend on checking the output. However, like I mentioned in my last review, several test cases like the ones mentioned below can be automated. This is especially true as TDD is explicitly mentioned in your problem statement: "Write the required tests before implementing/refactoring the methods in the above-mentioned classes". Add past due assignments to the studentâ€™s task list (on Student View). Check for correction in due dates of assignments (when an assignmentâ€™s due date is edited, it s
problem No Screencast or deployed URL provided.
problem I can not see any link to test changes as well as no video to watch the changes. Team could have shared implemented part to test and review.
problem Write-up needs serious attention of the team. The approach followed is good but it still needs to be worked on. the write-up should include contents which makes it self-explanatory.
problem lacking necessary UI description, eg, the final appearance of the task listÂ or the pathway toÂ show a task list.
problem The write-up is very detailed as to what features have been implemented but lacks on explaining how they are implemented. It can be improved by adding how the features have been implemented, why they chose this logic to implement the features and how to test the code or show how they have tested the code.
problem The wiki documentation has been updated. All the information has been documented in a neat and logical manner. The write up adequately provides what functionality the work is related to. They havent updated any part of the wiki documentation but overall their documentation is concise and to the point.
problem Write up is too brief. No detail description of approach taken as well as no picture to relate to changes as suggested to add in last review.
problem - The write-up does mention the files changed but misses out on adding code snippets. - Little formatting inconsistencies found like "-- Expertiza Project" in the introduction, and a ":-" only for Overview but none of the other headings. - Looks like "Separate the list of 'teamed with' students from the current tasks box" needs to be a heading rather than plain text! -Â Now we have created a separate table for assignments" sounds ambiguous - does it mean a new database table or a html table..? Please be specific. - "A helper function was also added to format a string into multiple lines" - please mention what the string is about (what it represents), what are these multiple lines that it is getting split into, and why you would want to split them. - Test Cases are not stated. Test Plan does mention one as "for example" but the testing process could've been given a little more respect. :)
problem The write up is lacking screenshots, for example, the colour coded views etc and the test plan to verify the issues. Only the test plan for colour coding has been mentioned. The issues and the plan of action have been described properly.
problem The view file contain 200 more files so it is quite difficult to figure out theÂ structure of the View. It is better if independent component is introduced to construct the whole task view. And the commits contain the Gemfile, which is considered not secure to deploy for it alters the production environment.
problem Codewise no issues. Build issue has to be fixed.
problem Not able to see the changes done by the team. Test plan could have been explained better. If the URL or the screencast was provided it would have been better.
problem No. i can not see any link of video to check the changed functionality or system, hence it is difficult to pass the changes to production. Yes new team can take up remaining changes and provide a working system.
problem Code looks okay, and the spec is written in detail. But as mentioned earlier, I'm not in a position to judge due to lack of video or deployment link or even some screenshots proving the work.
problem before deploying the project onto the production server, this projects asksÂ for some attention. new test cases should be added to the project. I can't say much on that.
problem The build fails. there are 3 warnings which needs team's attention. there are no conflicts with the base branch.
problem One of the Travis CI tests is failing,Â https://travis-ci.org/expertiza/expertiza/builds/449165455?utm_source=github_status&utm_medium=notification Â Found many "code climate" issues.
problem No link of the pull request provided.
problem The travis CI build did not pass. But the tests on which the build fails has no direct relationship with the code that the team has changed or added.
problem The TravisÂ build passed but there are a lot of warnings and issues that have not been fixed. MAny of them are trivial and easy to fix.
problem The pull request has some failed cases. no conflict.
problem The code is written aptly and it does what it is supposed to do. However, code comments are missing.
problem The code was well written and there was no issue with the naming or functions used. However, a few comments could be added to the current_team,new_team and team to make the code more readable.
problem The team has modified an existing test case, but itÂ didn't increase the test coverage.
problem The team added test cases in the spec file for both the issues. Further, a detailed explainationÂ is given using screenshots for manual testing if necessary. The coverage increased for 1 issue while it remained the same for the other.
problem The user name issue does not seem to have been resolved. Although the code added seems adequate, I was able to create a username with spaces in the string.
problem The write up has most of the relevant information. The formatting could have been better. I would suggest the team to use a standard dimension for the screenshots they have added.
problem I think work is still needed on this project. All test cases are not able to pass so.
problem I did not understand why is it necessary to prohibit spaces in usernames. I believe the code could have been modified to work with spaces as well
problem The code looks good and it could be deployed onto the production server. However,Â there could be a situation where even though a random num(0-1000) is assigned to each team there might be a chance that two teams get the same name.
problem Build pass was failed in Travis CI.
problem No the code did not pass Travis CI tests. there was an issue with generate_team_name which could be fixed.
problem No updates after first review.
problem Looks good. Function nameÂ componentDidMount is a bit confusing.
problem Code is written well without dead or complicated code. DRY principle is followed. I can not see any changes or commits in code after last submission.
problem Comments in the code would have been helpful to understand the flow.
problem I can't examine the code because a link to the repository is not actually given in the project, and when I navigate to their repository, I can't figure out which branch is the correct one; however, from the details of the writeup, it seems as though the code is well written.
problem The code was already well-written . The team did a great work in following coding best practices. The team should have include code comments to make the code easier to understand.
problem The code is well-written and there are no bad names or long functions. The coding style is also pertaining to the Ruby standards. Although it would be good if they could work in making the code more 'DRY' by making suggested changes to the code.
problem One new commit after first review.
problem Can not see new commits after last submission. 2 Issues are resolved out of 3 issues given in problem statement.
problem No new commits were made during the 2nd round.
problem I can't actually see this team's repository because they linked the expertiza/expertiza pull request, but it doesn't look like new code was committed in the second round.
problem There was one new commit during the second round.
problem Yes, there is one commit during round 2, and it fixed trivial rubcop issues related to indentation.Â Two suggestions of adding meaningful comments for tree_display function in tree_display.jsx and second on having a single copy of RubricArray for two functions were not implemented.
problem No additional commits were found considering one issue was still left to be implemented. Suggestion: There should have beenÂ someÂ commits present pertaining to test cases or at least the 3rd issue that was not implemented.
problem No new test were added and existing test are failing. AssignmentsController#update when params has key :assignment_form when the timezone preference of current user is not nil and assignment form updates attributes successfully shows an error message and redirects to assignments#edit page Failure/Error: if current_round !=
problem I don't see any test cases added. The overall coverage has decreased by 2.99% to 33.88%.
problem No test plans added and the coverage decreased in the pull request. Test plans are not needed for the project
problem No test plan added and no test cases written in code as well as in wiki.
problem The test coverage has decreased by 2%.
problem No test cases were added and the coverage decreased.Â The overall coverage decreased (-2.9%) to 33.88%.
problem The test coverage decreased, but I'm not really worried about that because that seems to be a common theme with many of the refactoring projects.
problem The team has not added any test case for the implementation. The overall test coverage has decreased.
problem No new tests have been added to the project. Commits for the first round had increased the code coverage by .0004 which was good, but the code coverage has decreased by 2.9% as per the latest build report.
problem The team did not add any test cases.Â The coverage did not increase as a result of that.Â Suggestion: Unit test cases should have been written as a part of the final deliverable.
problem The team might has out 2 issues to be resolved.
problem On checking the videos, the functionality seems to be working fine. I haven't been able to manually test it.
problem No UI provided but videos are uploaded to demonstrate the functionality
problem The team only implemented 2/3 parts of the project and has not created the tests for the same. The CI build is also failing for the pull request. The functionalities implemented are working as expected.
problem The team has uploaded manual testing screencast to show fixes for 2 out of 3 issues to be fixed, and everything works as expected. The audio in the screencast helps clearly understand the before and after scenarios. However, there are no corresponding test cases to test the fixes. No changes have been done to the spec file.
problem The project was not deployed. The project should have been deployed. However, the video that the team uploaded shows the 2 functionalities that they have implemented. And they work as intended. Suggestion: One feature was not implemented (3rd issue) and should have been done as a part of the deliverable. And the project should have been deployed.
problem Unable to find any difference after the first review although the team had to explain about some issues.
problem It looks decent. The screenshots should be with the issue write up and not at the end
problem Write up is written well and it is understandable. Images are not in proportion and not of same size and hence wiki page does not look steady. Team can work on image size and image description and manual test plan in more detail.
problem The content is good and explanatory but the writing styles needs to be improved as there is inconsistency in the font size and font type.
problem The writeup was well written and easy to understand. However, it would have been better if some steps accompanied the screenshots as to what was happening in each screenshot. That would have made the writeup even easier to understand.
problem The writeup thoroughly details the changes written in this project, but the first section seems like informally written reminders for the development team.
problem The write-up is well written and organised. Everything looks fine. The team should have mentioned about the approach taken to solve the mentioned problem statement which will make the implementation easier to understand.
problem The write is well-organized and clear in its material. The authors have improved the write-up by explaining what each newly defined functions work. and added code snippets wherever necessary.Â However, the test plan is still missing from the write-up.
problem No,it should not deployed till the build is fixed. It is aÂ good starting place for a future team to pick up
problem Two issues resolved seem like working pretty well and can be deployed in production. Third unresolved issue is a good start for future team to pick up.
problem I don't think this code is ready to be deployed due to the fact that I can't actually examine the functionality, nor can I see the actual repository this project was written in.
problem I think that the team has done a great work for the future team to pick up. They can improve it by adding comments for newly defined functions. Although, the pull request build has not passed, after fixing the conflicts, the new team can readily work ahead on the remaining issues.
problem I do not think the code should be deployed. The test cases are not yet written and there are a few code climate issues. Due to the lack of test cases, the Travis CI build has also failed.Â Suggestion: Once they are resolved the code can be deployed. There is one remaining issue, but that could be done in the next iteration.
problem Not able to merge. Issues regarding Travis tests etc need to be resolved.
problem feature and controller test failing. Mentioned in the previous review as well. Travis Failing and issues with code climate as well
problem Travis test build have failed. Can write version compatible code
problem Pull request is not accepted, also build did not pass Travis CI. But the functionalities improved and accepted and working fine.
problem The Travis CI test has been failed.
problem No, the build did not pass in Travis CI. several checks were failed but there was no conflict with the base branch.
problem The pull request did not pass Travis CI, but there were no conflicts.
problem No, the build for the pull request does not pass. The build had 4 jobs, out of which 2 jobs passed successfully. However, 2 build jobs have errors. FirstÂ job failure is related to webdriver error for chrome where test fails. Second job failure is related to NoMethodError for method []
problem The Travis CI test did not past.Â I did not find any test cases written. Suggestion: Test cases should have been written as a part of the final deliverable.
problem Not very good, some problems existing during the first round are still here.
problem Most of the updated code is well written. Some functions could have been shortened. For example, in the set_display_type function, instead of writing a 'when' statement for each of the options, you could have stored them in a hashmap and set display type to that value if it exists in the hashmap.
problem The code is well written. It follows DRY principle. It would have been better if more comments were added.
problem The code follows good coding style, adheres to naming standards and is DRY. However, the suggested changes since last round have not been implemented which emphasized on shortening the length of long functions create and view.
problem No, they seems did not commit again
problem No, the strange part is the code hasn't been committed during the second round. It is strange because they have surely seem to have achieved all their requirements to problems going by the wiki page so, why haven't they committed the new changes is the question.
problem No new commits were made during 2nd round.
problem There have been no new commits since the last round of submission. There seems to be some work pending since the last round for integrating the branch.
problem There have been no additions to test cases, although they have added a test case in last round.Â The test coverage has significantly gone down by 39.4% after their code changes.
problem No, they did not commit any new code, so no coverage increased.
problem The team has made sure to write the relevant test cases wherever possible. But the overall coverage has decreased. In my opinion the newly added test cases coverÂ more or less the entire range of this project. But I think that they need to focus a bit more on the test casses.
problem Yes, the team did add test cases to test their changes, but the overall test coverage has decreased
problem The team did not perform any changes from the first round. No test cases were added and the coverage remained the same. The test cases from the previous round considerably fulfill the range of the project.
problem No, it did not work intended.
problem There wasn't any link provided to check if the UI was working fine. This project was majorly focussed on refactor and looking at the code changes in the PR I can guess that the features might be working as they were supposed to.
problem N link to the deployed version is provided hence cannot comment on this question
problem The team has added screenshots on the submission page, which show that the UI is working as intended.Â However, it had been more clear had they made a screencast of the same.
problem I don not think it's good, because they just paste most of their code on the writeup.
problem Overall, the writeup was pretty good. Everything is explained in a good way with the help of code snippets and screenshots. There is definitely lack of explanation on how to check the work. THis is the only thing that I found where the writeup could've focussed more. Other than that it looks good.
problem Alignment issues for the content
problem The authors have portrayed their work by adding many code snippets. It is cumbersome to go through the entire code in the write-up. A general approach towards refactoring principles used would have been impressive.
problem No, they didn't pass Travis CI.
problem No, according to Travis CI the build doesn't seem to have passed due to some bundle install errors. Although they surely should have resolved it because the code wouldn't be able to achieve the above results as stated by their photos and wikipedia page.
problem The code has been merged in a good way and there have been no merge conflicts so far which is commendable. However, the Travis CI was failing and the code climate check was failing too. This is something that the team must look into and make sure that the changes that they have made are consistent with the existing expertizaÂ code.
problem The pull request did not pass the TravisÂ CI build. There are no conflicts with the base branch.
problem The pull request still shows that the build fails. On observing the logs, there is only one build job which fails due to a ActionNotFound error for view_action method. This needs to be looked at.
problem The build for the Travis CI fails and also the code climate shows 79 issues to be resolved. However, it does pass the Danger Bot with considerable warnings.
problem No, I think they code have some bugs in there.
problem Even though the code has been refactored keeping in mind the coding standards but I think that there is still room for improvement in writing the test cases and the PR checks should be checked as well since they are failing. This is something that the next team could pickup and then the code could be ready to be deployed on the production server.
problem Since the TravisÂ test has failed and the test coverage has also decreased, merging the code would not be a good idea. The project doesn't need to be redone from scratch, some modifications to the existing workÂ could make the project ready for deployment.
problem The code enables properly testing the various features and describes the system working as desired. However, since the Travis build did not pass, the code could be deployed but with careful intervention by the developer. It could be taken up from here and does not require to be redone from scratch.
problem The overall code quality is moderate. I would suggest the team to either use hexadecimal color codes or names, to ensure that the code remains consistent.
problem Code is written properly with no bad naming conventions. No major code change can be seen after first submission. Â Code is DRY. But I could not see color change specific comments in the code.
problem It was a simple UI color change, so not many categories are not applicable. the code can be DRY, by using the CSS file for styles. Also there is no need to add colors in bothand . would suffice
problem No commit has been added since round 1. They should have fixed the build failure which is probably happening because they have pushed changes few extra changes in schema.rb which I don't think is required for this project.
problem Unfortunately, no tests were added. It would have been good if the team added test cases to check their UI changes.
problem They have added test cases and the coverage did increase but only by a little amount. They should have considered adding more test cases since the task of changing the color of the links was such a minuscule one.
problem It says it failed, but I am not sure the most recent commit has been checked yet.
problem The coverage could be increased to %100, but this is a great start.
problem A huge improvement from Round 1. In round one not much code was submitted so this is a huge improvement. Keep it up. I have a Suggestion: It is very important to have comments in the code which will help other readers understand your code or in this case understand what you have tested without having to look for any other documentation which explains it. (Code file should be self sufficient)
problem Lack of Comments
problem Your team have put all "let" behind the code. However, there are, still, a lot of 'let(:response) { VmQuestionResponse.new(review_questionnaire, assignment, 1) }'. It is repetitive and unnecessary.
problem The structure of codes is not very good, that is, for a "it" statement, there are two many things include in it to be tested. It is better to separate Â the test cases clearly. Besides, the objects seem not store in factories properly.
problem No code was committed during round 1. MostÂ of the code was committed during second round based on reviews of Round 1.
problem The test cover most cases, but some scenarios like different cases for the if statement for add/team method is not sufficient.
problem The team has heeded to the advice given in the last round and explained their tests in a more detailed manner. I do feel that the write up is well written and covers almost all the important points of the project. But I do feel images showing their tests running successfully could be added to the results part of the writeup.
problem The description for the background, motivation and the deign is not very clear. The team can give more detailed introduction specific to this project.
problem I do believe the code could be deployed after a bit of refactoring is done as suggested by the code climate tests. But overall looking at only the functionality of the code, it is ready to be deployed
problem It is a testing project which aims at improving test coverage. So production deployment is not in question. However before merging the code to Master branch here are a few recommended changes. 1) Adding comments to improve readability and understanding for future use. 2) Avoid using comments like "I swear this is the last one". They do not explain anything about what you changed from your last commit and why. Proper professional comments are expected. All these comments should be refactored.
problem Ready to be deploy but must resolve the build issues.
problem I am not sure since these are Unit tests and there are Travis tests failures too. Need to check with the team and mentors.
problem The test made the coverage increase, but it still have room to improve its structure to make it more clear and useful.
problem The code has been merged in a good way and there have been no merge conflicts. The build did pass the Travis CI. The code climate test failed but those were small issues which can easily fixed by just revisiting the code.
problem Travis CI has error ed. The tests fail.However there are no conflicts with the base branch or master branch.
problem The build has failed in Travis CI.
problem Travis Passed. Code Climate has 82 issues
problem Build does not pass. Also, code climate issues are observed.
problem Travis test did not pass. Errors were not fixed. Continuous Integration failure.
problem Detailed. But the screenshots of the manual testing are missing in the test plan.
problem Except one method, all the other methods have been covered. This is similar to round 1 review given by me.
problem The coverage has increased by 6.3%. The team has added new tests that check whether Assignments is absent in the menu in default view and there is an option to Open Student View. The tests also check whether there is a close button present when the instructor is in the students view, also it checks whether the Assignment is present by default in the student view or not.
problem The write-up was nicely written in the first round itself. It gives a clear idea of the project.
problem Yes, the changes work as expected in the UI. The test cases cover most of the scenarios. Would have been good if there was some scope for negative test cases that could be explained.
problem The added features work as expected, though the login info on the write-up didn't work for me.
problem I can't say about this since I tried to login with the credentials mentioned in their wiki(student5408/password) and I couldn't. However looking at their screenshots it seems that the UI looks good to go.
problem The write up is short and to the point, it could have been formatted and arranged in a better way.
problem The write up was well explained. Test cases were with images of test cases in the UI. The code could have a github screenshot or the link to the changed file for more clarity.
problem These are my views on their writeup: 1.Â Certain sections are too bold. I find that to be distracting. 2.Â I like the way that they highlighted the lines of code that they have edited/modified. It made it easier to understand their work. 3. It was also good that they included references section at the end. It was something that I haven't seen in the other projects I have reviewed so far.
problem Again, the problem persists of containment of sentence.
problem The code looks to be ready to be deployed on production, but would appreciate to have a few more tests run prior to it.
problem Although as per the scope of the project, the team did extremely well. All implementations as written in the project description were completed. However I feel that this project in general has more scope. Say introducing email notifications to the students when a review is due. As far as the work of the team is concerned, they completed everything that was asked of them.
problem Build needs to be fixed. Then its ready for production.
problem No. This is not standards to add colors in the respective element. It becomes very hard to maintain or modify such changes in future. It would be better to move the style to a scss file and use a class-UI to make this change, which is clean and DRY
problem There has been test failures, but not related to the project
problem Build is failing probably because they have pushed changes few extra changes in schema.rb which I don't think is required for this project.
problem I am honestly unsure how to rate this. Earlier the build was passing. Now Travis CI cumulatively says the build failed, but when you look at the build history, Job#6150.3 failed, but Job#6150.4 passed.
problem Within the travis builds, the test folders of helpers, models and features are passing. The test folder for the controller seems to be failing for some reason.
problem The code changes are accepted but build does not pass travis CI. The problem statement is simple and team has implemented a clean solution for the same.
problem No. I see there are some code was commented, which seems unnecessary, so just delete it.
problem In the wiki, I really appreciated seeing the appropriate build statements next to the unit tests. It helped connect what each test was testing in my mind.
problem Yes good write up but would have like to see details on model.Â In test plan lines like "Â two test cases for method " are redundant. Can / should remove them
problem Most are good, but the Test cases part just a combine of "describe" and "it" part of spec code. Could be replaced by a link of git.
problem the team has made great improvement as compared to the last submission. The new code added has no bad names, long or complicated functions but there is lack of comments. the heading of the write-up pages explains what the test case is doing but there should be proper commenting done in the code too.
problem Write-up includes everything the team has implemented. It clearly show the files which were involved to complete the project, background of the project and evrything. overall work done by the team is good but I feel that the test plan on the write-up page should be edited. The team should work on presenting their work to everyone in a good way.
problem The code has been very well written and it follows all the coding practices. There could have been few more comments but other than that I don't see any other problem.
noProblem They did include the test plan section and it is enough.
noProblem The test plan is excellent. It includes all the cases to be considered and it's expected output. The authors haven't missed any scenarios.
noProblem Yes conditions are tested well.
noProblem Maybe add the code to wiki.
noProblem Yes, the test plan including setup environment and all the cases they need to test.
noProblem They do have clear testing section, but not said as test plan.
noProblem The report mentions all the required details like the problem statement , the old version of the code and the improved version of the code and how well it is improved and implemented , thus the report is also very well articulated
noProblem Yes each topic description starts with what the current issue is, what are the changes made and how is it impacted and what is the end result. Nicely Articulated
noProblem The implementation strategy is clearly discussed in the writeup which is easy to follow.
noProblem Yes, the bug to fix flow is very well explained. Comprehensive and easy to understand.
noProblem The writeup explains the implementation approach for every functionality that they implemented.
noProblem Yes, all the have done are shown in the github link.
noProblem yes, this writeup has explain how and why the authors did the work the way they did, and also, there are some expamles that included in the writeup.
noProblem Yes, they mentioned in wiki page that they used RSpec and Virtual Box tools to accomplish this mission. Also, they comment all the method they need to test just below the subtitle which is nice layout.
noProblem Seems all variables and methods follow certain naming rules.
noProblem The variable , method and class names all seem to be reasonable and well written.
noProblem The code seems DRY and follows good design principles avoiding redundancy.
noProblem Can not run servo as I dont have the needed environment.
noProblem The writeup was well written and explained what the Mozilla project was about. It also mentioned the purpose of the project along with the technology used to implement the same.
noProblem The document is really well written specifying clearly the functionalities worked on.
noProblem Not any clue.
noProblem The writeup details the work done by the authors and mentions how they approached implementing the OffScreenCanvas API.
noProblem Everything looks complete.
noProblem The writeup is the Test Plan.
noProblem They dont have a test plan exclusively listed out but the document can give insights on how things were done.
noProblem Yes the team tested all the True/False return values
noProblem Because the writeup is the test plan, and all the tests are in the writeup, and all tests pass, they get 5 stars.
noProblem The test cases mentioned in the write up are implemented. They are working expected.
noProblem Yes they have 100% coverage.
noProblem Great use of whitespace and indentation.
noProblem Each test case appears to be quite smooth and minimal.
noProblem Nicely formatted and written code.
noProblem Descriptions in Rspec are self-explanatory and easy to follow.
noProblem Code coverage is increased fromÂ Â (+9.7%) toÂ 46.487% but theÂ build has failed. Coding standards are fo
noProblem Very nicely written Wiki.
noProblem Very detailed writeup shows how they test each method. I like that they show how they found some bugs!
noProblem TheÂ functionality is clearly indicated.
noProblem Detailed document with all the necessary details. Easy to understand the idea and the work done in the project. Good job!
noProblem Yes,Â the Methods are explained like what it does and how it is used to test. Yes, we can understand what the project does
noProblem They wrote clearly what they have done and also wrote the bugs they found. Very good.
noProblem The write-up is good explains whyÂ they did cetainÂ changes.
noProblem Very nice and detailed explanations of the test cases, nice edge cases captured.
noProblem This write-up goes into detail and explain the rationale behind every line of testing code.
noProblem Writeup demonstrates why they test each method the way they do. The placement of each method before the test which tests it is great.
noProblem The wiki link clearly explains what and why they did.
noProblem Yes Team has explained where they are using a Mock
noProblem Yes they explained very well about how and why they did the work, and they also pasted their code and explained them in detail.
noProblem Everything seems to be working for me.
noProblem Video shows 100% LoC coverage and all test cases pass. I suspect their edge case coverage is quite good too based, on the number of tests.
noProblem Team had mentioned couple of BUG in specific line in the Model Class. Corrected those config and ran the RSPEC Test and it is 100% covered
noProblem According to their video, their test runs pretty good.
noProblem Code coverage is 100% for the required file.
noProblem All the cases discussed in the test plan have been implemented.Â Well done in achieving 100% test coverage and passing all the tests.
noProblem over 9000! I mean 90%! Great job testing Participant y'all!
noProblem YES.
noProblem Yes and it all passes too.
noProblem Every test case that is provided on the wiki page is part of the automated test suite. There are no cases of failing tests.
noProblem yes they have automated test and all of them pass
noProblem Names for variables, classes, and method are properly named and make sense.
noProblem They kept working on it and did really impressive.
noProblem It looks great. Everything is followed.
noProblem Yes there is no unreasonable function names and all method name are suggestive and apt
noProblem This was a testing project and the mocked objects were appropriate.Â The code is DRY. There is no redundancy in the code.
noProblem So fresh and so clean, clean! This code is too neat to even be dry. Too hot to touch. I'm just still super impressed by the wiki and the video.
noProblem All the code is in a single file as it tests a single model and it seems to cover it extensively. It also looks like there's no DRY issues.
noProblem Code seems to be concise and well written.
noProblem The features work as intended, they cover the test cases and edge cases as well.
noProblem After working through several edge case side effects, by hand, up hill, both ways, it looks like all of their bases are covered and edge cases satisfied.
noProblem The features work as intended
noProblem Since coverage is 100% and the code looks good to me, I am assuming it works fine.
noProblem Running the code manuallyÂ resulted in theÂ 100% coverage of theÂ object under test.
noProblem This wiki is very detailed and explains what is done for every tested method. It also contains links to all resources one may require to understand the functionalities of the project. Great Job guys !!!
noProblem This is easily the most clear of any testing write-up that I have seen to-date. It is organized into meaningful sections that follow their test plan, and show of their deliverables.
noProblem The wiki pageÂ provides clear details about the work, and very easy to understand.
noProblem The writeup is clear and easy to understand.
noProblem Yes, it is easy understand that it is a testing project and how it is done.
noProblem looks like edge cases and invalid inputs are handled.
noProblem The test plan look complete enough.
noProblem The plan looksÂ good and it covers a lot of cases.
noProblem the write up doesn't has a testÂ plan but looking at the code it seems they have check every edge case. Also since there coverage is coming to to be 100% , everything should work.
noProblem The test plan is comprehensive and fully covers all the methods and cases that are part of the object under test. Running the test suite yields 100% overall coverage.
noProblem Yes they have come up with all possible inputs, edge cases and wrong data entries to check the system behaviour is not faulty
noProblem For every tested method, they explainÂ what they did and why they did it.
noProblem They even wrote down their plan to accomplish the project! I love it.
noProblem It is a testing task, I assume there is not any design needed.
noProblem It explains clearly what tests are missing and how the coverage is increased.
noProblem YesÂ they have explained everything.
noProblem They team has thought through efficiently to use design options that avoid test reruns and to dry out some mocks settings
noProblem All the variables and function names used are appropriate.
noProblem The variables, names are well assigned.
noProblem Functions and variables are named aptly
noProblem The features work as intended. Edge cases are properly executed.
noProblem The code works.
noProblem The write up addresses details of all the three problem statements along with the code changes done in every file and the files added. The team has also added screenshots of the manual testing and the video demonstrating the functionality they added.
noProblem The write up covers all the issues and is well organized, including the code blocks and the screenshots.
noProblem The Documentation is well written and indicated clearly what was the problem tackled and how it was approached and solved
noProblem Yes, the team has clearly stated the problem statement and the changes they have done to provide solutions to the problem. They have been given 3 problems to which they have clearly provided the names of the files and the part of the code which is changed. The video explains the problem and the implemented solution perfectly without any ambiguity.
noProblem The write up clearly explains about the modifications made in Expertiza.Â It indicates the functionality of their work which is topic management and the problem statement is clearly elaborated. It provides the files changed and also the code snippets in which the changes are made. The write up also provides visualÂ representations of the changes made.
noProblem writeupÂ is very well written, contains enoughÂ screenshots and explanationsÂ of the code.
noProblem The team has explained the issue and the solution they chose with enough details to understand to way of implementation.
noProblem Yes allÂ the 17 test cases are automated. They have reached the goal of 90% coverage .
noProblem Test cases are present.
noProblem Yes all 17 test cases are automated
noProblem Everything in the wiki was a test.
noProblem It seems you have cover 94% of the participant.rb. However, all checks have failed in the pull request test.
noProblem Yes, the admin has included the Test Plan cases in the automated tests.
noProblem The authors have implemented every test case that is discussed in the test plan. Detailed explanations and code itself is provided in the project's wiki page.
noProblem All variables, methods and class names lookÂ reasonable.
noProblem it follows the standard ruby practices . All the variables , methods and class name look reasonable. The added tests looks very clean
noProblem Naming conventions are followed. Test coverage has increased.
noProblem Coverage has increased by 7 percent overall
noProblem The added tests look very clean.
noProblem Pull request build passes well and there are no issues.
noProblem FuncyFunctionalare of correct length.
noProblem Does not apply as its a testing project with most testcases written in a single Rspec file to test the functionality
noProblem Well, the code looks good and very much follows the Ruby Style Guide. The code also is DRY. It looks well written and does not any changes.
noProblem Video covers how to run the test cases which are clear and understandable.
noProblem Tests work
noProblem Yes, after testing the work manually, I could see that their features are working as intended.
noProblem The write is very descriptive and included code from both the model and the spec file.
noProblem The writeup explains how the tests relate to their respective methods.
noProblem very clearly writeup.
noProblem It is well written, quite understandable. It clearly and adequately indicates the working functionality. I can understand what the project is about.
noProblem Yes the test appears complete as they have mentioned all from setting up the expertiza environment to the tests that they have implemented along with the plan of the they executed their project
noProblem Yes, the Test Plan looks complete and includes all the test cases and the actions.
noProblem Yes the have mentioned all of the required work and its related explanation. they have reasoned out their exact methods and the issues to be considered while testing in the problem statement.
noProblem Functionalities have been tested properly.
noProblem Yes, the writeup explains explains how the authors did their work and they have mentioned the steps behind each functionality. They have put a video explanation of the same.
noProblem Yes, it looks they have converted all the cases into the Test Plan.
noProblem Good work on including test cases. The app works fine after testing.
noProblem Yes most of them but they have not added any automated integration tests. Unit testing has been done and is great to see such detailed tests
noProblem All the test plan is converted to automated testing.
noProblem The variable and method names are apt.
noProblem Yes. the variables have been very keenly named. Especially in the file, _rubric.html.erb, the variables are very accurately and effectively named, as there could have been much confusion otherwise. Kudos for that.
noProblem The variables, methods and class names are aptly named. I could not find names which are not suggestive of functionality.
noProblem The code follows standards.
noProblem The code follows the DRY principle.
noProblem 3
noProblem Great work. Clearly Understandable. Functions are of appropriate length, Codes are in appropriateÂ methods,Â Code is very well commented, Code follows ruby style guide. Good naming.
noProblem They do work as intended.
noProblem All of the features mentioned by the author works successfully in the demonstration as well as in the manual tests performed by me.
noProblem Could not detect any flaws. Works exactly as it has been been in the wiki. Good guidance.
noProblem Tested in the links given, the changes are working correct. The server is up and I was able to reflect the steps mentioned.
noProblem I can find where is the bookmarks page, but according to their screenshots I think their features work well.
noProblem The write-up is very clear and directs user to the main issue very well. The flow is very structured, in the sense that first it gives a high level view of what expertiza is, it then tells about the book-mark functionality, and then tells the problem and how they came up with the solution. One of the most professional wiki I've reviewed.
noProblem The writeup is clear. It is easy to understand what the project does.
noProblem The write-up was splendid. All instructions were written thoroughly. I did not face any problem in understanding. Also, screenshots guided well
noProblem They have included a test model video in which all the test are passing. It looks complete
noProblem Yes. The test plan is present in the writeup. Also, the links to youtube videos for the demonstration was particularly helpful too.
noProblem The authors considered different pre-conditions, edge cases, invalid input values, and other possibilities and i clearly well written. Test Plan looks complete
noProblem Yes, I followed the youtube link to check the tests and they have tested the controllers.
noProblem TestplenÂ looks exhaustive and is explained well.
noProblem They don't have Test Plan section, but they added some screenshots of the test result, I can see they have pretty good path coverage. But I can not know if they test edge cases or invalid input values without seeing their Test Plan.
noProblem Yes, the problem statement was explained thoroughly. Also, the team very aptly described why the issue needs to be fixed. great work !
noProblem I do not see any test plan in the writeup.
noProblem The newly added code does not resolve the previous issues to great extent.
noProblem The deployed setup cant be reached. The site is not up.
noProblem Code works.
noProblem The project seems to be incomplete. The work done is also not properly mentioned in the writeup.
noProblem Test cases are failing
noProblem The test plan focusses on a particular scenario for the functionality to work and does not handle validations and edge cases
noProblem Include the code snippet in the write up as well.
noProblem There was no test plan. Also all the test cases don't seem to have been written which is evident since the code coverage 46 percent.
noProblem They have added Rspec and Unit tests
noProblem Edge cases are covered as well.
noProblem Yes, the admin has included the Test Plan cases in the automated tests.Â They have solved all the issues they were tasked with.
noProblem Variable names methods and class names look fine to me.
noProblem The build is passing the test coverage and the bullet points mentioned in the issues section have been properly implemented to achieve the desired result. All the issues have been implemented as discussed.
noProblem Test not passed
noProblem The chnages made by the author seemed to follow most of the guidelines that a professional prgrammer should follow. The variable names were unambiguous and clearly stated what they stood for. Also the functions and classes did what they stated.
noProblem The writeup is good and clearly mentions the issues to be solved.
noProblem The test plan is very good and there is also a videoÂ file which clearly shows the manual testing being done.
noProblem The code added in the pull request is reasonable.
noProblem The code added appears to be dry.
noProblem All the names suggest the functions well.
noProblem The code for the export_file controller and models for question_advice are tested adequately with the questionnaires_controller sepc model file. The variables, methods and class names follow the general standard Ruby practices.
noProblem The code overall seems dry. The functions are to the point and the code follows Ruby Style Guide.
noProblem well explained in the video file
noProblem All the names are intuitive and reasonable. Good job following naming conventions!
noProblem Very clear.
noProblem The features do work as expected. The authors have implemented all that they claimed that they would do.
noProblem The link for the work can not be accessed, but according to the video they provided, the features works well.
noProblem The test cases written work as specified. The features are working as intended and the functionality is getting implemented with minimal errors.
noProblem I think it is well written, quite understandable. It clearly and adequately indicates the working functionality. I can understand what the project is about.
noProblem The wiki document provides the necessary details about the project and the tasks performed by the team. It gives a general overview of the project implementations, the functionality carried out by the team.
noProblem The document clearly explains not only the problem statement but also what Expertiza actually is. It proceeds to explain how they solved the problem of the rubric criteria.
noProblem The documentation is well done and gives a comprehensive overview of the project
noProblem Yes, the author did include test plans and test cases. Also the test cases seem sufficiently exhaustive to cover most of the edge cases.
noProblem The Test Plan along with the existing issues and its solution is given.
noProblem No test plan, even though they did have the task of testing the questionnaire controller
noProblem Test plan is nicely written and implemented
noProblem The plan gives enough roles for the first issue to test if the code works well.
noProblem Yes, as mentioned earlier, this part was very aptly implemented by the author.
noProblem Explained Clearly
noProblem The document explains the different files which they had to change along with why the previous version was not up to par. Then they show their implementation of the file
noProblem The writeup describes the problem statements, solutions and the 'why' and 'how' of the problem. The screenshots were clear.
noProblem The writeup enlists a thorough report from the environment setup to the project build. It includes a proper check on the problem at hand, the approach to achieve the goals and the solution implemented.
noProblem They wrote many test cases I think they are enough, but I didn't find edge cases or invalid input tests.
noProblem No design patterns were used. The write up explains the implementation and screenshots of code explains the flow better.
noProblem The write up explains the functionality. The problem statement gives a clear view of the project.
noProblem The variable, class and method names are named appropriately and they suggest the functionality.
noProblem The authors have included a thorough test plan and they seem to have considered a lot of test cases. The tests convey they entire flow properly and show that the bugs have been fixed.
noProblem The variables, methods, and class names do seem to follow proper convention and are suggestive of the functionality they are being used for.
noProblem All the tests have been added as per the test plan and have been run successfully.
noProblem Authors have clearly explained what needs to be done to fix the issue, how it is done and why it is done.
noProblem Yes, the test plan looks complete enoughÂ and all the edge cases have been tested. The document also includes the screenshots of the manual testing.
noProblem The test plan looks good enough for the fix they have provided.
noProblem The variable and method names look clean and concise. No new class is added.
noProblem The functions are small and well defined.
noProblem The feature works as it is supposed to. Don't see any issues.
noProblem this is refractoringÂ project , doesn't involve new test cases .
noProblem All the cases discussed in Test Plan have been converted into automated tests.
noProblem The team has separated the existing methods of a class in 2 sub classes. They have used meaningful names for same. The team has not added any new functions as per the wiki description.
noProblem Variable andÂ method names seems to be appropriate.
noProblem The variable/method names and class names are intuitive and follow Ruby standards.
noProblem Code adheres to the Ruby coding standard. The team has also implemented strategy design pattern.
noProblem The code is more about the changes in the database and it does follow the standards.
noProblem The code follows Ruby Style Guide.
noProblem refactoringÂ is done really well.Â there were no violation of DRY principle
noProblem The code follows DRY principle. None of the methods needs to be broken down into separate components.
noProblem Code is concise as mentionedÂ Methods are extracted into separate methods Comments are sufficient I could understand it The code is as per Ruby guide Most of them are DRY code
noProblem The features are working as per intended plan of work.
noProblem Couldn't test theÂ features as no information regarding logging in credentials were provided anywhere.
noProblem Most of the edge cases cover
noProblem The write up addresses the problem statement and explains about the background of the functionality.
noProblem writeup is clear and easy to understand .Â it covers all the work
noProblem Very well written.
noProblem The writeup gives us enough clarity to understand what the project is about.
noProblem The report is detailed enough to explain the approach taken to refactor the code.
noProblem Very well written. The purposeÂ was clear!
noProblem Yes the write up is concise
noProblem Yes, it does explain the previous functionality and their changes will take affect. The explanation is done with diagram as well as the query.
noProblem Yes, explains well.
noProblem clearly explained about the implementation and usage of the strategy pattern
noProblem The authors clearly explain how they refactored the code.
noProblem They explained how they used StrategyÂ PatternÂ and why they used it. Loved the walkthrough!
noProblem I could see a clear description of the changes and good naming conventions
noProblem Everything seems to be working fine
noProblem Existing test cases have been fixed for review feedback by a team instead of a team member.
noProblem Naming of classes and variables are apt.
noProblem All method names are suggestive of the functionality they provide.
noProblem The team has properly used the naming conventions for variables and functions. The functionality could be easily interpreted by reading the name
noProblem Basic test cases are covered in the test plan
noProblem Team has taken care of test plan with automated test cases. As mention by team, they have implemented capybara testing and has good understanding of it.
noProblem All tests added pass.
noProblem Include test cases for negative scenarios as well.
noProblem Up to standards with ruby coding practices
noProblem The code is well modularized and separate methods have been created to provide different functionality. eg: added get_feedback_assessment method to add feedback for a team.
noProblem Methods, variables and class names are well defined as per the standards.
noProblem The code has all 5 of the following characteristics: (i) is DRY (ii) follows Ruby style guide (iii) is commented (iv) does not contain long methods (v) variables and functions are properly named.
noProblem The team has done a good job of maintaining the code DRY and as neat as possible. No suggestions to improve.
noProblem Variables, methods and class names are given professionally with reasonable meaning. The names very well indicate the functionality to be performed by the name/variable.
noProblem The code added in the project uses intuitive naming conventions. Good job guys !!
noProblem Pull request build passe well and there are no issues.
noProblem features are working as intended.
noProblem Function names seemed to be clear enough and satisfactory.
noProblem Names are clearly used and defined as given. def remove_administrator redirect_to action: 'list_administrato
noProblem 1. Function written are simple, crisp and clear. No long functions or dead lines of codes 2. Team has taken care of modularization. No part of code needs to be added as separateÂ method 3. Code and names given to variable do help to understand the flow of the code. 4. Code follows Ruby style guide. 5. DRY principle is followed very well within the two functions changed.
noProblem The code seemed fine and follows the ruby guide style. I could understand the flow of the code and what different functions did.
noProblem They have explained about how they are using DRY principles in wiki. Refactoring a new method like,Â def self.destroy_helper(params, position) inÂ (users_controller.rb) clearly explains the DRY method being used
noProblem I have manually tested the changed functionalities and issues are taken care very well. Team has given justice to problem statement assigned to them, but with in the scope of issue assigned. Also taken care of edge cases.
noProblem I could get things working.
noProblem Manually tested the functionality of teammate review. Working as expected.
noProblem The features are working as expected in this project. The views have changed to fit the new implementation.
noProblem the write-up provides adequate information along with before and after code which helps in better understanding of the issues and changes made
noProblem Team has written a professional and understandable writeup. Formatting is good. With good explanation of the approach taken to solve the issue. Creative way of writing before and after of the code snippet. Team could have added pictures to make it more relatable for users new with Expertiza.
noProblem The writeup is clearly and adequately defined. It shows what the project is about, what all changes the team have made, all assumptions they have made and edge cases which they have ignored as they were out of the scope of the project.
noProblem Well explained. Add screenshot of the changes which can help understand the change visually.
noProblem Please add a guide in the wiki where to test if the features work or not. Initially found it difficult in the expertiza page where it has been modified.Â The software works as expected in most cases. Was able to check the following participant feedback displays author feedback view toÂ whole team checking feedback assessment give feedback and edit feedback functionalities in the review view
noProblem The writeup was written well enough to how and what the project does. The only suggestion is to include screenshots. That would make the write up even more easy to understand.
noProblem Couldn't log in to test the code as no credentialsÂ were provided anywhere.
noProblem It works fine for the cases tested.
noProblem Yes, test plan is complete enough also team has explained the test plan technology to used to achieve it. Good knowledge of Capybara testing. Team could have added test scenarios for each issue step by step rather than single lines.
noProblem Test plan seems complete enough.
noProblem Written very well explained approach taken to solve the issue.. Along with what was the actual problem existed previously in the system and how team has given a thought process the fix the issue. No type of design patternÂ is involved.
noProblem The authors concisely explain the work they did. As a suggestion, I would ask them to include the tests written in the wikipedia page as well. The idea is for any reader to understand 100% what all happened in the project, without looking at the code.
noProblem Yes, the writeup explains explains how the authors did their work and they have mentioned the steps behind each functionality. They have made an UML diagram as well.
noProblem Write clearly explains the changes done.
noProblem The team does explain how and what they did.
noProblem The writeup includes their thinking methodology and why they arrived at that solution. 'Changes'Â under 'User Deletion' clearly explains what went wrong in the existing code and what should be added. One suggestion would be, instead of showing 'Before' and 'After', they could have leveraged Git s UI version of + , - in red and green to have shown the differences. But 'before after ' way worked too !
noProblem Nicely written Wiki with screenshots describing some of the changes made.
noProblem Yes, the purpose of the project is clearly explained.
noProblem Most of the edge cases seemÂ to be covered.
noProblem Unfortunately, the write-up does not include a test plan. The team has included the following line in the "Testing" section: "Fixed the existing test cases for the review feedback by a team instead of a team member." The team could improve this by adding the test cases to maybe to check whether the "get_feedback_assessment" method returns the proper assessment using teamid or not or check whether the summary reports navigation redirects the user to the correct page or not.
noProblem All of the cases discussed in the Test Plan have been included in the test file. And all of them are also passing. Very good!!
noProblem The tests have been properly converted into automated tests.
noProblem The test cases are covered in the coded.
noProblem They kept working on this test and improved it.
noProblem The names are very intuitive. The build doesn't seem to have been passed because of the indentation errors and failure to follow certain design guidelines.
noProblem the code follows correct name structure for variables, methods and class.
noProblem All the names are used properly.
noProblem Code contribution of all team members. The code doesn not smell dry
noProblem The code looks good. It seems well ordered, structured, and 'DRY'.
noProblem the function definition is of perfect size. the code follows the Ruby Style Guide.
noProblem No idea how to manually test the authors file.
noProblem The tests all pass successfully.
noProblem Clearly.
noProblem The wiki document was very clear with respect to the responsibilities of the group. it also detailed their approach to writing the tests as well as explained the functionalities that the tests were written on. Well done!
noProblem The write up is perfectly written.It clearly describes what functionality the work is related to. It gives information for each aspect of the project.
noProblem Test plan is well-rounded.
noProblem test cases are thorough
noProblem The test plan is accurate and checks for different pre conditions , edge cases , invalid input values. I could not find any missed scenarios.
noProblem For the methods that include different conditions, they provided tests fo different kinds of conditions. Also, for each method, the team test various aspects of the method.
noProblem Well explained information about the Design and the results.
noProblem The write up is enough for me to understand.
noProblem The document explained well the work and the approach to doing the work.
noProblem The write up is clear with its goal. It nicely explains how and why did the author work in a particular way.
noProblem The naming conventions are followed as per standards
noProblem Follows ruby standard codes. Already implemented functions are changed and have stayed away from adding too many functionalities.
noProblem Everything works fine according to me.
noProblem Yes, the features which have been done till now work well.
noProblem Very precise write-up with nice details on how the fixes were applied.
noProblem The write up is detailed. All details are mentioned including files involved, solution as well as test plan and how they have done or implemented the solution. The code snippets also gives good idea of the project work. The first part gives detailed background of the project.
noProblem Enough details has been provided.
noProblem I think the test-plan is complete and most of the edge cases are covered.
noProblem Test plan is manual.
noProblem They have included test plan but few examples and screenshot of their work would have been a plus point.
noProblem Testing is done manually and there is mention of automated tests in the wiki but no files are seen. It's better to provide all links like github code, testing videos and wiki while submitting on expertiza.
noProblem I understood the write-up pretty well. I also liked to way the fix was implemented
noProblem Yes, the writeup explains explains how the authors did their work and they have mentioned the steps behind each functionality. They have not used any design principles or patterns.
noProblem Yes, team has explained why they worked in certain way.
noProblem It explains their approach and issues they encountered like latin format, storing html tags and how they fixed it.
noProblem All the cases discussed in the test plan have been implemented.
noProblem they have done all the 29 test case and test them throughly.
noProblem The team has tested all the methods of the corresponding model file.
noProblem Well done in achieving 100% test coverage and passing all the tests.
noProblem Yes they have converted them.
noProblem work as intended to be
noProblem Code style seems to be good.
noProblem Not find anyÂ improper variable names or method names.
noProblem Names for variables, classes, and method are properly named and make sense
noProblem The code is DRY enough, and the functions seem to be compact.
noProblem This was a testing project and the mocked objects were appropriate
noProblem The code is DRY. There is no redundancy in the code.
noProblem All the codes are of perfect length. That is actually one of the best thing about the code. It follows basic ruby style guide.
noProblem Code climate issues that were reported have been fixed.
noProblem For every tested method, they explain why theyÂ created certain objects or did what they did
noProblem The writeup explains well the plan of work of the authors and the way in which they approached the task at hand.
noProblem Appropriate explanations are provided for the tests.
noProblem Yes the Test Plan part is pretty through, they list all 29 test case they have done for the assignment_team.rb.
noProblem The Test Plan is detailed and comprehensive. Good job!
noProblem no miss
noProblem This wiki is very detailed and explains what is done for every tested method
noProblem The write up is descriptive and very well written. I could easily understand everything about this project. Good job!
noProblem From the document I could understand the functionality on which the tests were written.
noProblem The writeup describes briefly and clearly what the AssignmentTeam class does in the expertiza project. It has also given the details on the test plan, test cases and explained the use of RSpec testing framework and factories. I would suggest to add a link to their video that shows the tests running in the wiki page. All in all good work!
noProblem The tests are very well written. They clearly indicate what functionality they are checking for.Â The tests follow a language that is easy to follow.
noProblem The writeup matches up very well with tests written and also describes in details what scenarios are tested.
noProblem yes, very clear
noProblem All tests works fine.
noProblem It's a testing project and the video provided show that all test pass and they have at least 90% coverage
noProblem As mentioned above, and also stated in the video and the pull request itself, the author has covered up everything.
noProblem hey variables follow all the stanard conventions that it needs to.
noProblem Yes the tests are automated, also the command to run the test is given in the wiki.
noProblem The test cases given by the team work as described. The features are implemented accordingly. The edge cases are considered while designing the mocks. In general, all the code for test cases works as specified.
noProblem Video seems fine, covers all the cases with 100% coverage.
noProblem the code follows Ruby style guide. the code does not contain long methods. the variables and functions are properly named.
noProblem They have covered all cases which they mentioned in the Test Plan
noProblem the writeup just simply explanin what is expertiza and the requirement for this program.
noProblem It has all the details about the testing for review_response_map class.
noProblem Since it is a test project, their variables, methods and class names are reasonable and easily understand.
noProblem Regarding the writeup,Â I told the changes which I felt needed above. The code looks comparatively neat. A clear video showing the test cases running will be appreciated.
noProblem Write-up provides all the necessary information needed to understand the project but a brief explanation about certain methodsÂ would have been better.
noProblem The unit test cases were completely fine, and covered almost all of the code.
noProblem It divides testing codes into parts, and described purpose of each chunk of code.
noProblem Briefly covered all the possibilities.
noProblem As mentioned above, it lacks some depth in this.
noProblem For testing I don't think there are any design related thing.
noProblem No team could have given some info on that
noProblem The coding syle is good well versed
noProblem The code is written neatly and follows the suggested guidelines.
noProblem The code is well written. DRY concepts are used.
noProblem Test cases are effective, with minimal statements there is maximum coverage
noProblem The code looks good.
noProblem The code works fine for the listed functionalities. All the cases along with the edge cases are considered.
noProblem the basic test cases are test well.
noProblem The test cases work as expected and handles edge cases as well
noProblem The code works in the edge cases also for delete an other tests mentioned.
noProblem Yes, the code has all the possible test cases. Many of the edge cases are covered and listed in the wiki.
noProblem the writeup does bot explain how and why the authors did the work the way they did.
noProblem The wiki for this project contains tons of useful information about testing and rspec. I am not sure that some of it needs to be explained to the current extentÂ (example: what unit testing and TDD is or the environment set up). They are nice to include but maybe less as the purpose of the project is not to educate on those topics. Overall, this wiki did an outstanding job of describing the purpose of the project.
noProblem They have clearly state what the platform is and what they have tested.
noProblem This wiki is the most comprehensive one I've come across. Right from the basics of Expertiza to unit testing to developing and explaining the test cases, everything has been done to perfection. Also, the result and the explaination for choosing the test case is provided, which is very much appreciated.
noProblem I think this team has done a nice job on the writeup of unit test, which contains every functionality of their work and is easy to understand.
noProblem The writeup Problem Statement section is very clear about what their work relatedÂ to.
noProblem The wiki document coherently specifies the overall procedure adopted by the team for the project. From the page, it is seen that the team have given a general overview of the project scope and additional functionality and references used towards the working of the project.
noProblem wonderful job with 100% coverage
noProblem All the tests passes with 100% test coverage. Great work!
noProblem The team has worked well on changing magic numbers to reasonable variables. For example, 1 to item.
noProblem From the pull request, it is clear that the team wrote test cases for the menu model and achieved a 100% coverage that checks for most of the edge cases. The variables included the mock instance have been adequately used for testing the methods.
noProblem good job
noProblem The code is "dry" enough with some "before" statement to prevent duplicate codes.
noProblem code style is perfect
noProblem The code properly provides test cases for both the Menu class and the Node class(in the Message class). The code follows the DRY principle such that all the test cases use the variables and scenarios appropriately.
noProblem All the test passed.
noProblem Yes, very well done on adding tests.
noProblem Test cases not passed
noProblem The write up is well formed and structured. The entire flow is explained along with files changed/methods implemented in each stage. Could have described the approach a bit more.
noProblem Code convention for mail looks good but I found find_participant_emails misleading because it gets email for all participants and not emails for participant
noProblem more comments are needed for clearity .
noProblem There are some style issues related to spacing and unnecessary parenthesis.
noProblem Did not find any problematic edge cases.
noProblem The team have done a good job in explaining their work.
noProblem the related functionality is mentioned.
noProblem Perfectly explained write up along with the design document to get the better understanding of the issues and flow.
noProblem writeup explains inÂ brief how and why the functionality of sidekiq was implemented.
noProblem The wiki has been documented with a lot of details explaining the problem statement as well as the approach.
noProblem Yes the writeup mentions why the authors did the work the way they did it by clearly posting screenshots of the code modifications done by them.
noProblem The names seem to be appropriate to their functionality.
noProblem The code is appropriate but additional comments would make the code much more readable
noProblem The write-up is well written along with the screenshots attached for the code changes which helps in explaining the issues and changes made to solve those.Â Just one suggestion, if you are explaining all the steps and redirection for some issues/changes please keep the content consistent for other issues/changes as well.
noProblem Well written
noProblem Methods, names etc are used according to the functionality. As mentioned earlier half the code changes are explained.
noProblem Basic functionalities working
noProblem Wiki page is clearly and neatly written. I could understand what the project does. Writeup also has code snippets which has been modified.
noProblem Yes the writeup explains how and why the did the modifications. It has comparisons between the previous and new versions and why they made they made the necessary modifications.Â There was no mention of using design principles or patterns.
noProblem 1. Functions are of appropriate length 2. Codes are in appropriateÂ methods 3. Code is very well commented. Overall, great work. Clearly Understandable.
noProblem The write up is well made!
noProblem Problem is well defined but the authors have listed 3 issues that need to be fixed but they have only provided 2 links in the problem statement. It will be nice if they can give the link to the third as well.
noProblem Yes authors have an details about code changes that they have done and why they have done. I would have liked more emphasis on "why"
noProblem the writeup is understandable.
noProblem not adequate explanation.
noProblem All the cases are covered.
noProblem Test Plans are missing
noProblem Testing isn't applicable to this assignment.
noProblem The background and problem statement are clear and concise. The description of the implementation is thorough but a little too detailed. It relies too much on the source code and not enough on figures and written explanation.
noProblem Write up is easy to understand and follow.
noProblem More of what is done is explained. Also, steps to manually test the instance could have been included.
noProblem Workflows worked properly when I tried.
noProblem The authors have not converted test cases into automated tests. However manual testing has been shown in the vedioÂ link attached
noProblem All provided variables are well assigned.
noProblem Good thing would be to increase the test coverage.
noProblem Variables and methods seemed intuitive enough
noProblem The functions added are not too long. This is the minimal amount of code that had to be added toÂ implement the changes.
noProblem The commits show contribution by only 1 author. The code does not smell DRY.
noProblem The code is DRY however, certain sections of the code could be shortened further.
noProblem everything seems to be working fine.
noProblem Since the code is not deployed, manually testing cannot be performed. But, the screencast shows that all the manual testing is passed.
noProblem From the video it seems it should work fine with the edge cases as well.
noProblem Manual testing could not be performed as the link to the deployed application was not available however the vedioÂ link attached sufficiently demonstrates how the features work.
noProblem all the scenarios including the corner cases are working fine. No issues or problems were found with the functionality. The only issue is related to the CI built which is failing at the moment. The team needs to analyse the root cause related to the build failure and fix it. Other than that it was a great team effort!
noProblem The write up seems quite understandable.
noProblem The write up is well written and explain how and what is done in the project regarding all the issues.Â Just one suggestion- it would have been great if the screenshots were uploaded corresponding to the changes made. But, otherwise the writeup is understandable.
noProblem Yes, the project is to do 2 things : 1. Stop teams from dropping assignments very late / close to deadline 2. Have different deadlines when assignments are done at different periods. The wiki should be created on expertiza page and not on wikipedia site.
noProblem The write-up is clear and clearly explains the issues corrected.
noProblem The wiki is well written and contains all required information regarding the project. The screenshots can be included in the wiki and the code pasted in the documentation could be formatted. The team also need to inlcude the test plan section in the wiki. Apart from this , the team did a great work.
noProblem Good, but lacks readability. The code is directly copy-pastedÂ in the approachÂ section. You could have used the pseudo code with proper explanations. The structure and formattingÂ should be improved.
noProblem No test plan is included but it seems that team have covered all the scenarios properly.
noProblem The write up does not have a test plan.
noProblem I found the test cases to be sufficient. No suggestion needed.
noProblem I don't think there's any testing involved in this assignment.
noProblem Writeup doesn't has a test plan but in the video they have testedÂ a lot. Also please add audio as well in your video explaining what you are doing and why so that its easy for the user to understand, otherwise watching 23 minutes silent videos is just to much.
noProblem No proper test plan has been mentioned yet in the write-up. But a link to demo vedioÂ is available which includes the manual testing case.
noProblem Test plan section is missing.
noProblem Writeup clearly explains why the team followed the particular approach and additionally mentions all the steps followed,thus defining the approach clearly.
noProblem The writeup does talk about the changes and why the authors did it that way. Â Rather than pasting the code (without any indentation) in the wiki page, the authors could have pasted screenshots of the code! This might have made it easier to comprehend.
noProblem The readme was sufficient to explain details about the idea and also both the videos explain stepwise how this is achieved and demonstrates it. AlsoÂ the bugs are fixed and droptopicdeadline has been integrated into the code of this assignment.
noProblem It's hard to understand the code you have changed from writeup. I sawÂ the changes in your pull request it looks good to me.
noProblem Not very comprehensive.
noProblem There are no changes to any files in the spec directory so there are no new tests.
noProblem No tests were added.
noProblem New method names and variables are fine, however this team did not add a lot of new classes, methods, etc.
noProblem 2 failed and 1 accepted.
noProblem Their code changes are little, though they have handled naming conventions in a good way, as illustrated below. def self.handle_duplicate
noProblem The work done is successfully implementing the required changes
noProblem all the code looks well written and dry to me.
noProblem The handle_duplicates function has a lot of white space and print statements left in it. It could've been chopped up into tiny sub-functions too, hypothetically.
noProblem 1. Functions are of appropriate length and well structured with respect to the purpose in question.Â 2. All code has been suitably well put into the methods with their intended function and work cutout for them.Â 3. No, the comments have been well placed and self explanatory making it easy to follow.Â 4. The code does follow the ruby style guidelines and is thorough in that regard.Â 5. Nope, all code is consistent and to the point.
noProblem The code contribution is significant. The function such as import_team_members shows good coding practice and following Ruby code standards.
noProblem Their code changes as per the pull request is less.Â They have done justice to the little code they changed.
noProblem The code is well written following the concepts
noProblem Worked as documented
noProblem No test plan. Don't know why this question is even asked.
noProblem Code is good enough.
noProblem No test plan required I suppose.
noProblem Yes, the team has efficiently detailed all the details about the projects and the need for their changes to providing code of their changes. They have also attached coverage and test run screen shots for references.
noProblem I think the code looks good and very much follows the Ruby Style Guide. The code also is DRY. It looks well written and does not any changes.
noProblem There is no Test Plan section at this time. However, the authors did include some discussion of edge cases and the fact that the initialize function required testing of known success case and potential failure. I think that this is sufficient without the inclusion of a Test Plan section. I would suggest that since this rubric calls for the section to just rearrange the content of your current page. Also, include the additional edge cases that you have already tested for in the other functions possibly with some specific examples. This will allow for a more thorough Test Plan section.
noProblem Variable names and test cases are name appropriately. Test cases context, describe, and it statements are clear as to the division and purpose.
noProblem The code is written very neat and follows suggest guidelines. Authors have done a great job with the DRY principle and bringing out statements that would have been otherwise repetitive in the test cases.
noProblem The authors seem to have considered most edge cases and pre-conditions. The section isn't explicitly named 'Test Plan', but the necessary content is there.
noProblem Everything is described clearly and the functionality added is easy to understand.
noProblem All code is formatted well and neatly, with clear functionality.
noProblem All tests designed were to be automated.
noProblem Nothing to manually test.
noProblem The write-up is descriptive and shows code from the _spec file paired with explanation.
noProblem The pseudo-code test plan does a good job of explaining the functionality of the tests without being clogged up by implementation details. I do suggest putting it closer to the top of the wiki page though.
noProblem All tests pass, and 100% coverage was attained.
noProblem Very nicely written document with test-plan which explains each test case , why it is written and what it tests n simple English language.
noProblem very nicely articulated description of all 29Â testcases.
noProblem Rspec code looks good.Proper comments and good variable name usage are 2 things i will suggest to improve. Very good work overall.
noProblem Yes , all 29 test cases have been automated. The youtube video describes it perfectly
noProblem The tests run successfully even when cloned and run in development environment on VCL.
noProblem Tried to cover maximum test cases and explained well in the document with the coverage and video
noProblem The write-up explains the tasks adequately enough for a user to understand the expected outcome.
noProblem They have explained the tests that needed to be implementedÂ to verify the working of the functionality.
noProblem The test plan looks complete enough, they have covered most of the cases. The test coverage has increased a little bit.
noProblem The write up is very clear, methods and test case are explained in a neat way
noProblem The procedure and intention for writing the test cases is clearly mentioned
noProblem All the scenarios are covered. Even the branch cases
noProblem All of the above 5 criteria are met.
noProblem Yes most of the edge cases is checked.
noProblem The writeup has documented all the changes they have done, but could have been more elaborative on the exact functionality of menu.rb.
noProblem No, all method names and describe provided are apt and to the point
noProblem yes and all cases pass
noProblem Their tests are very straight-forward and can be extended to test few edge cases
noProblem Authors explain the test destination vividly.
noProblem All variable names are reasonable and easy to understand.
noProblem Neat code and well established form of the test.
noProblem Test plan looks very generic.
noProblem Test plan is given a appreciable thought and team has also implemented test scenarios mainly inÂ student_task_controller_spec.rb WouldÂ suggest team to try and increase test coverage.
noProblem Good work on including test cases.
noProblem The code changes are well organized and nothing is out of place.
noProblem I could see commit performed by only single team member. 1. Functions are not too long or repeatative. 2. No code needs to be extracted as a new function. 3. Yes team need to add more comments. 4. Team does follow Ruby style guide. 5. Team understood rails and followed DRY principle well.
noProblem I feel some comments can be added before every function for the code to be understood better.
noProblem 1. Functions are of appropriate length 2. Codes are in approriateÂ methods 3. Code is very well commented. Overall, great work.
noProblem the features added seem to be running good .
noProblem The code works as it should.
noProblem The wiki documentation has been updated. All the information has been documented in a neat and logical manner. The write up adequately provides what functionality the work is related to. The project changes to the code have been described in paragraphs which could have been better if they could have updated with code snippets and screen shots of the tasks at hand.
noProblem Wiki has been well written, with enough clarity and description
noProblem It is clear what the project does and why it does it.
noProblem The writeup is clear. It is easy to understand what the project does. It would be better if you can put in more code details and major pieces that do the important logic.
noProblem The writeup is pretty clear.
noProblem The test plan section is present, and it is covering all the scenarios.
noProblem They seem to have included a testing plan have mentioned it in their report. They seem to have considered edge cases and other possibilities.
noProblem Not much has been explained about the test plan. The authors have, however, explained how they will be going about the testing in general. An overview is provided which is clear to understand.
noProblem More details are expected in the Test Plan like edge cases, normal cases.
noProblem The writeup explains everything regarding why and how the steps were carried out.
noProblem They have explained how they have implemented each task by adding/editing files.
noProblem Yes, the writeup explains what the authors did.
noProblem The team has created a new spec file to test all the issues of the PR.
noProblem Yes, the cases discussed have been converted into appropriate tests.
noProblem Adequate testing was performed using RSpec tests for both the issues.
noProblem They have converted the test cases mentioned in the test plan into automated tests. The tests have been implemented as mentioned in the write-up.
noProblem The team has made minimal changes in the code to fix the issues. No new class, function or variable has been added.
noProblem All tests pass.
noProblem No automated tests. But the fix seems to be working fine as per the test plan provided.
noProblem No issues found.
noProblem The newly added code adheres to ruby programming standards.
noProblem The names used seem appropriate to their intended functionality.
noProblem The variables, methods and class names are named appropriately. The variables used in the program suggest the functionality.
noProblem There are no additions in terms of methods or any new implementation. There are minuscule changes done so it still follows the existing standard.
noProblem There were not many big changes. All the changes are crisp and to the point.
noProblem The team has done well not to over complicate the issues and have resolved them with relatively few additions.
noProblem The code follows Ruby style Guidelines and is DRY.
noProblem The code resolves all the issues as per the problem statement and the features work correctly.
noProblem It works as expected.
noProblem Seems to be working.
noProblem The features for the issues fixed work as intended.
noProblem The team has explained the problem statement as well as the approach they has chosen with lot of details. It makes it very easy for end user to understand details of the project.
noProblem Write up is clearly understandable. Systematic approach taken to fix the issue.
noProblem Write up is quite impressive. I was able to understand the project through write up.
noProblem The write-up is good and clearly mentions the issues to be corrected.
noProblem The problem is explained clearly and the implementation plan is also described elaborately. The explanation helps in understanding the project very well.
noProblem The team has included test plan as well as the screenshot of the manual testing.
noProblem Write up has test plan with clear steps and screenshots.
noProblem They have covered few edge cases. Just a suggestion to include result before and after fixing the issue. May be juxtapose it.
noProblem Yes, the project deals with an issue related to names,Â such as not allowing whitespaces , etc. The test verify that the issues are now solved.
noProblem The test plan looks good. It includes both manual testing and automated testing by writing Rspec tests.
noProblem Yes the team has done great job in the write up It is properly indexed and addresses details about each issue and its solution.
noProblem Write up explains about the problem and how it needs to be fixed which seemed logical
noProblem They standardized the team name generation and fixed the username without space. For design patterns I think they didn't used it may be it wasn't needed
noProblem No write-up available rn
noProblem The write-up clearly mentions the issues to be fixed and the code changed to fix each issue.
noProblem The write-up explainsÂ the approach used and the code used for implementation very clearly. The test plan is also defined extensively. Screenshots help in understanding the implementation more. They did not use any design patterns.
noProblem All test cases seem to be passed.
noProblem Ruby coding practice seem to be fine. Class and variable names are apt.
noProblem method names and variables are used aptly which helps in easy understanding
noProblem The newly added variable, methods, class names are written properly. The names indicates the functionality implemented by respective names.
noProblem Function and variable names seemed to be appropriate enough. The names suggested the functionality. No suggestion is needed.
noProblem The naming conventions are properly followed. In case of Ruby, snake case has been properly used and in case of JavaScript code, camel case is used.
noProblem Methods are not too long and each function is performed in the appropriate method
noProblem 1. Functions and logic are written properly without long functions and dead or messy code. 2. No . Team has provide good modularization. No need to extract code further into more functions. 3. Code was understandable and easy to understand. 4. Code does follow ruby style guidelines. 5. Code and packages follow DRY principle.
noProblem Code seemed to follow the ruby style guide
noProblem none of the functions are too long Â could find changes where DRY principle was violated Â the code follows ruby convention and guidelines Â comments were included wherever necessary. the code is easy to follow. Â Good Job!
noProblem The code is well written. The function length is also well within the required bounds. Comments adequately convey the info about the functionality that is implemented.
noProblem They have not provided a link for the deployed so cannot test anything but they have provided a video and according to that everything seems to be working
noProblem Not deployed but the video provided which includes the demonstration of the fix.
noProblem The manual testing done in the screencast seems fine. The features work correctly
noProblem Everything is explained in detail
noProblem Issues explained properly and change as well. The modifications are demonstrated using screenshots which helps in better understanding.
noProblem The test plan seems to be complete enough. No additional pre-conditions and edge cases are required.
noProblem Issue 1 under solutions tab is actually the third point discussed in the Fixes Required.It could be discussed as Issue 3Â rather Issue 1 for better clarity. Only the solution for one issue is discussed. (?) The discussed solution is again well-defined with adequate screenshots.
noProblem One test case visible.
noProblem yes the functionality still holds good.
noProblem Decreased to 12%.
noProblem The test coverage on the contrary decreased
noProblem The names are intuitive.
noProblem The variable names look fine, methods names are also meaningful.
noProblem 1. Some Functions are of huge length and adequately structured with respect to the purpose in question, but I am assuming the complexity of the question requires so.Â 2. All code has been suitably well put into the methods with their intended function and work cutout for them.Â 3. No, the comments have been well placed and but are veryÂ strangeÂ and vague at some places suggesting an amateur approach.
noProblem Not really clear. Lines have been changed. No specific functions. But it shows good coding skills.
noProblem The project's purpose is to refactor the code. Hence the code has been separated into different files for better understanding.
noProblem I can see a file changed and the code in it looks to follow the concepts which needs to be followed
noProblem The code follows Ruby standards and DRY principle.
noProblem The code seemedÂ ok to me.
noProblem The functionality does work. Some errors are visible as shown by Git.
noProblem Cant really know what exactly is completed.
noProblem Some of the common edge cases work as per expected
noProblem They were not required to write automated tests as far as I know
noProblem The newly added code does adhere common HTML standards. The only other change is to the db schema.
noProblem Variable, methods and class names seems as per coding standards and variableÂ names are making it easy to understand the logic code. Hence names used are reasonable.
noProblem The only change this team had to do was add color codes for the various types of links that come up while reviewing. This would be hard to mess up.Â And the team has not messed it up. Good Job guys.
noProblem The added code is easy to understand and not complex.
noProblem The code added is extremely easy to read, follow and understand.
noProblem repeated style tags
noProblem Looks good.
noProblem The code follows Ruby guidelines. However, since the project involved just adding colour to certain links there was no point of the code being DRY. In fact, reviewing this project doesn't make sense since the project was literally just changing 3 lines of code, NOT THAT IT IS THE FAULT OF THE TEAM.
noProblem The code is complete and does what it was intended to do.
noProblem The implemented solutions work in the deployment
noProblem There are just the changes in the button colours required which are working as expected.
noProblem Yes. Team has resolve the issue very well and also taken care of edge cases.
noProblem The changes in this project were simple enough to work for all edge cases.
noProblem Looks great.
noProblem Yes. The team clearly indicates in the wiki, what this project is related to and how they went about to complete the given task at hand. I'm not sure about this, but maybe the heading for the wiki is incorrect. This project is listed as E1828 in the list of OSS projects. But the team have named it as E1785. This may be a mistake on the team's part, if so, I would suggest them to correct it.
noProblem The document is well described with details on Expertiza, its purpose. It also details the files related to their assignment.
noProblem Explained very well.
noProblem There is no scope of a test plan with changes made to the view.
noProblem There is no explicit test plan mentioned in the wiki. But for this project I don't believe one was needed.
noProblem The writeup doesn't has a test plan, but the work they have done is on UI i.e. colouring the links. So there won't be any edge cases as such to fail in this project.
noProblem They have explainedÂ the changes they have done and why they have done them.
noProblem The project was to change the colour of certain links to depict certain statuses. Since the complexity of the project was not high there was no scope to use any design principles or patterns.
noProblem The write up explains each and every thing which they implemented
noProblem The code change seems simple enough that does not require any design principle or patterns. Whatever the code changes are, explained properly and coding principles with required output.
noProblem The write up does intend to capture the changes that have been made, there isn't much for them to explain and thus the writeup seems short. There isn't much scope for the team to have used design patterns in a project which involved making cosmetic changes to the views.
noProblem Looks good. Explains what work is done and what is the corresponding output
noProblem the document contains the whole information including the test plans and the the expertiza environment setup. It is neatly documented as well which makes it more readable
noProblem Again, since their entire project is on RSpec testing, so this aspect has been well taken care of.
noProblem As mentioned by the team, more code needs to be added for 90% coverage.
noProblem The tests are included
noProblem The variable names seems good
noProblem It follows the DRY principle
noProblem Difficult to understand what are the changes .
noProblem Code written follows the Ruby Style Guide.
noProblem Very well written, clean and concise.
noProblem It seems to work well.
noProblem Manually Tested the Test Code and 97% covered(validated via Coverage.index file)
noProblem All the tests pass successfully.
noProblem Yes. I can understand the intention of the test. Nicely done
noProblem Feel a pretty good job has been done.
noProblem Since, their entire problem relies on the RSpec testing framework itself, they have implemented it in a good and a concise manner.
noProblem Yes, testing is thorough
noProblem The writeup does a good job in explaining how the authors did the work they did.
noProblem Basic test missing.
noProblem Seems like some tests have failed.
noProblem Yes, converted Test Plan into automated tests.
noProblem The authors have converted all the cases discussed inÂ Test PlanÂ into automated tests
noProblem The names of variables and methods are aptly chosen and clearly understandable.
noProblem All the method names/variable names and class names are intuitive and according to Ruby standards.
noProblem No long functions No separate methods required. Follows Ruby Style Guide.
noProblem The code does followÂ "good Ruby and Rails coding practices". No bad naming. Every file is properly named based on their functionalities. I cannot find issues with coding. One method handles only one task. I could not find any bugs in the system and this works exactly how it is supposed to work.
noProblem The code is concise with 3 functions in the controller. Sufficient comments are used to explain the logic. The code follows the DRY principle, as there is no repetition seen in the code.
noProblem The code follows Ruby Style Guise and follows DRY principle. None of the functions is too long.
noProblem none of the functions are too long could find changes where DRY principle was violated the code follows ruby convention and guidelines comments were included wherever necessary. the code is easy to follow. Good Job!
noProblem Yes, works properly.
noProblem Test case implementation is not done.
noProblem No bugs found. Works as intended.Â The System works without any glitches.
noProblem The features perfectly work as intended.
noProblem Explained clearly in the wiki!
noProblem Explains well. Consists of all sub topics.
noProblem The wiki has been written in a very clean and readable way. It is very legible and I could understand what the project does and how the project does what it does.
noProblem The writeup is very nicely written. By reading the background section, anyone can understand the functionality the project is related to.
noProblem The wiki is well written and contains all required information regarding the project. The screenshots included in the wiki could be more specific with the details of what would the student view and default view. Apart from this , the team did a great work.
noProblem Yes, considers all test cases.
noProblem The test plan looks complete.
noProblem The team did a great work in creating automated scripts for the cases related to the scenario. The scripts are also included in the automated test plan.
noProblem Write up is explained in detail.
noProblem Explained well.
noProblem Yes, explains correctly.
noProblem Yes, the team has clearly explained, the code which is written to avoid the confusion due to the presence of two "Assignment " tabs in the Instructor view. Appropriate comments are provided to understand the logic behind the methods.
noProblem Nicely written write-up explaining details about various issues, fixes, and tests.
noProblem seems like test cases cover the edge cases.
noProblem Nicely written code
noProblem Everything seems to be working fine for me
noProblem Yes, the writeup is pretty clear.
noProblem Yes lot of new tests added and the addition of the tests has 92% code coverage. Great job
noProblem Pretty good at this part, they list almost every testing case in the wiki, talking about what condition it is and give the code.
noProblem All of the codes seems "dry" enough, have some "each" statement to prevent duplicate codes.
noProblem They did all of them.
noProblem All the test case works.
noProblem The writeup clearly explains what the team has implemented. It is very clear and can easily be understood. test case for each and every step is clearly explained.
noProblem string passed in "it" clearly explains what the test case is going to do. as it is a unit test, there are not much variable that are named. already assignd variables are used.
noProblem none of the functions/cases implemented are too long. they are short which are easy to figure out what is actually being implemented. The code is easy to understanf so there is not much need of comments but some should be added
noProblem Excellent write up. Includes all important details. It is one of the most intuitive write up so far I have reviewed.
noProblem The overall structure of the code looks good and all the coding standards have been followed.
noProblem Most code changes were on UI, and written perfectly. No commits after first deadline, so same as first review.
noProblem I think their code is well written.
noProblem No new code was committed during the second round. This could be due to the fact that the team finished their code at the end of the first round itself.
noProblem No new commits.
noProblem No, but all the functionalities are working fine from 1st review itself.
noProblem There are no new commits.
noProblem In the first round the team had only created the two Web IDLÂ files namely OffScreenCanvas.webidl and OffScreenCanvasRenderingContext2D.webidl; which are the interface files which define the implementation in the corresponding files offscreencanvas.rs and offscreenrenderingcontext2d.rs. In this round the team has implemented the functionalities described in the two Web IDL files in offscreencanvas.rs and offscreenrenderingcontext2d.rs. The offscreencanvas.rs interacts with the javascript and hence has the constructor with attributes height and width; a method getContext() to return the reference to OffscreenCanvasRenderingContext2d; and a reflector object for garbage collection. The offscreenrenderingcontext2d.rs file does not interact directly with Javascript and does not have a constructor or reflector object. It has the code to build the offscreencanvas object.Â On inspection, the variable and method names used in the code are intuitive. But the main issue is that the name of the webid
noProblem No new commits made during the second round, as the functionality seems completed in the first round itself.
noProblem There is no new commits during the 2nd round.
noProblem The code seems to be good. It follows the principle of good design. Even though I do not know RUST, the use of variable names was very intuitive.
noProblem The code doesn't make sense to me, someone who isn't familiar with this project, but it does seem to be formatted well.
noProblem There are only minor modifications and they are well written. I don't think there is any other way it could be done.
noProblem The code changes are majorly on html files. Capybara could have been used to test the functionalities The code coverage has increased overall.
noProblem There is no new test and the coverage did not increase.
noProblem Yes, there is
noProblem Tests have been thoroughly and very well performed. Also, well documented.
noProblem The code seems to be written well. The Ruby style guide is followed.
noProblem Team added elaborate Test plans and implementation for their test cases.
noProblem The team provides some test cases, but it seems the tests were all done themselves and they didn't write codes for it and make it automatic. The test shows the feature work properly.
noProblem Some commits were made to rectify old errors and get an approved pull request
noProblem There wasn't any link provided to check if the UI was working fine. But there was a video showing the projectÂ successfully running. And also the tests did seem to cover almost all the scenarios.
noProblem Everything works like expected.
noProblem Yes it works as intended. From the video, it seems everything is working fine.
noProblem Yes, new code has been committed in the 2nd round. The team has essentially implemented the offscreencanvas.rs and offscreenrenderingcontext2d.rs. offscreencanvas.rs is respondible for implementing the OffscreenCanvas.webidl. This interacts directly with javascript and when a new instance of offscreencanvas is created, it calls the constructor with arguments height and width which in turn calls the new method defined in this file. It also contains the reflector object that tells the Javascript garbage collector to ignore the canvas object while clearing memory. Additionally, it has the implementation of the getContext() method that returns a weak reference to OffscreenCanvasRenderingContext2d, which is responsible for doing background rendering task. offscreenrenderingcontext2d.rs has the implementation of OffscreenCanvasRenderingContext2D. It does not interact directly with JavaScript, so it does not have the Constructor or reflector. The functionality to build an offscreencanvas object ha
noProblem Yes there new commits in round 2.
noProblem The writeup has been pretty well written by the team. Introduction to the problem statement, the implementation details, and the test plans have been stated.
noProblem The writeup is accurate and sufficient, the team gives clear explanations for the whole project and the process to realize it. For the point that is not easy to understand, they provided some examples and use mathematics method to support the explantation, which makes the read easily.
noProblem Several new commits were added during the second round.
noProblem The writeup is elaborate, well written, with proper description of the test cases with screenshots and steps for each issue.
noProblem Overall, I think the write up is good and clear.
noProblem Well documented and explained with good amount of screenshots. Also the video length has been reduced to only whatever needs to be shown, which is great.
noProblem The authors have improved the writeup based on the suggestions from first review.Â It is more precise and self explanatory. The background is lot clear after the first review.
noProblem The team has made a great improvement with respect to the previous submission. The code is brief and easy to understand.
noProblem I do feel the code can be deployed to the production server once a few test cases have been implemented by the team.
noProblem Test cases are yet to be added
noProblem The changes can be deployed to production server.
noProblem Yes, it works as intended and code follows the ruby guidelines, the documentation is well explanatory.
noProblem I think this code is ready to be deployed onto the server.
noProblem The team have done a great job and passed all their tests.
noProblem The team has suggested 2 methods to test. The first and the recommended method is using the existing automated tests for OffScreenCanvas feature. A new offscreen-canvas directory was added to tests and a new .ini file enables the new preference. The second approach is writing own test cases and a sample HTML file can be used to test if the OffscreenCanvas is rendered.
noProblem Travis CI has passed.
noProblem Every thing has passed, there is no conflict or build fail.
noProblem No test cases as this wasn't a testing project.
noProblem Yes, the build pass in Travis CI.
noProblem The build passed with no conflicts in Travis CI.
noProblem The build passes
noProblem In the test plan section and on Git also I found no test cases written. There is testing done, however it is not what was desired.
noProblem The code was well written even in the first round.
noProblem The present test cases appear to be written fine.
noProblem No, the authors didn't improve the code.
noProblem To test the system operation the project has to be built and run. The Sample HTML file was used to render a Test Canvas as given in the Wiki
noProblem When tested the project does what was desired to be done.
noProblem The authors made a solid attempt at improving the writeup. However, there are still some issues. DOM was left undefined and the code was separated from the descriptions.
noProblem Write up is good,Â with code flow diagram and test plan (pull request).
noProblem No new code was committed during the 2nd round of resubmission.
noProblem The Wiki is pretty much strong with plenty of info.
noProblem Yes since it was a unit test assignment, tests have been added and overall coverage has increased
noProblem Coverage went up by 8.4%, according to coveralls.
noProblem The write-up is lucid and has now incorporated the changes that were made in the round 2. It starts off by introducing Servo, Rust, OffScreenCanvas, web worker, Web IDL. The authors then describe the code flow using a flow chart which was really appealing. I especially liked the Under the hood section, which elucidated the files (OffscreenCanvas.webidl, OffscreenCanvasRenderingContext2D.webidl, offscreencanvas.rs and offscreenrenderingcontext2d.rs) that they modified/created in this project and their functionalities concisely. The write up then includes the code from the above four files and finally ends with the test plan with 2 approaches, links to pull request and references.
noProblem The write-up is good. I liked the use of the flow-chart to explain the flow of their code and explain the functionality. I think that this was the first write-up that used a flowchart.
noProblem They added all the test cases! There is so much coverage now!
noProblem Overall coverage was increased by 8+ percentage.
noProblem The writeup is the best part about the project. It describes clearly what and how the work is done. One can clearly understand their working strategy from the writeup.
noProblem The tests cover all the scenarios. Given that the problem statement is pretty open-ended, the changes fulfil the purpose.
noProblem Yes, It works .
noProblem I think it covers all of the scenarios, but don't quote me. I don't have a great understanding of review response map.
noProblem Since it is a unit test project with well-written tests, I don't see any issues why it can't be deployed to production
noProblem the test examples they showed are good.
noProblem The build is passing successfully
noProblem Yes, I feel the code is written in a good format. I checked the changes made by the authors and didn't find any bad naming or anything else.
noProblem The code was well-written in the first round itself. The method names, variabble names and class names are intuitive and suggestive of the functionality.
noProblem The code is well written. No issues with naming conventions/coding style.
noProblem Impressed by the coding and the way the solution was implemented. They implemented a complex feature in simple lines of code. Coding standard has been followed, naming conventions are followed and code is formatted.
noProblem The code is written really well. The professor frequently advised the team to improve the naming conventions as seen from the comments in the Pull Request. Suggestions: I still feel that the functionÂ review_reminder_emailÂ is a bit longer.
noProblem yes new code was committed during the second round
noProblem There are 2 commits
noProblem Two commits were done during the 2nd round.
noProblem 2 new commits - to add additional features.
noProblem No new commits as fix was delivered in first round.
noProblem No commits were found. The last commit was 15 days back.Â Suggestion: I feel that there should have been some commits as the pull request shows merge issues. The Travis CI build fails and the code climate is also not able to analyse the code. There should have been commits related to resolving these things.
noProblem There is code committed during 2nd round.
noProblem They have added the test cases with context as "when participant is added to the assignment using CSV" and the test case covers the required functionality that was intended to beÂ implemented
noProblem Team has added tests for assignment_participant model which they have changed. As the requirement was just testing one component, this is sufficient, however testing the controller would have been a more through Integration test.
noProblem yes, team has added the test cases and they cover the portion tp check whether the email has been sent to or not.
noProblem The team has added test cases. The test coverage has increased.
noProblem Yes everything is working as intended
noProblem Yes, this does work properly
noProblem The system operation works well as intended.
noProblem Yes, it looks fine to me.
noProblem The functionality works fine. Good job team! No suggestions.
noProblem The write up is well documented and covers all the needed information covering problem statement , a detailed explanation of how the functionality is implemented with what changes have been made to the different files and test case that they have added.
noProblem The code is up to the mark and has maintained god coding practice
noProblem The write-up is clear , concise and explains the work done properly. Some screen shots would have been handy though
noProblem The code is very well written. The code style is very succinct and very careful. There's no bad name, no long functions, nor any DRY problems. I have not done the first round review. But for this time it's very well-written. Good alignment.
noProblem code was well written the first time
noProblem The writeup was written very nicely in the first round itself.
noProblem Very detailed. Great job.
noProblem The code has been writtenÂ well and properly modularized. Since this is a testing project, all the RSpecÂ tests are written properly.
noProblem Yes , I think that the code can be deployed
noProblem Yes, it works perfectly
noProblem The test plan is added and Rspec test has been added.Overall testing seems good,
noProblem No there were no conflicts and do not need to be resolved.
noProblem Yes, there are new commits.
noProblem Yes, the team has committedÂ changes during the second round. The changes involved correcting the indentation issue.
noProblem I couldn't test manually, but the videos show proper operation.
noProblem As per their screencast(shared on the gdriveÂ link), the feature seems to be working locally. There is no Heroku deployment or a link to the VCL present.
noProblem yes they have included test cases and the the coverage has increased by +2.7% , it basically covers 39.427% of the code
noProblem The code is almost completed. Only a few final touches will make it ready to be deployed onto the production server. Maybe the future team can also work on it to achieve some more enhanced features.
noProblem This is not an Expertiza project.
noProblem The UI and system operation works as intended. The video provided clearly shows the issues that the team has handled.
noProblem According to their video, their code works well.
noProblem The write up has seen significant improvement. Flow diagram has been made and screen casts have been added to show the flow. Screen casts have been added for both bugs and functionality. Very good job
noProblem Extremely well written Wiki Page, thorough and to the point with enough technical content and relevant screenshots pertaining to the before and after scenarios of the problem statements.Â Moreover, its a considerable improvement from the last submission where in they had nothing of the sort.
noProblem The write-up is comprehensive and clearly mentions the filenames where the changes have been made. Moreover the team has explained the logic behind the code in the video provided which is really helpful. The team has done a good job with respect to that. They have added an flowchart image explaining the logic behind checkbox. This adds up to the readability of the project
noProblem The writeup is detailed and the authors have done a nice job. It covers issue, their solution, explanation of the solution and test plan.
noProblem Yes, there are only minor modifications and they are well justified.
noProblem 100% coverage by the test cases.
noProblem Yes, the coverage is 100%.
noProblem Yes, as the project purely involves adding unit tests, the team has added all unit tests for participant.rbÂ model. The tests haveÂ increased the overall coverage by 2.7%.
noProblem The code coverage was 100% in the first round.
noProblem Yes the test covers all the intended scenarios with the edge cases and has a build pass of 100%
noProblem they did unit tests
noProblem More test cases can be included for testing "sad paths".
noProblem Yes, they cover all the scenarios.
noProblem Yes, this testing project covers 100% of testing coverage.
noProblem The code coverage is 100%.Â Every test case passes after a manual check.
noProblem The write up is quite well written and is properly sequentially presented which increase the readibility
noProblem The documentation is well written.
noProblem The writeup covers all the relevant parts of the project. The primary objective of the project is defined clearly. A comprehensive description is provided for technical steps needed to set up the environment and the functionality which is related to the test suite. Furthermore, the team provides a detailed explanation of each test case along with the corresponding code.
noProblem Write-up is goodÂ and understandable.
noProblem Yes as the the test case has a build pass of 100% and also increases the test coverage , it should be merged
noProblem I think the code is totally ready to be put into production. It's written in a very professional fashion.
noProblem they did unit tests and they have passing coverage
noProblem I feel that the code is ready to be deployed as it's path coverage is 100% and it satisfies all requirements.
noProblem Can be deployed once travis passes.
noProblem Yes, they all passed the Travis CI. No conflict that's remained being not resolved.
noProblem The code seemed to be well written in the first round. But I dont see changes done in round 2. The github link provided shows last commit for Oct 21. Though I see that there are change made in the wiki which were required and are done well.
noProblem Unit tests achieved 100% line coverage and the use of Rspec's descriptions and context was great.
noProblem Did not notice anything repeated in the spec file. There is no bad naming
noProblem Write up is good enough to explain the code changes with their functionalities.
noProblem No new commits were added, but I don't think they should be penalized for this, as their code was already perfect the first time.
noProblem There are no new commits. Maybe this final version is pretty well-written so they didn't update.
noProblem Very nicely tested project.
noProblem Coverage was already at 100%.
noProblem Coverage increased by 9.7%.
noProblem Coverage is the same as before.
noProblem The coverage is 100%.
noProblem Video depicts tests running and passing.
noProblem Yes, they cover all theÂ scenarios.
noProblem It works fine with
noProblem Yes it covers all he scenarios.
noProblem Very nicely written Wiki, all test cases have been nicely described and the rationale behind the test is also well written.
noProblem The writeup is very detailed and even described a bug they found.
noProblem Well written document. Good job!
noProblem Team has explained everything clearly
noProblem Writeup is good.
noProblem Yes, I think it should be merged, mainly improving the coverage by ~10%.
noProblem Let's get some unit tests in this code. 100% LoC coverage is a great place to start.
noProblem The Travis CI build passed.
noProblem Seems at par with the coding standards
noProblem Did not find problems in the code in the first round. Follows ruby style guide, commented and good naming. Very well written.
noProblem No new commits have been made in the 2nd round
noProblem Last commit seems to be 11 days ago
noProblem No new commits have been made. All changes are in the documentation only.
noProblem I don't see any new commits for round 2, mostly nothing was needed
noProblem No new code was committed during the second round.
noProblem Unfortunately, there was no new commit added. The latest commit is 10 days ago
noProblem No new test were added but earlier tests are working.
noProblem The code was well written, DRY was not violated.
noProblem The code seems to be dry, and I had no issues with it in the 1st round.
noProblem It looks as good as round 1.
noProblem Naming looks good, they had already added comment to the code in the first review.
noProblem Don't see any DRY issues. Well Written Test code
noProblem The code is well written.Â No suggestions.
noProblem The team has added test cases: 1. To check that if there is no rejoinder for the review then it redirects to new author feedback page. 2. To check that the other teammate is able to edit. 3. To check if the page is redirecting back to review. 4. To check if the rejoinder by a participant of a team is saved properly.Â The overall coverage decreased from 48% to 47.601%. It decreased by 0.04%
noProblem No there had been no bad names or wrong conventions used even in round 1. so no change there. TheÂ team has made few modifications to beautify the code by using ternary conditionsÂ which did make the code elegant. No new comments added.
noProblem Commits for Code Climate changes were pushed in.
noProblem The team added new commits in the second round as well to improve their code style, improve codeclimate issues and changes other reviewer's suggested. Very few teams have done this. Great work.
noProblem Several commits were made to decrease the code climate warnings.
noProblem Yes. They are updating code to fix code climate issues.
noProblem Yes, there areÂ new codes committed during the 2nd round.
noProblem The number of commits since the 1st round is impressive.Â Significant improvements have been done pertaining to naming, indentation and overall Code Climate issues.
noProblem No new commits with respect to code or functionality. Just few indentations,Â comment changes and code beautifications done
noProblem The system operation from UI works as expected by the project. I was able to verify that the rejoinder is given by the team instead of team member. The rejoinder is also made easily available to the user, by providing easy navigation options to give feedback to reviewers, hence making the UI more user friendly. The Author feedback section contains the team's collective feedback to reviewers of particular assignments. Most of the task is to refactor code so that it complies with the new requirement of team rejoinders, and the features work as expected.
noProblem The projects works as intended. Some of the issues in the problem statement covers refactoring which has been properly handled by the team.
noProblem Test cases were added. Overall increase in the coverage range observed.
noProblem Yes, the team added relevant test cases which increased the overall coverage.
noProblem No unit tests were added during the resubmission, but they had an initially high coverage.
noProblem They achieve 100% during first round, so I don't think there are any new test need to be added.
noProblem Yes, they coverage is 100%.
noProblem Yes the project was about testing and coverage has increased.
noProblem Nicely written wiki.
noProblem The coverall showed that the Overall coverage increased (+3.2%) toÂ 39.999% The coverage of the participant.rb file is 100%. So great job team! No suggestions.
noProblem The write up is simple and understandable. It starts off by describing about Expertiza, motivation behind the project, the tasks to do, list of classes that are modified and impacted by the change. I like how the authors have screenshots of both the existing code that is removed and the new code that is added in the pull request, which juxtaposes them and highlights the tasks in the problem statement and goals of the project. The write up then ends with the test plan which lists the test cases handled.
noProblem The code coverage was 100% in theÂ 1st round.
noProblem YEs the project was a test project and the team has managed to achieve 100% coverage of the model. There was no increase in coverage from Round 1 to Round 2
noProblem The project works as intended. Test cases are showing a positive impact on the results.
noProblem Yes, the tests cover all the scenarios one should check for. Great work !!!
noProblem Everything is good here!
noProblem Edge cases are tested, and all scenarios for each method are tested.
noProblem Yes a lot of cases concerning a participant has been added.
noProblem yes, 100% coverage has been achieved as shown in the video.
noProblem The tests specified in the participant.rb file run perfectly well . The same has been demonstrated in the video mentioned above. No suggestions.
noProblem The code coverage is 100%. Every test case passes after a manual check.
noProblem The writeup was significantly well written. Almost all the changes were covered.
noProblem The team has written their wiki page in a very detailed manner. They even added the video links which were missing in the first round as suggested. Thank you and good job :)
noProblem Easily one of the most clearly documented projects I have reviewed in this class so far. I liked their organization of the Test Plan within the write-up.
noProblem The wiki page provides clear details about the work, and very easy to understand. Just like round 1.
noProblem It is crisp and to the point, there are no clarity issues either.
noProblem Well explained, all the test cases have been explained and are self explanatory as well.
noProblem Well Written
noProblem The writeup is really well written and has covered all the desired aspects along with the test plan. No suggestions.
noProblem TheÂ writeup clearly defines the primary objective of the project and justifies the reasoning behind introduction of additional helper constructs like participant factory. The authors complement the descriptions of each test case with associated block of code and elaborate on the details of their inner workings.
noProblem The write-up and screen cast were both very explanatory. It included detailed code, the need for the test of partipant.rb and the use of the model. There was no change required from the initial write up.
noProblem The code is well organized and written & ready to be merged into the production server.
noProblem The tests are good and it can be merged to the main line.
noProblem Commits were made in second round
noProblem The code has been written as per the coding standard. The code written by the team adheres to dry principle.
noProblem the code was well written, following the principles.
noProblem Yes, code is well written
noProblem The code is well written and follows all the DRY problems.Â The team has changed the files based on previous reviews and to make it more DRY comments before the methods that they created gave a better understanding what each code does. // function for showing warning when number of slots is set as zero Â Changing the names that suited the functionality more, is appreciated.
noProblem There does not seem any issues with the code. The team has properly used the naming convention and has provided comments wherever necessary
noProblem Few new commits are made
noProblem There has been 2 commits made in second round. One for adding comments and another one for fixingÂ Issue #926 the sorting of topics by topic number in assignments.
noProblem 3 New commits
noProblem ProperlyÂ done in round 2 also
noProblem The team has done few commits. One was on few sort fixes, while they other was on refactoring.
noProblem The team has added some new commits which are about the added comments. The team has picked up the suggestion from the previous review to add comments for better readability, which is commendable.
noProblem A commit was done in second round addressing issues from reviews.
noProblem Yes the features work as described in the problem statement. The team has done good job and has fixed all the below issues: Issue #971 Change create topic UI into AJAX. Issue #9
noProblem The code works as required.
noProblem The new features work as expected.
noProblem The working is perfect, everything works as intended. The team has explained this in a brief manner in their youtube video.
noProblem System works as expected and this is evidenced by tests and videos.
noProblem The write-up is informative and provides all necessary details of the changes made.
noProblem The write up is impressive and very detailed. It has been documented well which helps to understand about the project and the code implementation. It also provides detailed test plan which makes it easier for end user to do UI testing.
noProblem The writeup is well organized and well documented.
noProblem Writeup is very detailed and well written. It is supplemented by enough code pieces and reasoning and good amount of pictures and videos to explain what the teamÂ has done in detail.
noProblem Yes, the code can be deployed to production.
noProblem The code is well written, tested and documented and hence I think it should be ready to be deployed.
noProblem Yes the Travis CI build is passing successfully.
noProblem No conflicts and Build Passes
noProblem Yes no conflicts at all which needs to be resolved
noProblem Yes, the Travis CI has passed.
noProblem The build has passed in Travis CI and no conflicts have occured.
noProblem The code follows Ruby style guide.
noProblem The code is very well written and follows good coding practice
noProblem Project was on implementing test cases. The test cases are well written and the code coverage has increased.
noProblem The code is both succinct and very carefully. i have not done the code check in the first round. but for this time, there's no bad names, functions are standardly-named, good alignment and commenting.
noProblem Code makes good use of rspec's describe and context options, and manages to achieve ~95% code coverage.
noProblem Yes code was committed to follow clean code practices based on first review.
noProblem Code was cleaned up 5 days ago.
noProblem Yes, new code was committed in the 2nd round.
noProblem Test coverage remains the same at 94%. Hence, my suggestion/opinion is same as the previous review.
noProblem Yes they have added test case and it has increased the coverage by 3% and has increased the coverage to 39.721%
noProblem Project was writing unit test cases and the newly written test cases has increased the test cases.
noProblem Test coverage for assignment_participant model increased to 94 percent.
noProblem Coverage increased by 3%.
noProblem Yes, the team has added test cases and the team has covered every functionality.
noProblem I'm afraid no test cases were added in round 2.
noProblem Yes the test case covers all the required test cases along with the edge cases .
noProblem Project was on writing test cases and the newly written test cases has increased the coverage.
noProblem Since it's unit test, it seems there's hardly a way to veirifyÂ with UI
noProblem All the test cases pass. Majority of test scenarios described in document is covered and automated
noProblem Video demonstrates working and passing tests.
noProblem The code coverage is ~94% which passes the required threshold.
noProblem The writeup seems to be well written. It is concise and to the point.
noProblem The write up is very well documented as it explains the test plans and also what changes have been made along with the reference to the files which have been modified
noProblem Very clearly writeup
noProblem The writeup is comprehensive and fully covers given functionality. There were no significant issues that needed to be fixed from the first round.
noProblem The writeup is complete and well organized. And it also mentions the corresponding change in origin code.
noProblem Yes as the testÂ case increase the test coverage and the build pass is 100% , thus the code is ready to be merged
noProblem Yes, it is a good code.
noProblem After resolving the issues with Travis tests and adding comments to the code, it is ready to be merged with Master branch. Production deployment in not applicable.
noProblem Travis Cl build failed
noProblem Yes, the Travis CI build was passed. The conflicts could be seen resolved.
noProblem Their code is pretty good, and they solved most of the problems.
noProblem Overall well written code. Use of factory bot reduces code redundancy in building test cases. The team could have reduced the code redundancy inthe menu method test example.
noProblem The topic assigned to this team is Unit testing on menu.rb. So, they had to create Rspec tests for the methods in the model file menu.rb in the new file spec/models/menu_spec.rb. The team has precisely tested the functionalities of every method including all relevant scenarios (as contexts) of both the nested class Node and the enclosing class Menu. The names used for mock objects and literals are intuitive and follow the Ruby's convention. There were a few issues regarding incorrect indentation and the verbosity of the spec code in the previous round. The team has rectified those in this round. In my view, giving additional comments for code in rspec is superfluous as the tests are already embedded with information on what it intends to do through the use of 'describe', 'context' and 'it' methods.Â The code is DRY through the use of reusable mock objects like menu, nodes, site controllers, content pages, controller actions, items and roles which span across the entire block wh
noProblem They do not have these problems in the first round.
noProblem The code follows the Ruby style guide and makes good use of the Better specs documentation for writing Rspec test. The team has also made an extensive use of the describe and construct contexts which helps to understand the code written.
noProblem The code is well written. No suggestions.
noProblem well done! 100% cover.
noProblem 2 Commit during 2nd round.
noProblem Yes, this team has been keeping push new commits during the 2nd round.
noProblem Yes, new commits were added in the second round to fix the code climate issue
noProblem There was a commit during the 2nd round. This was made after the user codeclimate pointed out a few issues with respect to the indentation and lengthy code.
noProblem Yes, the code climate issues were resolved.
noProblem There are some new commits in the 2nd round.
noProblem No new commits were found. But this was because the project was already done and did not need any changes.Â No suggestions.
noProblem modify some to make it drier.
noProblem This team already had full coverage. I am not sure how to answer this question as new tests were not needed.
noProblem Yes, the team did added test cases, which have been clearly mentioned in the write-up. Although the results image isn't clearly visible, but it is still enough to figure out the team passed 100% of the test cases.
noProblem Yes they have add some test cases, and the coverage increased.
noProblem The team's project is unit testing the menu.rb model file. Hence they added Rspec test code in spec/models/menu_spec.rb. The pull request indicates that the overall coverage increased by a significant 5.5%. The report tells cites that 5779 lines have been covered and 13673 lines are relevant.
noProblem no new added tests but the team had managed to get 100% test coverage in first round.
noProblem The travis report shows failing case implying no coverage there.
noProblem They add test cases for the first round and the coverage increases, however, they did not add more in second round.
noProblem The team did not add or improve any team cases from the first round. The full path coverage of 100% was already achieved in the first stage.
noProblem Coveralls shows the following : Overall coverage increased (+5.5%) toÂ 42.266% The coverage of menu.rb has increased to 100%. Great job team! No suggestions.
noProblem 100% coverage
noProblem As mentioned above, the team did a really good job at this. The writeup talks in detail what all tests did the team implement, and from the pull request, we can make out that the team was pretty consistent with their efforts.
noProblem Yes, it works as intended
noProblem The test cases have covered all the scenarios that I can think of including the cases when the objects passed as parameters are nil. For example there are scenarios covering the cases when the objects like controller_action attribute, site_controller variable, content_page, menu items, parent id are nil objects; and also scenarios when URL of controller action is unavailable, when the by_name hash does not contain a given node name and when a menu id is not present in the @selected hash.
noProblem Yes, everything works. Well done!
noProblem All scenarios mentioned in the writeup are properly covered.
noProblem They covered all the scenarios.
noProblem The code coverage of 100% satisfies the minimum criteria. It works as intended which can be seen in the video. The tests covers all the scenarios for passing them.
noProblem The tests execute perfectly well and this has been demonstrated by the video. No suggestions.
noProblem cover all!
noProblem Fantastic wiki! Extremely informative about your project.
noProblem There has not been any changes after first round in the writeup. So my opinion remains the same as it was in the previous review.
noProblem The writeupÂ overall is good, but they did change the problem related to test plan like I mentioned last time.
noProblem The writeup is complete and comprehensive in that it fully covers the given functionality. It clearly and adequately indicates the working functionality.
noProblem The writeup is written in a verbose manner. The test plan is also mentioned.Â No suggestions.
noProblem written up is also a brilliant work!
noProblem Yes, the code is perfectly fine, and is a great start for the team which would come in the future to follow-up with the work on this.
noProblem The team has created test cases for unit testing the model file menu.rb. The test cases are meaningful and are getting passed. Once the Capybara error quoted in the 3rd rubric gets fixed, the current code can be merged into the repository. Since the team's project is unit testing and does not concern modification or augmentation of any feature, there is no question of deployment to production server.
noProblem One check needs to pass to get deployed.
noProblem Once travis build passes the project could be merged. I have seen specs in the existing code base that are very implementation dependent so this won't be an issue.
noProblem I believe this code is ready to be merged once the Travis CI passed.
noProblem The build can be definitely deployed once the Travis CI issue has been fixed. Suggestion- Rectify the Travis CI issue.
noProblem meaningful test
noProblem Nice work!
noProblem All passed.
noProblem Yes, the build passes Travis CI. No, it did not had any conflicts. There was only one message, which was a warning, but apart from that, it everything seemed perfect.
noProblem Yes, they have passed the Travis CI.
noProblem very few conflicts
noProblem Yes,coding practices seem upto standards
noProblem The code is well written and well commented and follows ruby style guide.
noProblem They don't have code problem for the first round.
noProblem No the new code was not committed during the second round. This could be due to the fact that the team finished their code at the end of the first round itself.
noProblem Doesn't seem to have new commits in round 2. last commit was on 2nd November
noProblem The last commits were 12 days earlier, hence no new commits were made during the second round.
noProblem No new code was committed in the second round.
noProblem No new code was added, nor was any necessary.
noProblem Yes, they were made.
noProblem No new commits. Last commit was on Nov 2nd before the first review.
noProblem Yes 1 checkin was done on nov 2nd
noProblem The code was already delivered in the first round. Hence, no commits this round. The author has regularly pushed commits.
noProblem No new commit during second round.
noProblem Yes, the team did add test cases to test their changes and their overall test coverage has increased.
noProblem The code seems to same as before. nothing new has been added.
noProblem The team has added test cases and they cover all the required functionality. The code coverage has increased by a small amount.
noProblem Many test cases were added, with overall test coverage increasing for the project.
noProblem Overall coverage increased (+0.3%) toÂ 37.074% Good work on including test cases. The app works fine after testing. The newly added tests cover the scope of this project very well.
noProblem Team has added many tests. Coverage has increased from 1 to 38%, which is impressive.
noProblem The testing has been implemented and looks well implemented.
noProblem Yes, they add test cases, and the coverage is the same as the first round.
noProblem Yes everything does seem to work properly.
noProblem Yes, the project did work as intended. The video demonstration and manual testing were enough to prove this fact.
noProblem The system works well. All the functionality has been implemented. I ran the project and it worked as intended. The back button issue in UI has been fixed.
noProblem Yes, it works as intended.
noProblem yes
noProblem Yes, as mentioned in the problem statement, the solution is delivered. It works fine.
noProblem The functionality works and is evidenced by the video.
noProblem Yes, everything works.
noProblem The writeup written well. The team could have included snippets of their code instead of screenshots.
noProblem The write-up was very good, in the sense that it mentioned the high level view of the tasks first, and then dug deeper under the hood. But, it only showed what files they changed, and what it produced as a result. They could have also shown what is that they changed, or provided a link in the wiki. Yes, one can deduce that from the pull request too, but having a link or the content itself on the wiki is a big boon.
noProblem The writeup is well written and self explanatory.
noProblem The writeup is great, in first round they did not have a test plan part. But they added it in the second part.
noProblem No, its not as the coverage is increases by small amount.
noProblem The build did not pass in Travis CI. There were no conflicts that needed to be resolved.
noProblem Travis test has failed, I can see it in pull request page. Conflict has not been resolved.
noProblem New code commit was not made in second round
noProblem Code looks good. Well formatted and naming conventions are followed.
noProblem The code was well written and implemented the functionalities needed. It made good use of naming conventions and the team worked on improving the code layout by following the Ruby style guide and DRY principles.
noProblem All the names are used properly and the team adds some comments after last round.
noProblem No, no new committed were added during the second round. The last commit was around 13 days back, and no new code has been pushed since then.
noProblem Some New commits, improves the code a bit
noProblem Yes, 2 commits were done in the second round.
noProblem No new commits
noProblem There were a good number if commits in 2nd round.
noProblem Commits were done long ago and commits are regular. No new commits as changes were fixed in earlier round. Commit titles are well written and not ambiguous.
noProblem The team did not make any commits from their first round. They had successfully fixed the issues in the first round stage itself.
noProblem The team add some comments and test cases during the 2nd round.
noProblem Yes, the team has indeed added test case and made a test plan for both the issues that they have resolved.
noProblem 11% Coverage Increased. Good Job!
noProblem Yes, the team has added adequate test cases.
noProblem yes the coverage has increased
noProblem The team did not add any test cases and the coverage remained the same.
noProblem The team added test cases for test_case.rb and the coverage has increased. which makes the overall coverage increases relatively a large extent.
noProblem The feature implementation was good. The TA can't edit the rubric of the instructor. But the test cases are very limited.
noProblem Following the steps, I can see the changes implemented.
noProblem So far the best write up
noProblem The team vastly improved on the writeup from the first stage by giving a general overview of the tasks taken up and the list of issues present and resolved during the project.
noProblem The code seems ready for merge
noProblem Yes, it is ready.
noProblem If it works just like in the video then definitely yes.
noProblem Since, the changes are reflecting, it looks good to be merged.
noProblem Yes, the code can be deployed on the production server as it passes the needed build of Travis CI. The project would work as required to.
noProblem Travis-CI Passes
noProblem Yes, the build request has been passed.
noProblem I could not find Travis CI
noProblem Travis tests have passed. There were some initial failures but the team has fixed it. There are no lingering failures.
noProblem the build passes
noProblem The code is well commented, I did not see any bad naming conventions or bad coding style
noProblem I see only one commit on Nov 2nd.Â The project was in good working condition during the first review itself. and they did fix the minor bugs in the commit
noProblem Travis CI is passed there is no issues with the build
noProblem UI is working correctlyÂ there are no features broken
noProblem this code is ready for server
noProblem The code was already well-written . No changes were suggested in the first round. The team did a great work in following coding best practices.
noProblem The video explains the new functionality and the functionality is working as expected. Good job!
noProblem The write-up is well written and organised. Everything looks fine. Great work with the write up!
noProblem Code has no problem.
noProblem They did not provide a link for me to test, but their video shows that their code works well.
noProblem There doesn't seem to be any new code added in the github. But overall has a good history of commits which is documented well through commit messages.
noProblem The bug fixing does work according to the screenshots provided by the authors. They have provided a step by step screenshot of the issue that they have fixed. The authors haven't hosted their version of the expertiza so it is very difficult to actually check the functionality. They could have hosted expertiza on VCL or they could have put a screen cast of the working functionality to help in reviewing.
noProblem No new commits were added during the 2nd round.
noProblem The team did add test cases covering the functionality. The overall coverage increasedÂ by +6.6% to 43.356%.
noProblem Since, theÂ project was not deployed hence manual testing could not be performed. But, the screencasts show that the system works as intended.
noProblem Yes, I think the project is ready to be deployed at the production server since all the required functionalities are implemented.
noProblem The code is well written.Â The variable and method names look clean and concise. The functions are small and well defined
noProblem The write up clearly captures the functionality that the work is related to.
noProblem Yes, the code is written really well.
noProblem NO I don't find any conflicts in the work which needs to be resolved.
noProblem Yes, team has written test cases in a proper manner which increases the coverage also
noProblem Yes, It works perfectly fine. Also, the screencast they uploaded, makes it more easy and convenient for me to understand the portion of changes implemented.
noProblem Very well written and elaborated.
noProblem Yes, I believe this code is ready to be deployed as it seems perfeclty fin
noProblem The code follows DRY principles
noProblem there was no complicated functions , code strictly followed DRY principle
noProblem No Changes in the code from the last time. Code is written properly.
noProblem Code was well written, DRY, and intuitively done. Easy to follow the functionality implemented.
noProblem No new commits have been made in round 2.
noProblem All the commits were completed by Oct 31
noProblem No commits were done in 2nd round.
noProblem the last commit I see is from Oct 31st.I'm assuming they did not have toÂ change much in the 2nd round
noProblem No Commit,
noProblem A small amount of new code was committed in the second round.
noProblem No new commits were made during the second round.
noProblem No new commits have been made since the last round. However, there is nothing significant as just codeclimate fixes are remaining.
noProblem I couldn'tÂ any newÂ commits in the second submission, though the functionalityÂ seemed to be fulfilled in the first round itself.
noProblem Yes, the coverage has increased and has almost reached to 50%.
noProblem This project is refactoring and there were not much of functionality changes, I see that teams have changed the existing tests make sure there is no coverage miss
noProblem The test coverage seems to have increased slightly. Since this is a refactoring project, I wouldn't expect testing to be the focus, so that's pretty good even though the added test case most likely doesn't cover all the work done here.
noProblem The team had added a test case in the last round, which I think was sufficient to test basic functionality.Â There have been no additions to test cases in the second round.
noProblem Team added several test cases, and the coverage was seen to increase
noProblem Yes the code addresses all issues.
noProblem Yes, refactoringÂ did not impact on the existing operation at all.
noProblem The system operation works as intended.
noProblem Yes, this is a refactoring project and the UI works as it is supposed to, after their code changes. All the functionalities seem to be intact. Good job there!
noProblem The system operation works as intended from the link provided.
noProblem The team has explained the issue and the solution they chose with enoughÂ Â details to understand to way of implementation.
noProblem overall it is well written, they can add reference section where they can put the link to the project etc.
noProblem The write-up is to the point and explains their approach neatly. The team has made efforts to update the write-up with the provided suggestions and it has improved the write-up.
noProblem The writeup was elaborate, and fully elucidated the test added and the removed methods and SQL lines and their scope.
noProblem I strongly believe that this code is ready for production server
noProblem Changes are working perfectly.
noProblem I think this code is ready to go, because it is better organized and structured than it used to be.
noProblem I think that it is a neatly written code and once the integration issues have been resolved, it should be ready to be deployed on th production server.Â The code being readable, can be easily picked up by the future team.
noProblem build is passing on Travis CI. there are no pending conflicts
noProblem Ignoring this question since it is an OSS project.
noProblem Though there were several build fails during the first round which seem to have been triggeredÂ on bundle exec, the final build passes in Travis CI
noProblem Could not see any commits after the last submission as functionalities were working fine, but team could have worked upon improving test coverage.
noProblem No, no new code was committed during 2nd round.
noProblem No Commits
noProblem No new code was committed during the 2nd round.
noProblem Team s last commit was on Oct 31st , which was the first deadline.
noProblem Good Job on the test cases.
noProblem Yes, test cases were written for admin_controller and roles_controller. The test cases increased the coverage as well. Every method in these files are tested and covers a good range of this project.
noProblem When open from the UI, working fine and as expected. No refactoring required.
noProblem Yes, the system operation works well. All the functionalities mentioned work properly.
noProblem Yes, the system works fine and as intended. The features work as they are supposed to.
noProblem They had to create a superuser who has a right to delete other users . When checked these functionalities were working upto 80% expectation. The tests written do cover the portion assigned to them and the tests are thorough.
noProblem The write-up is well organized but it would have been better if some screenshots were uploaded along with the steps. That would have made the document easier to understand.
noProblem The writeup is short and precise - has everything that is needed for testing and understanding and kept the writeup small for better understanding. They have mentioned about their DRY principle within "Changes" itself. Mentioning it as a separate sub topic will give more visibility is what I felt. Other than that everything is self explanatory.
noProblem The writeup is well written. It covers almost all the work done. However, one suggestion would be to include more details about hoe the tests were done. I just one small portion dedicated to explanation of RSpec and not the work implemented.
noProblem No it should go through more edge cases testing
noProblem As mentioned above, the functionalities work well. So, yeah this can deployed on the production server.
noProblem After fixing the issues suggested by code climate, the code can be deployed.
noProblem Pull request build passed well and there are no issues.
noProblem The pull request has passed the Travis CI
noProblem Yes , it can be deployed and is a good starting point for teams in the future.
noProblem I think the code can be merged. All the test cases seem to cover the edge cases and my testing shows that the things function as expected.
noProblem Yes it is ready to be deployed.
noProblem Travis CI says tests have failed but these don't include the tests written by the team.
noProblem The Travis CI build passed , the code does not have any conflicts with the master. Initially (stage 1) a lot of changes were made so that the Travis CI build would pass. Kudos for effort!
noProblem The code has passed the Travis CI build has passed. The danger build has also passed with one warning because of more that 500 Lines of Code. On the other hand the codeclimate build has failed with 7 issues to fix.Â 1. There is a method get_feedback_assessments_for which has a Cognitive Complexity of 9 (which exceeds 5) and must be refactored. 2. The model class Team contains 21 methods (which is more than the 20 allowed) and hence has to be refactored. 3. The method view_heatgrid has 28 Lines of code that exceeds the allowed 20 and hence has to be refactored. 4. The method set_content has a Cognitive Complexity of 6 (which exceeds the allowed 5) and hence has to be refactored 5. Presence of an unescaped model attribute in the file app/views/response/view.html.erb 6. Assignment Branch condition size for get_feedback_assessments_for is too high 7. Indentation issues in app/models/assignment_participant.rb There are no conflicts with the ba
noProblem The build has passed and there have not been any conflicts.
noProblem The CI build has passed and there are no conflicts.
noProblem A lot of outdated approaches were used. Refactoring was needed.
noProblem The code was written pretty well.
noProblem No commits needed after first review.
noProblem No new commits. No new bug fixed.
noProblem The last commit was 12 days ago. I believe that this team had finished their work well before round 1 itself. I think they had planned the work well in advance and followed that plan as well.
noProblem There were really few commits in the 2nd round. The only commit I could see was on 30th October. The only suggestion I would give is to continuously update their work on git.
noProblem There is no new commit during the 2nd round.
noProblem No new test cases added, but the existing ones had a good coverage too.
noProblem Overall test coverageÂ was decreased by 35%.
noProblem No need for adding new test cases as the previous submission already achieved 100% coverage. I apologize for not being certain how to accurately answer this question.
noProblem They didn't add test cases, but the test coverage is always above 90%.
noProblem There are no new tests and that is because the team had already completed their work before deadline 1 and the coverage was 100% on the deadline one itself so there is basically no scope for improvement for this team.
noProblem The team did add test cases. They achieved a little more than the desired coverage even , that means they have done a great work.
noProblem The team added test cases for menu.rb and the coverage increases but the overall coverage seems decrease due to that.
noProblem From the video, the functionality works well.
noProblem N/A. This is a unit test project.
noProblem Yes, the tests cover all the scenarios.
noProblem The tests cover most of the scenarios as is evident from their mutant killing capabilities.
noProblem The team was asked to write test cases and get a coverage of around 90%. The team did a really good job in writing test cases for all the methods present in the assigned files.
noProblem The project has a good coverage of the codes
noProblem The writeup is well documented
noProblem The write up is very informative and clearly shows the impact and result of the project tests. It would have been a great addition to have included more discussion on the design choices of your testcases and how it was implemented. Overall a great wiki.
noProblem The writeup is pretty good and easy to follow.
noProblem I loved the write-up. Write from the beginning to explaining Expertiza to explaining their task and the test plan which was very detailed and methodical. I also like that they had included a screen shot of the Mutant test which shows the thoroughness of their tests. Overall an impressive job by the authors.
noProblem The writeup is well written and clearly tells the flow and method of working. It shows clearly what all work is done and how it is done. It mentions specifically the explanation of each functionality and how it is checked.
noProblem The writeup gives an easy-understanding introduction of the two classes the team needed to test. Also, there is detailed test plan is provided. The wiki also shows how the test cases are designed and the results. However, for the motivation part, it is a little bit general, which needs to add more things specific for this project.
noProblem a Lot of refactoring is required before the code goes on to production server.
noProblem The team gives a good guidelines for how to test and what to test for the two classes.
noProblem Travis CI failed.
noProblem The travis CI build failed.
noProblem The code is extremly well-written.
noProblem Videos and code explained very well.
noProblem Yes some of the issues were fixed.
noProblem The code was written clearly, DRY, and intuitive to follow the intended functionality.
noProblem Yes rspecÂ and few changes were committed
noProblem Yes, a lot of commits were made mostly to fix the issues pointed out by the CI tools
noProblem Yes, there were many parts of the code committed during round 2.
noProblem 5 new commits were made during second round
noProblem The team has a really good job of committing their code on a regular basis. There has been some code commits even in the 2nd round.
noProblem Yes, there were few new commits
noProblem Yes, the team actively committed to the project during the second round.
noProblem The team seems to have thoroughly tested the use case and the coverage has increased.
noProblem Yes, the team has added test cases and it covers all the functionalities and issues.
noProblem Video showing test cases passed. Good Job!
noProblem YEs, the team has included the relevant test cases to test their changes and the overall coverage has increased by 0.04% which I think covers the scope of this project.
noProblem Coverage increased by 0.04%
noProblem Yes the team did add test cases that increased coverage. They are appropriate for the scope of the project.
noProblem My testing shows things seem to be working as expected and documented.
noProblem The deployment link hasn't been provided. Though they have put videos for the same
noProblem It works as intended.
noProblem Yes code works.
noProblem From the video links that have been shared, it is very clear that the features are working as they were supposed to. Even the test cases are passing. I see no issues with this part.
noProblem Looking from videos all the intended features work
noProblem Yes the code works has expected. it accepts the utf-8 codes now and also parses HTML tags in reviews like expected
noProblem The write-up is well written explaining all the steps undertaken to make desired changes and displaying how the system works afterÂ the changes have been made (with screenshots). They have also added Test plans in the wiki page
noProblem Pretty nicely written Wiki. Test Plan also describes how various tests were performed.
noProblem Yes the write up is good, if they were able to host it'd have been better for checking the work.
noProblem The write up is well written, elaborate, and clearly elucidates both the manual test cases considered as well as the automated tests implemented. Screenshots of both cases were also included as well. Steps for manual testing were clearly written.
noProblem The team has considerably improved the write-up. The write-up was very inefficient and dint provide details of the code-base also the video was encoded and impossible to view in Round 1. The team has rectified all these issues with round 2. they have documented their fixed more clearly with screen shots and code this time.
noProblem It can be deployed but first, it should be tested thoroughly.
noProblem I think the changes are tested nicely and seem to cover all the necessary cases. This can be merged into the master branch and is ready for production use
noProblem Its ready to be merged.
noProblem In my opinion, this team has done pretty good work and the code looks like ready to be deployed on the production server.
noProblem Yes, just fix the few issues present and that should be fine for it to be merged into main line as the feature seems to work and there isn't any major code issue.
noProblem Pull request build passes well and there are issues.
noProblem The build has successfully passed the Travis CI test and there are no merge conflicts present in the pull request. However, there were a few code climate issues which I think can be easily fixed.
noProblem The travis ci test passes.
noProblem The build passed in Travis CI with no conflicts.
noProblem Code is short, variables and functions are well-named.
noProblem the code is very well written. there are no bad names, long functions or any lack of comments. The code written by the team is self-explanatory.
noProblem The variables, methods and class names are aptly named. I could not find names which are not suggestive of functionality. (i) The writeup is well written and easy to read and well commented (ii) It is adequately descriptive of the work done. (iii) Explanation of reasons for the style of code and problem solving approach is lacking.
noProblem The code is concise and easy to understand. The team has provided comments to explain the logic of the new function created which really helps.
noProblem The code was well-written in the first round itself and followed good coding standards.
noProblem A few bug fixes were made after the first round of submissions
noProblem There were only 2 commits made during the second round. However, the team had mostly implemented most of the functionality during the first round, maybe due to which there are less commits in the second round
noProblem The Ui and system operations works well as intended. They newly added features works perfectly as they are supposed to do.
noProblem Everything works as expected except for the case mentioned above.
noProblem Some of the functionalities have been implemented but the pull request is yet to be merged with the master branch
noProblem No credential provided for login. Hence, couldn't check.
noProblem The write-up clearly mentions how to check/test the work done by the team. it includes almost everything the team has changed during their project.Â It clearly mentions the filenames where the changes have been made. All the references are also included in the write-up
noProblem The team has provided an excellent write-up with proper explanation of the problem statement and the solutions they have provided. The team has also includedÂ a video which make things really easy to understand. The team has shown navigation structure of the expertiza menu, which makes the workflow clear.
noProblem very nice code, easy to read and understand.
noProblem The code written by the team satisfies the basic functionality expected. The team followed the comments from previous round of using good naming conventions for certain variables.
noProblem yes, new code committed during the 2nd round.
noProblem Yes new commit is done for second review,
noProblem Yes, the team covered 100% of the code they had to test. Also, the video given in the link was very informative and helped to understand the implications of the work done by the team to a far greater extent.
noProblem The coverage is 100% since the first round. It seems there's no newly added tests.
noProblem 100 percent coverage.
noProblem They reached 100% at first round.
noProblem Yes, the team covered all the scenarios I could have come up with. I specially appreciate the work that they've put into the import functionality. They have come with with more scenarios than I couldÂ have even thought of, and tested it pretty thoroughly.
noProblem The project successfully covered all the scenarios.
noProblem nil test were added, all scenarios are covered.
noProblem very nice writeup.
noProblem The write-up is well written in my thought, it is clear and understandable.
noProblem The team has presented a working deployment to be possible. It passes most of the builds and can be deployed on the production server.
noProblem Yes, the Travis CI is passed. No conflict that are remain do be resolved.
noProblem the build passed in Travis CI.
noProblem Travis build : passed.
noProblem The code looks good with the standards followed. The changes are explained in the wiki for the same. Also, the video has been uploaded but doesnt seem to have the audio with it.
noProblem The code is perfect right now.
noProblem Yes, through their commit record, I have seen some improvement.
noProblem Yes, they have improved after the last review
noProblem I dont seem many commits for round 2, but yes the video has been added for explanation. Also, the wiki is pretty well explained with the code.
noProblem Yes, there's new commits.
noProblem yes, new code committed during the second round.
noProblem Yes, according to the commit record, they have commit new code during the 2nd round.
noProblem The second commit is perfect. it got perfect coverage. But it seems that the 100% coverage was so since the first round. But the new commitedÂ code as better code style and no more indentation issue
noProblem Yes, they have added some test cases, and coverage increased.
noProblem 100 % coverage achieved. Great work!
noProblem The team did a great job inÂ increasing the test coverage to 100%.
noProblem This is a testing project. The tests have covered all the scenarios possible.
noProblem great writeup.
noProblem The document is well written with all the required details.
noProblem Yes, for production code itself is perfect.
noProblem As explained in the video, the build seems to work fine.
noProblem Yes, it passed all the pull requests.
noProblem The build successfully passes Travis CI.
noProblem The commits show equal contribution by all team members.
noProblem Well written with understandable content
noProblem The code was very well-written and up to to servo standards.
noProblem This code seems to be well structured and written
noProblem Yes, It was committed and the changes were merged
noProblem Yes new code was added and committed during the 2nd round that implements oscillator node example to exercise different oscillator types and generate triangle waveform.
noProblem Yes, new commits were made during the second round.
noProblem I don't see any tests in this project.
noProblem The team's test plan includes running the oscillator binary file using the command ./oscillator. This will run the oscillator.rs where various oscillator nodes corresponding to sine, square, sawtooth and triangle waveforms are generated. Hence, the user will be able to listen to these waves after a definite interval.
noProblem It's working.
noProblem I'm not really sure how to categorize this project, but it seems to be structured and implemented properly.
noProblem The writeup was really well explained.
noProblem Writeup is good and understandable. Test plan is written well indicating the steps clearly in what needs to be done to test.
noProblem Well-written and self explanatory.
noProblem The writeup starts off by introducing Servo- Mozilla's experimental high performance browser engine and Rust- which is a systems programming language with memory safety and concurrency used to build Servo. It then moves over to Web Audio API for handling audio operations inside audio context and allow modular routing, and a workflow for implementing Web Audio was clearly listed. It then flows into the scope of the project and the implementation. The graphical and mathematical representation of the sine, square, sawtooth and triangle waveform gave a solid conceptual foundation. The code snippet of the changes done in oscillator_node.rs and the new file oscillator.rs (created by the team) has also been included. The section Build that explains the procedure to install dependencies (Rust), step by step procedure for building and running the build was very useful to explore the project. The team had included the build instructions for Windows and Debian-based Linux. They could have augmented the build instruct
noProblem The writeup is very detailed and gave me a good idea of what was going on with this project.
noProblem It is already deployed on the production server
noProblem The project is in great shape and has already been merged to the servo repository on Github which means that it is production ready. The team has fixed the few formatting issues pointed by a servo team member.Â The approach taken up by the team is in line with what is expected of them and it is a good start to advance the Webaudio API of the servo browser engine in the future.
noProblem I believe this code is ready to be deployed, and if it isn't, it can definitely be picked up in the future.
noProblem The project follows most of the DRY principles
noProblem Yes the code has been well written and very ruby like. The usage of existing gems is good. Functions have were good. I did not find many issues with the first review. So authors have kept it the same. very well done. Â I wanted few more comment in code but thats okay.
noProblem This is not an expertiza project, but the pull request does pass.
noProblem Not an expertiza project.
noProblem Properly explained write up, with old and new changes.
noProblem The writeup I must say has been one of the best I have seenÂ so far. It clearly mentions all the issues that they were facing and were asked to tackle. The solutions are well documented as well. The screenshots help in understanding the problems that they fixed.
noProblem test cases were added to increase the coverage.
noProblem The team has added test cases and the coverage has increased marginally for most files. However, the coverage reduced for one file which might be because a particular corner case was not tested.
noProblem Coverage is present, slightly increases the overall project coverage.
noProblem no new commits.
noProblem The team has not made any new commits in round 2 because they did the code implementation in round 1.
noProblem The last commit was made on Oct 31
noProblem No new code was necessary.
noProblem No new commits in 2nd phase
noProblem No new commits during the second round.
noProblem Yes everything does seem to work properly. Since this was a refactoring project every feature worked as it was supposed to.
noProblem This project is based on emails which cannot be tested in test environment.
noProblem Features work as expected.
noProblem The team has implemented most of the required functionalities
noProblem The features work as they are supposed to, only problem is with the code using excessive if-else like structure. Code is brittle in this sense. Could have made functions and passed parameters to make it more flexible.
noProblem Functionality seems correct.
noProblem The refactored mailer with the use of Sidekiq works as intended.
noProblem The write up addresses details of all the three problem statements along with the code changes done in every file and the files added. The team has also added screenshots of the manual testing.
noProblem The writeupÂ is comprehensive and includes code that was added so it is easy to understand.
noProblem The test section has been improved with more detail.
noProblem authors have added a new doc in addition to wiki. i think that is not required, they could have simply added that in the wiki.Â as in review 1 would have liked a. link to the issue in problem statementÂ 2.Â more details in why this sidekiq was used and not other message queue
noProblem Write up is elaborate, and elucidates the test cases and tests well.
noProblem code can be deployed on production server as necessary test cases and implementation has been carried out succesfully.
noProblem I think we cannot add it to production because i feelÂ authorization for the newly added pages is required.Â once that is done it should be okay to add the code after further testing
noProblem build did not pass in travis ci.
noProblem The build has passed and has no conflicts with the base branch.
noProblem Some of the tests passed but there are still some unresolved build errors on Travis CI. There are pending issues which need to be rectified
noProblem Travis CI runs smoothly and no errors occurred. No conflicts occurred.
noProblem Everything checks out.
noProblem The code was well written and looks dry. However, a few comments could be added to make the code more understandable.
noProblem The code was committed frequently during the second round.
noProblem The code is ready to be deployed onto the production server and in fact,Â the project was even partially merged.
noProblem The write-up is good and it clearly explains what each portion of the changedÂ code is intended for.
noProblem The project is about improving email notifications.Â Yes, it works as intended. Screenshots of the code and changes made have been clearly described. The tests cover all the scenarios.
noProblem The write-up is very detailed as to what features have been implemented but lacks on explaining how they are implemented. It can be improved by adding how the features have been implemented, why they chose this logic to implement the features.
noProblem NoÂ this code is not ready to be deployed onto the production server. Minor bugs said by the Travis CI can be fixed. Also, Add test cases and after thorough testing, it should be good to be deployed andÂ hence this will be a good starting place for a future team to pick up.
noProblem Yes lot of code has been checked in most oct 31. Good work
noProblem The code is well modularized and appropriate names are used for methods.
noProblem yes new commits were added during the second round.
noProblem I still see some lint issues and commented-out code. The code looked fairly DRY and compliant with standard Ruby style and looks that way still.
noProblem Writeup is decent. I felt that code should have been quoted rather than included pictures of as that would make it easier to modify. The pngs weren't same size which appears to be negative that peopleÂ have commented on my work too.
noProblem Spec needs to be fixed before merge.
noProblem The code is well written. I did not see any bad naming conventions or bad coding style.
noProblem No need for test cases. (+1 for mentioning it in the Wiki!)
noProblem Not required
noProblem Test cases were not required for this project.
noProblem The test cases were required as the chnages were related to UI. The team mentioned the same in the wiki.
noProblem yes, the ui operations works as intended.the features fixed now works as intended.
noProblem Since the project was deployed hence manual testing could not be done but the screenshots show that the project works as intended.
noProblem The feature works as per the video shown.
noProblem Fro video it seems to work as intended.
noProblem the video explains the new functionality and the functionality is working as expected. Good job!
noProblem Yes, it works as expected.
noProblem Writeup has been improved after the first review. The codes now look more comprehensive.
noProblem The write was good and well-written. However, it would have been better if some screenshots were also present in the writeup. May be juxtaposing the screenshots of 'before and after' of fixing the issues. That would have made the write-up easier to understand.
noProblem The deployed link application again goes to video only, if deployment isn't done they could've removed the link.
noProblem In my opinion, the project is ready to be deployed and does not need to adopt a different approach.
noProblem The deployed application was not available, so it cannot be accurately predicted if the code functions as intended. However the vedioÂ links in the google drive show that the issues have been resolved through existing code.
noProblem The code is very well written and comments are properly given. Also the variables are descriptive and ruby guidelines are followed.
noProblem First review comment weren't addressed.
noProblem new code was comitted.
noProblem Few commits can be seen during 2nd phase. Mostly are for test plans.
noProblem No. The last commit was on oct 21st.
noProblem The team added many tests. They seem like they would have high coverage, but, with the failing build, this cannot be confirmed easily.
noProblem sufficient test cases added.
noProblem Not able to get coverage from the log: https://coveralls.io/jobs/41685719
noProblem ui works as intended.
noProblem The features work as intended and the emails are sent to the concerned party.
noProblem it is good starting place for future team to pickup.
noProblem No new test cases were added from the previous submit. Test cases already had full coverage so there was no need for additional testing. I was unsure how to answer this question as the rubric says any new test cases added.
noProblem All code is good, a variable name was even improved during the second round.
noProblem A small change was made, but there wasn't a need for drastic additions.
noProblem All necessary code is passing the build.
noProblem The video makes it clear that the tests work and are covering all aspects necessary.
noProblem The write up is still good.
noProblem The code is quite good.
noProblem The coverage was already at 100%, but they did update it to pass the build.
noProblem Yes. Variable name changes suggestion was incorporated.
noProblem Travis tests have failed. No conflicts. The overall test coverage has improved.
noProblem It is a testing project. The overall test coverage has improved. The tests thoroughly test the menu-bar and the sub-tress of menu bar(sub-menu options) as per the requirements.
noProblem No UI or functional changes are applicable. All the 29 tests run successfully
noProblem It is very well documented. No changes were required even during the first review.
noProblem It improves the test coverage, So once the Travis tests pass, It is ready to be merged with the Master branch. However no production deployment is applicable for test coverage improvement.
noProblem nicely writtenÂ test cases
noProblem Did not pass Travis CI
noProblem Not deployed
noProblem There is one new commit in round 2.
noProblem Yes the coverage is 100% already.
noProblem The code written follows the ruby on rails best practices.
noProblem Yes, the team has made one commit during the second round. They updated an ambiguous variable name.
noProblem No, the pull request didn't pass the TravisÂ CI build, but it doesn't have any conflicts with the base branch.
noProblem Yes, the team has added plenty of tests. The test coverage increased toÂ 100% whereas the overall coverage has increased by 11.4%
noProblem Yes, the test covers all the scenarios, including testing values of variablesÂ in the menu node and null case scenarios.
noProblem The team has corrected a single bad name used in the tests. There has been no change done to DRY the code yet. there test as mentioned earlier has few segments repeated throughout each test. For ex, the instantiation of Menu object. There has been no comments added for the code yet.
noProblem Yes, there has been one commit in round 2, rectifying the bad name used
noProblem The code is well written, the way the list function was split into multiple modular functions is appreciable. A great amount of effort has gone into fixing the issues.
noProblem New code added is written well with DRY and no long or complicated functions. I could see file updated has changes on line such as tab and space. Team could work upon indentation.
noProblem The code is well written. No issues with naming conventions or coding style.
noProblem overall only 3 commits are made during the entire project. no new code was committed during the second round
noProblem The last commit is on 10/31.
noProblem No New commits.
noProblem Could not see any new commits after last change. Also commits distribution is not equal.
noProblem No changes were committed in round 2.
noProblem No new test cases are written.
noProblem Test Plan could be described better.
noProblem Team could have added test plan in wiki along with test covered and test description. Also could have worked upon increasing test coverage.
noProblem Test are written
noProblem The team has added testcases but lacks coverage. The overall coverage decreased by 10.6% to 37.063%.
noProblem No test cases are added by the team and overall coverage of the project is decreased by 10.6%.
noProblem The operations work as intended but need to have automated test cases.
noProblem I could not get a deployment link or watch a video that demonstrates the work done. So, I'm unable to test.
noProblem I could neither test it manually nor there were any videos to check the functionality.
noProblem Write-up is explained pretty well.
noProblem I think the code need some amount of refactoring before it can be merged with the expertiza master and pushed to production. Some of the functions implemented by the team seem quite long and they should try and restrict the functionality implemented in each function to just one.
noProblem The code seems very well written and approach seems correct. If they improve the documentation and add test cases after thorough testing, it should be good to be deployed. As it stands, another team in future can pickup the code and implement these improvements.
noProblem Yes, the code has been written aptly and to the point. The intention is clear.
noProblem The Travis CI build has failed.
noProblem Pull request is not passed as well as Travis CI is also failed.
noProblem Travis CI build is failing. Other things are fine.
noProblem The code added during this project adheres DRY principles.
noProblem The code was written at it's best
noProblem Yes, the code is well written.
noProblem The team has followed rails best practices while writing the code.
noProblem All coding principles are followed. //Add more comments.
noProblem No new changes were committed during the second round.
noProblem No. They were no commits during round 2.
noProblem Yes, there are few commits after round 1
noProblem No, the team hasn't committedÂ any changes during the second round. The last commit was on 31st October 2018.
noProblem No there were no commits made after Oct 31st.
noProblem The team did add test cases covering the functionality. The overall coverage increased by 0.004%Â to 47.652%.
noProblem Yes, they did add the test cases and the coverage increased to 80%
noProblem coverage is same
noProblem Yes, it increases the coverage too
noProblem Changes are covered with new test cases.
noProblem I followed the steps as mentioned in the wiki and it works as expected.
noProblem Yes Everything works perfectly fine.
noProblem Works properly
noProblem Yes, the UI changes according to the specified conditions. After logging in asÂ aÂ student, we can see the team name being displayed at the top of the page.
noProblem Everything looks fine to me.
noProblem The writeup is great. I was able to understand the issue and do manual testing.
noProblem It was very well-written and self explanatory.
noProblem The wiki page has been written concisely. The team has used screenshots which ease the understanding of the work they've done.
noProblem The write-up clearly explains the issues faced and the code fixes used to solve them.
noProblem Comprehensive.
noProblem Yes, the code changes are simple and to the point. I don't see any other way it could be done.
noProblem The user name issue seems to not have been resolved when tested manually. The code may be deployable and would not cause a problem since there are not many complicated changes.
noProblem Yes, the changes have passed all theÂ checks and can be deployed in production.
noProblem ExcellentÂ work
noProblem In good state.
noProblem Yes, the build passes Travis CI
noProblem The travis builds on both pull request have passed.
noProblem No. The test failed.
noProblem There are no conflicts
noProblem Yes, the pull request has passed the Travis CI build test and does not contain any conflict with the base branch.
noProblem Yes, the Travis build is passing.
noProblem The code is well written and understandable.
noProblem The code is well written and has proper functions to handle each action. Not too long functions and names are aptly defined
noProblem The code seemed to be well-written and properly commented. Comments made it very easy to understand the code.
noProblem Overall the code is written really well. Snake casing has been thoroughly followed and in case of JavaScript, the camel casing is followed.Â No additional suggestions.
noProblem Yes, code has been committed in round 2.
noProblem Last commit was on Nov 6
noProblem Few commits made in 2nd round
noProblem No link provided but the videos shows that everything is working well.
noProblem 2 Issues are resolved and when checked from UI,Â featuresÂ are working as expected. Seems like no code refactoring is required.
noProblem Manual testing could not be performed due to lack of project deployment. But, the screencasts show that everything works fine.
noProblem The UI seems to work as it should, at least from the writeup.
noProblem The writeup is great and descriptive. I could find all the info I needed.
noProblem The writeup is very explanatory with all the screenshots attached which helps in better understanding
noProblem The write up is well written and explain the features that the team has implemented in a verbose manner.Â The writeup mentions solution description which gives a walk through about what steps were taken to implement the functionality.Â No suggestions.
noProblem The team has definitely resolved one issue. This could be a starting point for future teams.
noProblem Yes, the code is written aptly and to the point. I don't see any issues.
noProblem Yes just a few test plans needed and the code can be deployed on production server.
noProblem This code can be deployed after solving the issues generated by Travis CI.
noProblem The approach seems to be correct and the writeup ready to be deployed.
noProblem This is a code and project that has been honed into perfection. The team has shown due diligence and taken care of long and complicated functions and somewhat shaky coding style from the last submission. They have refactored the code to perfection thus fulfilling all their objectives.
noProblem The code follows the general guidelines for standard RSpec practices and also keeps the DRY principle in check. It makes a good use of names to specify what each attribute is assigned for.
noProblem No new commits were committed for the second round. It was cleaned up 13 days ago.
noProblem No new commits were made during the second round. The latest commit was on OctoberÂ 31st.
noProblem There wasÂ a substantial amount of commits done in the firstÂ phase of the project but I don't see any commits in the second phase. This could very possibly be because the team might have completed the requirement in the first phase itself.
noProblem Yes, an excellent job in that regard. They have first explained their test plans, then even provided links to their RSPEC tests which I checked. Then they have run and shown their screenshots of the Rspec tests going through successfully.
noProblem According to the screenshots uploaded by the authors, the features work as they are supposed to. New questionnairesÂ have been successfully created.
noProblem Yes, the code has been refactored to cover all the intended scenarios and the tests have been very well document along with testing the edge cases. As per their approach the first segregatedÂ the tests for questionnaires_controller into two test files, questionnaires_controller_spec and quiz_questionnaires_controller_spec and separated the tests for CRUD operations of quiz_questionnaires_controller into the quiz_questionnaires_controller_spec, renaming them from view_quiz, create_quiz and the like to view and create.Â This in my opinion is a thoroughÂ enoughÂ test.
noProblem The system works as intended. The project required to make the features work such as removing hardcoded parameters as save_choice method, replacing switch statements with subclass methods and creating models for the subclasses.
noProblem Extremely well written Wiki Page, thorough and to the point with enough technical content and relevant screenshots pertaining to the before and after scenarios of the problem statements.
noProblem The writeup gives a gist of the work carried out by team throughout the project. The team added the Test Plan section describing the testing procedures carried out. It is also structured nicely allowing the reader to understand the project in it's entirety.
noProblem Surely, once the code is sufficiently tested by the TAs, then it is can surely be implemented as a change. Even so, the Travis CI and the overall Coverage should be verified first. Going by their page, it is a finished project and hence no use giving it to the next semester as a project.
noProblem The code has been working fine, and once the integration conflict is solved, seems ready to be deployed. The future team will be able to pick up from where the current team has left.
noProblem There is significant improvement in the write up after the first round. It gives good idea of the project.
noProblem The code changes seem to be fine. I do not see any problems regarding the code as it is pretty well explained in the wiki as well.
noProblem Overall, the code was well written. As mentioned earlier, the only change the team had to make was add color codes. Hence, no mistake was made in the first round itself. Good Job.
noProblem Everything seems good.
noProblem CSS snippets are still written inline. No changes were made after round 1
noProblem Code looks good, there weren't many changes and mostly are HTML changes so no commenting is required as such as well.
noProblem The code was very well written. However, that should be a given considering the complexity of the project which wasn't a whole lot.
noProblem Code is still using DRY principles
noProblem No new commits were made during round 2.
noProblem The last commit was made 9 days ago as per the given link. There were not many changes required, so seems fine.
noProblem I can not see any new commits in second submission as the functionality was working properly in first submission itself.
noProblem New commits were not added in the 2nd round. In my opinion they were not required as well as the team completed their task in the first round itself.
noProblem No new content was necessary during the second round.
noProblem No there were no new commits due to the fact that were no changes to be made
noProblem No new Commits
noProblem No test cases were added. No real scope for the test cases to be added to test changes made to HTML code.
noProblem The test cases are added with good explanation. It does increase the code coverage. The thing I liked that the screenshots itself speak for the test cases.
noProblem As mentioned in wiki page by team, color change does not affect button functionality, hence no test plan is required. Hence giving full points here.
noProblem Um, somehow your commits increase the overall coverage of the project (and as mentioned in the write-up, test cases aren't possible).
noProblem It's UI project, testing isn't required as such. They have still mentioned in there documentation.
noProblem There are no test cases as it is an UI specific project
noProblem No tests were added as part of the project. just minimal UI changes
noProblem Documentation is well-written, instructions is given. Problem statement and solutions are provided. Screenshots are given.
noProblem Yes, new commits were done in the 2nd round.
noProblem There are minor fixes related to code style.
noProblem The team makes several commits during the 2nd round to make improvement.
noProblem Yes the team added test cases and the overall test coverage has increased.The team has added a lot of tests and I do feel it does cover the range of this project.
noProblem It is a testing project so test cases are added. The coverage has increased to 97.5 percent for Vm-Question Response Model.
noProblem Yes, the coverage has increased and test cases have been added. Coverage is more than 50%.
noProblem Coverage has increased from 11 to 97%. It is impressive. Great Job! The team has achieved what they were looking for.
noProblem The team added new test cases and make the coverage increase also the overall coverage for the whole system has increased
noProblem There wasn't any link provided to check if the UI was working fine. But there was a YouTube video showing the tests successfully running. And also the tests did seem to cover almost all the scenarios.
noProblem Yes almost all scenarios for vm_question_response model is covered. Good work.
noProblem This testing project covers all the scenario as required.
noProblem Since these are unit tests, no UI test needed.
noProblem The write-up explains what functionality is tested and why. The coverage is also mentioned along with code snippets which is good.
noProblem Writeup is well written and gives explanation for all the requirements.
noProblem Code is written very well, comments are detailed and functions and variables are named appropriately. (would just like to point out, in student_task_helper.rb#due_date_color , the variable "rtn" could've been named better!)
noProblem the team has implemented there testing plan and have been very thorough with there test cases. They seem to have considered a lot of cases and have implemented them in rspec. The only thing that they should do is use different commits for adding test cases.
noProblem Yes, it works as intended. It would be better if you could add a video recording of the flow/screenshots of the flow in the test plan.
noProblem The code follows the DRY principles correctly
noProblem Yes, improved the code.
noProblem yes,Â 2 commits were made in round 2.
noProblem Yes, new commits were done.
noProblem Yes. Twice during the second round.
noProblem yes, the team had added 2 test cases and the coverage increase is there as well. Newly added tests are enough to cover the range of project.
noProblem This feature doesn't say the view is of which student. Looking atÂ student_task/list page is confusing since I don't know who am I (which student).
noProblem Coverage has increased.
noProblem Coverage increased by a good margin
noProblem No new test cases are written. From the previous review,Â The authors have converted all the cases discussed inÂ Test PlanÂ into automated tests. Overall coverage increased (+6.3%) toÂ 43.07%
noProblem The team has added test cases and increased the test coverage.
noProblem The team has added new testcases in the new submission. The code coverage has also increased. Good work with the testcases.
noProblem Works as intended. Features work as they are supposed to. Tests cover all scenarios.
noProblem The system works perfectly as intended.
noProblem The system works as intended.
noProblem The video explains the new functionality and the functionality is working as expected. all the scenarios are covered in the rspec test as well. Good job!
noProblem Overall, it is well written.
noProblem The writeupÂ has adequate screenshots to help understand the problem statement
noProblem Contains all the required explanation.
noProblem Very good. I go by what I said in the first review. It is very legible and I could understand what the project does and how the project does what it does.
noProblem yes, the code is ready to be deployed onto the server. this is a good starting place for future team to pick up.
noProblem Looks fine. My biggest concern however is, which student's view opens here?Â Add the feature of impersonation to this, and we get two identical views of student_task/list page: one with this particular feature, and the other, with impersonation feature. What is the difference between these views
noProblem The color scheme added during this project is working when tested through the UI.
noProblem With the link provided, operation from UI are working as expected. No refactoring is required for the code change made.
noProblem Yes, as per the scope of the project, all works beautifully well. Great job team.
noProblem Works as intended.
noProblem Yes the color change is as per project. No new tests or re-factoring done as part of the project
noProblem The writeup is extremely well written. In the earlier round, I gave the team a suggestion to add the steps needed to check out their changes. They have added this part into the wiki now. Thank you and well done :)
noProblem Write up is written a neat and understandable with system screenshots and steps to test system manually.
noProblem The writing is good and completely covers the scope of the project.
noProblem Writeup is good. Explains everything they have done and how they have implemented.
noProblem No significant change from last round. But the writeup was good. Elaborative with screenshot of code and UI. It clearly mentioned the need for the change. But no approach mention but to be fair, the scope of the project doesnt call for it
noProblem Yes. The changes made are very basic and should not affect the functionality of the application in any away apart from the cosmetic changes made during the project.
noProblem Yes . Code seems ready to deploy. Also the approach taken is simple and very much acceptable.
noProblem I have no concerns regarding merging this into production.
noProblem Since, there are UI changes, they seem pretty improved
noProblem I believe the code is the best that it can ever be and should be merged with the expertiza.
noProblem The build request passed.
noProblem Well the build technically failed, but seeing as how that's practically impossible for this project, I'll give it a pass.
noProblem The build has passed and the changes are also well explained in the wiki. As expected, the screenshots of the test cases are also displayed.